{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75c69788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a02e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for data processing\n",
    "def card_to_num(card):\n",
    "    raw_rank = card[:-1]\n",
    "    \n",
    "    ranks = {\n",
    "        '2' : 0,\n",
    "        '3' : 1,\n",
    "        '4' : 2, \n",
    "        '5' : 3,\n",
    "        '6' : 4, \n",
    "        '7' : 5, \n",
    "        '8' : 6, \n",
    "        '9' : 7, \n",
    "        '10': 8, \n",
    "        'J' : 9, \n",
    "        'Q' : 10, \n",
    "        'K' : 11, \n",
    "        'A': 12\n",
    "    }\n",
    "\n",
    "    return ranks[raw_rank]\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_num(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1222d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_or_not_raw_df = pd.read_csv('CSVs/split_or_not.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb6ad32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned split_or_not\n",
    "split_or_not_raw_df['dealer_upcard'] = split_or_not_raw_df['dealer_upcard'].apply(card_to_num)\n",
    "split_or_not_raw_df['player_hand'] = split_or_not_raw_df['player_hand'].apply(hand_to_list)\n",
    "split_or_not_raw_df['player_hand'] = split_or_not_raw_df['player_hand'].apply(lambda hand: hand[0])\n",
    "split_or_not_df = split_or_not_raw_df.rename(columns = {'player_hand':'player_upcard'})\n",
    "\n",
    "# Turning into tensor matrices\n",
    "# split_or_not\n",
    "x1 = torch.tensor(split_or_not_df['player_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "x2 = torch.tensor(split_or_not_df['dealer_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(split_or_not_df['result'].values, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "X = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "split_or_not_dataset = Blackjack_Dataset(X,y)\n",
    "train_sn, test_sn = train_test_split(split_or_not_dataset, test_size=0.2) #I might have to do this earlier, on the dataframe, but this was easier so let's see if it works\n",
    "\n",
    "sn_train_dataloader = DataLoader(train_sn, batch_size=batch_size, shuffle=True)\n",
    "sn_test_dataloader = DataLoader(test_sn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4dbe5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            probs = torch.sigmoid(pred)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            correct += (preds.view(-1) == y.view(-1)).float().sum()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "659c20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sn_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "sn_model = sn_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "epochs = 20\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "sn_optimizer = torch.optim.SGD(sn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e267a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.520788  [ 3200/141921]\n",
      "loss: 0.641984  [ 6400/141921]\n",
      "loss: 0.502605  [ 9600/141921]\n",
      "loss: 0.555203  [12800/141921]\n",
      "loss: 0.564010  [16000/141921]\n",
      "loss: 0.583664  [19200/141921]\n",
      "loss: 0.635257  [22400/141921]\n",
      "loss: 0.638516  [25600/141921]\n",
      "loss: 0.618868  [28800/141921]\n",
      "loss: 0.580581  [32000/141921]\n",
      "loss: 0.607461  [35200/141921]\n",
      "loss: 0.556880  [38400/141921]\n",
      "loss: 0.536216  [41600/141921]\n",
      "loss: 0.559943  [44800/141921]\n",
      "loss: 0.610080  [48000/141921]\n",
      "loss: 0.592350  [51200/141921]\n",
      "loss: 0.534066  [54400/141921]\n",
      "loss: 0.566548  [57600/141921]\n",
      "loss: 0.406015  [60800/141921]\n",
      "loss: 0.470939  [64000/141921]\n",
      "loss: 0.461016  [67200/141921]\n",
      "loss: 0.697420  [70400/141921]\n",
      "loss: 0.626229  [73600/141921]\n",
      "loss: 0.566435  [76800/141921]\n",
      "loss: 0.642122  [80000/141921]\n",
      "loss: 0.693759  [83200/141921]\n",
      "loss: 0.655650  [86400/141921]\n",
      "loss: 0.645181  [89600/141921]\n",
      "loss: 0.615251  [92800/141921]\n",
      "loss: 0.616370  [96000/141921]\n",
      "loss: 0.554116  [99200/141921]\n",
      "loss: 0.560198  [102400/141921]\n",
      "loss: 0.650141  [105600/141921]\n",
      "loss: 0.631385  [108800/141921]\n",
      "loss: 0.652886  [112000/141921]\n",
      "loss: 0.582046  [115200/141921]\n",
      "loss: 0.514993  [118400/141921]\n",
      "loss: 0.498348  [121600/141921]\n",
      "loss: 0.425376  [124800/141921]\n",
      "loss: 0.454081  [128000/141921]\n",
      "loss: 0.608088  [131200/141921]\n",
      "loss: 0.523823  [134400/141921]\n",
      "loss: 0.572639  [137600/141921]\n",
      "loss: 0.568066  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.573052 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 0.568220  [ 3200/141921]\n",
      "loss: 0.613470  [ 6400/141921]\n",
      "loss: 0.677074  [ 9600/141921]\n",
      "loss: 0.622844  [12800/141921]\n",
      "loss: 0.629925  [16000/141921]\n",
      "loss: 0.598279  [19200/141921]\n",
      "loss: 0.639094  [22400/141921]\n",
      "loss: 0.604060  [25600/141921]\n",
      "loss: 0.517163  [28800/141921]\n",
      "loss: 0.607727  [32000/141921]\n",
      "loss: 0.545492  [35200/141921]\n",
      "loss: 0.572142  [38400/141921]\n",
      "loss: 0.503453  [41600/141921]\n",
      "loss: 0.573440  [44800/141921]\n",
      "loss: 0.564669  [48000/141921]\n",
      "loss: 0.659469  [51200/141921]\n",
      "loss: 0.511736  [54400/141921]\n",
      "loss: 0.571054  [57600/141921]\n",
      "loss: 0.638081  [60800/141921]\n",
      "loss: 0.479064  [64000/141921]\n",
      "loss: 0.551613  [67200/141921]\n",
      "loss: 0.576572  [70400/141921]\n",
      "loss: 0.512596  [73600/141921]\n",
      "loss: 0.686016  [76800/141921]\n",
      "loss: 0.543477  [80000/141921]\n",
      "loss: 0.624165  [83200/141921]\n",
      "loss: 0.584883  [86400/141921]\n",
      "loss: 0.603492  [89600/141921]\n",
      "loss: 0.612811  [92800/141921]\n",
      "loss: 0.509924  [96000/141921]\n",
      "loss: 0.538235  [99200/141921]\n",
      "loss: 0.554803  [102400/141921]\n",
      "loss: 0.655719  [105600/141921]\n",
      "loss: 0.572836  [108800/141921]\n",
      "loss: 0.595605  [112000/141921]\n",
      "loss: 0.584206  [115200/141921]\n",
      "loss: 0.518948  [118400/141921]\n",
      "loss: 0.710605  [121600/141921]\n",
      "loss: 0.538655  [124800/141921]\n",
      "loss: 0.693224  [128000/141921]\n",
      "loss: 0.530669  [131200/141921]\n",
      "loss: 0.584753  [134400/141921]\n",
      "loss: 0.674155  [137600/141921]\n",
      "loss: 0.601868  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.566745 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 0.456701  [ 3200/141921]\n",
      "loss: 0.552778  [ 6400/141921]\n",
      "loss: 0.620782  [ 9600/141921]\n",
      "loss: 0.695017  [12800/141921]\n",
      "loss: 0.587768  [16000/141921]\n",
      "loss: 0.558938  [19200/141921]\n",
      "loss: 0.625295  [22400/141921]\n",
      "loss: 0.633380  [25600/141921]\n",
      "loss: 0.539957  [28800/141921]\n",
      "loss: 0.633686  [32000/141921]\n",
      "loss: 0.641821  [35200/141921]\n",
      "loss: 0.594242  [38400/141921]\n",
      "loss: 0.613266  [41600/141921]\n",
      "loss: 0.588964  [44800/141921]\n",
      "loss: 0.547323  [48000/141921]\n",
      "loss: 0.707759  [51200/141921]\n",
      "loss: 0.549529  [54400/141921]\n",
      "loss: 0.520285  [57600/141921]\n",
      "loss: 0.486497  [60800/141921]\n",
      "loss: 0.621462  [64000/141921]\n",
      "loss: 0.629739  [67200/141921]\n",
      "loss: 0.548610  [70400/141921]\n",
      "loss: 0.491222  [73600/141921]\n",
      "loss: 0.601572  [76800/141921]\n",
      "loss: 0.545145  [80000/141921]\n",
      "loss: 0.604878  [83200/141921]\n",
      "loss: 0.647031  [86400/141921]\n",
      "loss: 0.589444  [89600/141921]\n",
      "loss: 0.593618  [92800/141921]\n",
      "loss: 0.559874  [96000/141921]\n",
      "loss: 0.606723  [99200/141921]\n",
      "loss: 0.579907  [102400/141921]\n",
      "loss: 0.647973  [105600/141921]\n",
      "loss: 0.453172  [108800/141921]\n",
      "loss: 0.532730  [112000/141921]\n",
      "loss: 0.560359  [115200/141921]\n",
      "loss: 0.525206  [118400/141921]\n",
      "loss: 0.602819  [121600/141921]\n",
      "loss: 0.619217  [124800/141921]\n",
      "loss: 0.621313  [128000/141921]\n",
      "loss: 0.550632  [131200/141921]\n",
      "loss: 0.623731  [134400/141921]\n",
      "loss: 0.524754  [137600/141921]\n",
      "loss: 0.516945  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.561586 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 0.525274  [ 3200/141921]\n",
      "loss: 0.472449  [ 6400/141921]\n",
      "loss: 0.624550  [ 9600/141921]\n",
      "loss: 0.572676  [12800/141921]\n",
      "loss: 0.635954  [16000/141921]\n",
      "loss: 0.533458  [19200/141921]\n",
      "loss: 0.595343  [22400/141921]\n",
      "loss: 0.493775  [25600/141921]\n",
      "loss: 0.516704  [28800/141921]\n",
      "loss: 0.631282  [32000/141921]\n",
      "loss: 0.532866  [35200/141921]\n",
      "loss: 0.533382  [38400/141921]\n",
      "loss: 0.427415  [41600/141921]\n",
      "loss: 0.592273  [44800/141921]\n",
      "loss: 0.525907  [48000/141921]\n",
      "loss: 0.608698  [51200/141921]\n",
      "loss: 0.630920  [54400/141921]\n",
      "loss: 0.545729  [57600/141921]\n",
      "loss: 0.533807  [60800/141921]\n",
      "loss: 0.563309  [64000/141921]\n",
      "loss: 0.725954  [67200/141921]\n",
      "loss: 0.634819  [70400/141921]\n",
      "loss: 0.491486  [73600/141921]\n",
      "loss: 0.746470  [76800/141921]\n",
      "loss: 0.633753  [80000/141921]\n",
      "loss: 0.588235  [83200/141921]\n",
      "loss: 0.612852  [86400/141921]\n",
      "loss: 0.525689  [89600/141921]\n",
      "loss: 0.524878  [92800/141921]\n",
      "loss: 0.604876  [96000/141921]\n",
      "loss: 0.537412  [99200/141921]\n",
      "loss: 0.573603  [102400/141921]\n",
      "loss: 0.594638  [105600/141921]\n",
      "loss: 0.547986  [108800/141921]\n",
      "loss: 0.541242  [112000/141921]\n",
      "loss: 0.522931  [115200/141921]\n",
      "loss: 0.615156  [118400/141921]\n",
      "loss: 0.519353  [121600/141921]\n",
      "loss: 0.544512  [124800/141921]\n",
      "loss: 0.599850  [128000/141921]\n",
      "loss: 0.621802  [131200/141921]\n",
      "loss: 0.542689  [134400/141921]\n",
      "loss: 0.482205  [137600/141921]\n",
      "loss: 0.576488  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.558639 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 0.537923  [ 3200/141921]\n",
      "loss: 0.566829  [ 6400/141921]\n",
      "loss: 0.460067  [ 9600/141921]\n",
      "loss: 0.559200  [12800/141921]\n",
      "loss: 0.551203  [16000/141921]\n",
      "loss: 0.795562  [19200/141921]\n",
      "loss: 0.590441  [22400/141921]\n",
      "loss: 0.536339  [25600/141921]\n",
      "loss: 0.603891  [28800/141921]\n",
      "loss: 0.467676  [32000/141921]\n",
      "loss: 0.563693  [35200/141921]\n",
      "loss: 0.590389  [38400/141921]\n",
      "loss: 0.522573  [41600/141921]\n",
      "loss: 0.703746  [44800/141921]\n",
      "loss: 0.713511  [48000/141921]\n",
      "loss: 0.451068  [51200/141921]\n",
      "loss: 0.627708  [54400/141921]\n",
      "loss: 0.459123  [57600/141921]\n",
      "loss: 0.548917  [60800/141921]\n",
      "loss: 0.618076  [64000/141921]\n",
      "loss: 0.629160  [67200/141921]\n",
      "loss: 0.467935  [70400/141921]\n",
      "loss: 0.645666  [73600/141921]\n",
      "loss: 0.507205  [76800/141921]\n",
      "loss: 0.512484  [80000/141921]\n",
      "loss: 0.555235  [83200/141921]\n",
      "loss: 0.570838  [86400/141921]\n",
      "loss: 0.613760  [89600/141921]\n",
      "loss: 0.490915  [92800/141921]\n",
      "loss: 0.622042  [96000/141921]\n",
      "loss: 0.545635  [99200/141921]\n",
      "loss: 0.512392  [102400/141921]\n",
      "loss: 0.838921  [105600/141921]\n",
      "loss: 0.465870  [108800/141921]\n",
      "loss: 0.506364  [112000/141921]\n",
      "loss: 0.502097  [115200/141921]\n",
      "loss: 0.566460  [118400/141921]\n",
      "loss: 0.552358  [121600/141921]\n",
      "loss: 0.512865  [124800/141921]\n",
      "loss: 0.522694  [128000/141921]\n",
      "loss: 0.563285  [131200/141921]\n",
      "loss: 0.572343  [134400/141921]\n",
      "loss: 0.434406  [137600/141921]\n",
      "loss: 0.527494  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.553749 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 0.463602  [ 3200/141921]\n",
      "loss: 0.414661  [ 6400/141921]\n",
      "loss: 0.553948  [ 9600/141921]\n",
      "loss: 0.504379  [12800/141921]\n",
      "loss: 0.416889  [16000/141921]\n",
      "loss: 0.505766  [19200/141921]\n",
      "loss: 0.352581  [22400/141921]\n",
      "loss: 0.470357  [25600/141921]\n",
      "loss: 0.590135  [28800/141921]\n",
      "loss: 0.586019  [32000/141921]\n",
      "loss: 0.447684  [35200/141921]\n",
      "loss: 0.569994  [38400/141921]\n",
      "loss: 0.532069  [41600/141921]\n",
      "loss: 0.519464  [44800/141921]\n",
      "loss: 0.453282  [48000/141921]\n",
      "loss: 0.668589  [51200/141921]\n",
      "loss: 0.497137  [54400/141921]\n",
      "loss: 0.578208  [57600/141921]\n",
      "loss: 0.615813  [60800/141921]\n",
      "loss: 0.522999  [64000/141921]\n",
      "loss: 0.600660  [67200/141921]\n",
      "loss: 0.534998  [70400/141921]\n",
      "loss: 0.537175  [73600/141921]\n",
      "loss: 0.555045  [76800/141921]\n",
      "loss: 0.434053  [80000/141921]\n",
      "loss: 0.419916  [83200/141921]\n",
      "loss: 0.649584  [86400/141921]\n",
      "loss: 0.600300  [89600/141921]\n",
      "loss: 0.414246  [92800/141921]\n",
      "loss: 0.659793  [96000/141921]\n",
      "loss: 0.487442  [99200/141921]\n",
      "loss: 0.553133  [102400/141921]\n",
      "loss: 0.487929  [105600/141921]\n",
      "loss: 0.564327  [108800/141921]\n",
      "loss: 0.648826  [112000/141921]\n",
      "loss: 0.529954  [115200/141921]\n",
      "loss: 0.665404  [118400/141921]\n",
      "loss: 0.554272  [121600/141921]\n",
      "loss: 0.519136  [124800/141921]\n",
      "loss: 0.465372  [128000/141921]\n",
      "loss: 0.575046  [131200/141921]\n",
      "loss: 0.623736  [134400/141921]\n",
      "loss: 0.549355  [137600/141921]\n",
      "loss: 0.595209  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.550932 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 0.653823  [ 3200/141921]\n",
      "loss: 0.631829  [ 6400/141921]\n",
      "loss: 0.481429  [ 9600/141921]\n",
      "loss: 0.616879  [12800/141921]\n",
      "loss: 0.517852  [16000/141921]\n",
      "loss: 0.498991  [19200/141921]\n",
      "loss: 0.514313  [22400/141921]\n",
      "loss: 0.646806  [25600/141921]\n",
      "loss: 0.464346  [28800/141921]\n",
      "loss: 0.536123  [32000/141921]\n",
      "loss: 0.614087  [35200/141921]\n",
      "loss: 0.573817  [38400/141921]\n",
      "loss: 0.680026  [41600/141921]\n",
      "loss: 0.603101  [44800/141921]\n",
      "loss: 0.458395  [48000/141921]\n",
      "loss: 0.584034  [51200/141921]\n",
      "loss: 0.633537  [54400/141921]\n",
      "loss: 0.580113  [57600/141921]\n",
      "loss: 0.505835  [60800/141921]\n",
      "loss: 0.563063  [64000/141921]\n",
      "loss: 0.454800  [67200/141921]\n",
      "loss: 0.511301  [70400/141921]\n",
      "loss: 0.458156  [73600/141921]\n",
      "loss: 0.455619  [76800/141921]\n",
      "loss: 0.537536  [80000/141921]\n",
      "loss: 0.548507  [83200/141921]\n",
      "loss: 0.566308  [86400/141921]\n",
      "loss: 0.610129  [89600/141921]\n",
      "loss: 0.701235  [92800/141921]\n",
      "loss: 0.535502  [96000/141921]\n",
      "loss: 0.505089  [99200/141921]\n",
      "loss: 0.600678  [102400/141921]\n",
      "loss: 0.625016  [105600/141921]\n",
      "loss: 0.497371  [108800/141921]\n",
      "loss: 0.558744  [112000/141921]\n",
      "loss: 0.536285  [115200/141921]\n",
      "loss: 0.575565  [118400/141921]\n",
      "loss: 0.668831  [121600/141921]\n",
      "loss: 0.532138  [124800/141921]\n",
      "loss: 0.424463  [128000/141921]\n",
      "loss: 0.377382  [131200/141921]\n",
      "loss: 0.518553  [134400/141921]\n",
      "loss: 0.545164  [137600/141921]\n",
      "loss: 0.507658  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.549305 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 0.566084  [ 3200/141921]\n",
      "loss: 0.646750  [ 6400/141921]\n",
      "loss: 0.594450  [ 9600/141921]\n",
      "loss: 0.602882  [12800/141921]\n",
      "loss: 0.424481  [16000/141921]\n",
      "loss: 0.498313  [19200/141921]\n",
      "loss: 0.626154  [22400/141921]\n",
      "loss: 0.669365  [25600/141921]\n",
      "loss: 0.534589  [28800/141921]\n",
      "loss: 0.560812  [32000/141921]\n",
      "loss: 0.473040  [35200/141921]\n",
      "loss: 0.586874  [38400/141921]\n",
      "loss: 0.473257  [41600/141921]\n",
      "loss: 0.675062  [44800/141921]\n",
      "loss: 0.551741  [48000/141921]\n",
      "loss: 0.612578  [51200/141921]\n",
      "loss: 0.543590  [54400/141921]\n",
      "loss: 0.600544  [57600/141921]\n",
      "loss: 0.719032  [60800/141921]\n",
      "loss: 0.659509  [64000/141921]\n",
      "loss: 0.576320  [67200/141921]\n",
      "loss: 0.598450  [70400/141921]\n",
      "loss: 0.561299  [73600/141921]\n",
      "loss: 0.620630  [76800/141921]\n",
      "loss: 0.584412  [80000/141921]\n",
      "loss: 0.652309  [83200/141921]\n",
      "loss: 0.564290  [86400/141921]\n",
      "loss: 0.617744  [89600/141921]\n",
      "loss: 0.547952  [92800/141921]\n",
      "loss: 0.572691  [96000/141921]\n",
      "loss: 0.456027  [99200/141921]\n",
      "loss: 0.552327  [102400/141921]\n",
      "loss: 0.565512  [105600/141921]\n",
      "loss: 0.630989  [108800/141921]\n",
      "loss: 0.668767  [112000/141921]\n",
      "loss: 0.497158  [115200/141921]\n",
      "loss: 0.495524  [118400/141921]\n",
      "loss: 0.512913  [121600/141921]\n",
      "loss: 0.582826  [124800/141921]\n",
      "loss: 0.549279  [128000/141921]\n",
      "loss: 0.421581  [131200/141921]\n",
      "loss: 0.654142  [134400/141921]\n",
      "loss: 0.463895  [137600/141921]\n",
      "loss: 0.487047  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.546235 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 0.529254  [ 3200/141921]\n",
      "loss: 0.538352  [ 6400/141921]\n",
      "loss: 0.586964  [ 9600/141921]\n",
      "loss: 0.673954  [12800/141921]\n",
      "loss: 0.525560  [16000/141921]\n",
      "loss: 0.527193  [19200/141921]\n",
      "loss: 0.442618  [22400/141921]\n",
      "loss: 0.639644  [25600/141921]\n",
      "loss: 0.480841  [28800/141921]\n",
      "loss: 0.451923  [32000/141921]\n",
      "loss: 0.511867  [35200/141921]\n",
      "loss: 0.482384  [38400/141921]\n",
      "loss: 0.583025  [41600/141921]\n",
      "loss: 0.406089  [44800/141921]\n",
      "loss: 0.482658  [48000/141921]\n",
      "loss: 0.542641  [51200/141921]\n",
      "loss: 0.609163  [54400/141921]\n",
      "loss: 0.566327  [57600/141921]\n",
      "loss: 0.575140  [60800/141921]\n",
      "loss: 0.540695  [64000/141921]\n",
      "loss: 0.623868  [67200/141921]\n",
      "loss: 0.512600  [70400/141921]\n",
      "loss: 0.548748  [73600/141921]\n",
      "loss: 0.559914  [76800/141921]\n",
      "loss: 0.688707  [80000/141921]\n",
      "loss: 0.453062  [83200/141921]\n",
      "loss: 0.447759  [86400/141921]\n",
      "loss: 0.541840  [89600/141921]\n",
      "loss: 0.591616  [92800/141921]\n",
      "loss: 0.546313  [96000/141921]\n",
      "loss: 0.568680  [99200/141921]\n",
      "loss: 0.464976  [102400/141921]\n",
      "loss: 0.623559  [105600/141921]\n",
      "loss: 0.427720  [108800/141921]\n",
      "loss: 0.531017  [112000/141921]\n",
      "loss: 0.463921  [115200/141921]\n",
      "loss: 0.349685  [118400/141921]\n",
      "loss: 0.590778  [121600/141921]\n",
      "loss: 0.567717  [124800/141921]\n",
      "loss: 0.637955  [128000/141921]\n",
      "loss: 0.411099  [131200/141921]\n",
      "loss: 0.524008  [134400/141921]\n",
      "loss: 0.493711  [137600/141921]\n",
      "loss: 0.446727  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.544659 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 0.538057  [ 3200/141921]\n",
      "loss: 0.431650  [ 6400/141921]\n",
      "loss: 0.557854  [ 9600/141921]\n",
      "loss: 0.543264  [12800/141921]\n",
      "loss: 0.690567  [16000/141921]\n",
      "loss: 0.497886  [19200/141921]\n",
      "loss: 0.517233  [22400/141921]\n",
      "loss: 0.594410  [25600/141921]\n",
      "loss: 0.366723  [28800/141921]\n",
      "loss: 0.571038  [32000/141921]\n",
      "loss: 0.514431  [35200/141921]\n",
      "loss: 0.497476  [38400/141921]\n",
      "loss: 0.530375  [41600/141921]\n",
      "loss: 0.415529  [44800/141921]\n",
      "loss: 0.622598  [48000/141921]\n",
      "loss: 0.555070  [51200/141921]\n",
      "loss: 0.599026  [54400/141921]\n",
      "loss: 0.482596  [57600/141921]\n",
      "loss: 0.502745  [60800/141921]\n",
      "loss: 0.736140  [64000/141921]\n",
      "loss: 0.566901  [67200/141921]\n",
      "loss: 0.460248  [70400/141921]\n",
      "loss: 0.480022  [73600/141921]\n",
      "loss: 0.590760  [76800/141921]\n",
      "loss: 0.501209  [80000/141921]\n",
      "loss: 0.752116  [83200/141921]\n",
      "loss: 0.591662  [86400/141921]\n",
      "loss: 0.411940  [89600/141921]\n",
      "loss: 0.590262  [92800/141921]\n",
      "loss: 0.452605  [96000/141921]\n",
      "loss: 0.584113  [99200/141921]\n",
      "loss: 0.571740  [102400/141921]\n",
      "loss: 0.560744  [105600/141921]\n",
      "loss: 0.613692  [108800/141921]\n",
      "loss: 0.516206  [112000/141921]\n",
      "loss: 0.564434  [115200/141921]\n",
      "loss: 0.579996  [118400/141921]\n",
      "loss: 0.527339  [121600/141921]\n",
      "loss: 0.363384  [124800/141921]\n",
      "loss: 0.457354  [128000/141921]\n",
      "loss: 0.604505  [131200/141921]\n",
      "loss: 0.538854  [134400/141921]\n",
      "loss: 0.552084  [137600/141921]\n",
      "loss: 0.497612  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.542796 \n",
      "\n",
      "Epoch 11\n",
      "---------------------------\n",
      "loss: 0.502409  [ 3200/141921]\n",
      "loss: 0.516823  [ 6400/141921]\n",
      "loss: 0.534266  [ 9600/141921]\n",
      "loss: 0.571918  [12800/141921]\n",
      "loss: 0.477870  [16000/141921]\n",
      "loss: 0.731743  [19200/141921]\n",
      "loss: 0.536819  [22400/141921]\n",
      "loss: 0.527992  [25600/141921]\n",
      "loss: 0.558592  [28800/141921]\n",
      "loss: 0.523150  [32000/141921]\n",
      "loss: 0.492738  [35200/141921]\n",
      "loss: 0.620516  [38400/141921]\n",
      "loss: 0.604673  [41600/141921]\n",
      "loss: 0.588252  [44800/141921]\n",
      "loss: 0.454886  [48000/141921]\n",
      "loss: 0.524347  [51200/141921]\n",
      "loss: 0.597595  [54400/141921]\n",
      "loss: 0.492604  [57600/141921]\n",
      "loss: 0.480004  [60800/141921]\n",
      "loss: 0.548563  [64000/141921]\n",
      "loss: 0.555847  [67200/141921]\n",
      "loss: 0.578741  [70400/141921]\n",
      "loss: 0.465966  [73600/141921]\n",
      "loss: 0.546234  [76800/141921]\n",
      "loss: 0.511214  [80000/141921]\n",
      "loss: 0.538833  [83200/141921]\n",
      "loss: 0.537082  [86400/141921]\n",
      "loss: 0.401496  [89600/141921]\n",
      "loss: 0.425599  [92800/141921]\n",
      "loss: 0.543924  [96000/141921]\n",
      "loss: 0.568311  [99200/141921]\n",
      "loss: 0.590206  [102400/141921]\n",
      "loss: 0.684014  [105600/141921]\n",
      "loss: 0.422073  [108800/141921]\n",
      "loss: 0.465337  [112000/141921]\n",
      "loss: 0.501341  [115200/141921]\n",
      "loss: 0.356637  [118400/141921]\n",
      "loss: 0.511495  [121600/141921]\n",
      "loss: 0.587410  [124800/141921]\n",
      "loss: 0.587298  [128000/141921]\n",
      "loss: 0.513908  [131200/141921]\n",
      "loss: 0.700539  [134400/141921]\n",
      "loss: 0.625805  [137600/141921]\n",
      "loss: 0.549625  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.540767 \n",
      "\n",
      "Epoch 12\n",
      "---------------------------\n",
      "loss: 0.415358  [ 3200/141921]\n",
      "loss: 0.421050  [ 6400/141921]\n",
      "loss: 0.634386  [ 9600/141921]\n",
      "loss: 0.520118  [12800/141921]\n",
      "loss: 0.533390  [16000/141921]\n",
      "loss: 0.488672  [19200/141921]\n",
      "loss: 0.507697  [22400/141921]\n",
      "loss: 0.483627  [25600/141921]\n",
      "loss: 0.434918  [28800/141921]\n",
      "loss: 0.561894  [32000/141921]\n",
      "loss: 0.549592  [35200/141921]\n",
      "loss: 0.592589  [38400/141921]\n",
      "loss: 0.588218  [41600/141921]\n",
      "loss: 0.456597  [44800/141921]\n",
      "loss: 0.512270  [48000/141921]\n",
      "loss: 0.726929  [51200/141921]\n",
      "loss: 0.504739  [54400/141921]\n",
      "loss: 0.592100  [57600/141921]\n",
      "loss: 0.510750  [60800/141921]\n",
      "loss: 0.531633  [64000/141921]\n",
      "loss: 0.565370  [67200/141921]\n",
      "loss: 0.627512  [70400/141921]\n",
      "loss: 0.565690  [73600/141921]\n",
      "loss: 0.570968  [76800/141921]\n",
      "loss: 0.614438  [80000/141921]\n",
      "loss: 0.627462  [83200/141921]\n",
      "loss: 0.606295  [86400/141921]\n",
      "loss: 0.514214  [89600/141921]\n",
      "loss: 0.422537  [92800/141921]\n",
      "loss: 0.484787  [96000/141921]\n",
      "loss: 0.408047  [99200/141921]\n",
      "loss: 0.409749  [102400/141921]\n",
      "loss: 0.552593  [105600/141921]\n",
      "loss: 0.453261  [108800/141921]\n",
      "loss: 0.504984  [112000/141921]\n",
      "loss: 0.539554  [115200/141921]\n",
      "loss: 0.661383  [118400/141921]\n",
      "loss: 0.563409  [121600/141921]\n",
      "loss: 0.565080  [124800/141921]\n",
      "loss: 0.506353  [128000/141921]\n",
      "loss: 0.568316  [131200/141921]\n",
      "loss: 0.573544  [134400/141921]\n",
      "loss: 0.481829  [137600/141921]\n",
      "loss: 0.483765  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.539022 \n",
      "\n",
      "Epoch 13\n",
      "---------------------------\n",
      "loss: 0.520363  [ 3200/141921]\n",
      "loss: 0.525457  [ 6400/141921]\n",
      "loss: 0.470792  [ 9600/141921]\n",
      "loss: 0.462372  [12800/141921]\n",
      "loss: 0.607730  [16000/141921]\n",
      "loss: 0.586168  [19200/141921]\n",
      "loss: 0.509737  [22400/141921]\n",
      "loss: 0.456998  [25600/141921]\n",
      "loss: 0.588740  [28800/141921]\n",
      "loss: 0.550424  [32000/141921]\n",
      "loss: 0.566695  [35200/141921]\n",
      "loss: 0.455538  [38400/141921]\n",
      "loss: 0.585636  [41600/141921]\n",
      "loss: 0.485747  [44800/141921]\n",
      "loss: 0.594377  [48000/141921]\n",
      "loss: 0.501032  [51200/141921]\n",
      "loss: 0.721538  [54400/141921]\n",
      "loss: 0.422167  [57600/141921]\n",
      "loss: 0.507633  [60800/141921]\n",
      "loss: 0.709197  [64000/141921]\n",
      "loss: 0.452116  [67200/141921]\n",
      "loss: 0.379266  [70400/141921]\n",
      "loss: 0.544428  [73600/141921]\n",
      "loss: 0.449315  [76800/141921]\n",
      "loss: 0.596055  [80000/141921]\n",
      "loss: 0.506729  [83200/141921]\n",
      "loss: 0.573602  [86400/141921]\n",
      "loss: 0.669039  [89600/141921]\n",
      "loss: 0.468189  [92800/141921]\n",
      "loss: 0.508776  [96000/141921]\n",
      "loss: 0.514878  [99200/141921]\n",
      "loss: 0.568056  [102400/141921]\n",
      "loss: 0.480246  [105600/141921]\n",
      "loss: 0.543268  [108800/141921]\n",
      "loss: 0.479999  [112000/141921]\n",
      "loss: 0.373165  [115200/141921]\n",
      "loss: 0.430821  [118400/141921]\n",
      "loss: 0.620145  [121600/141921]\n",
      "loss: 0.453097  [124800/141921]\n",
      "loss: 0.475792  [128000/141921]\n",
      "loss: 0.412249  [131200/141921]\n",
      "loss: 0.504056  [134400/141921]\n",
      "loss: 0.466198  [137600/141921]\n",
      "loss: 0.526035  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.540612 \n",
      "\n",
      "Epoch 14\n",
      "---------------------------\n",
      "loss: 0.527320  [ 3200/141921]\n",
      "loss: 0.608464  [ 6400/141921]\n",
      "loss: 0.411093  [ 9600/141921]\n",
      "loss: 0.515859  [12800/141921]\n",
      "loss: 0.518371  [16000/141921]\n",
      "loss: 0.442607  [19200/141921]\n",
      "loss: 0.660135  [22400/141921]\n",
      "loss: 0.598987  [25600/141921]\n",
      "loss: 0.504406  [28800/141921]\n",
      "loss: 0.463521  [32000/141921]\n",
      "loss: 0.493862  [35200/141921]\n",
      "loss: 0.505737  [38400/141921]\n",
      "loss: 0.580173  [41600/141921]\n",
      "loss: 0.576400  [44800/141921]\n",
      "loss: 0.512555  [48000/141921]\n",
      "loss: 0.622035  [51200/141921]\n",
      "loss: 0.478484  [54400/141921]\n",
      "loss: 0.545591  [57600/141921]\n",
      "loss: 0.450112  [60800/141921]\n",
      "loss: 0.486760  [64000/141921]\n",
      "loss: 0.566674  [67200/141921]\n",
      "loss: 0.604730  [70400/141921]\n",
      "loss: 0.403053  [73600/141921]\n",
      "loss: 0.631429  [76800/141921]\n",
      "loss: 0.535443  [80000/141921]\n",
      "loss: 0.509158  [83200/141921]\n",
      "loss: 0.340938  [86400/141921]\n",
      "loss: 0.531851  [89600/141921]\n",
      "loss: 0.613048  [92800/141921]\n",
      "loss: 0.475242  [96000/141921]\n",
      "loss: 0.572006  [99200/141921]\n",
      "loss: 0.498500  [102400/141921]\n",
      "loss: 0.464209  [105600/141921]\n",
      "loss: 0.506467  [108800/141921]\n",
      "loss: 0.576343  [112000/141921]\n",
      "loss: 0.456128  [115200/141921]\n",
      "loss: 0.638784  [118400/141921]\n",
      "loss: 0.546089  [121600/141921]\n",
      "loss: 0.626844  [124800/141921]\n",
      "loss: 0.419396  [128000/141921]\n",
      "loss: 0.480150  [131200/141921]\n",
      "loss: 0.434194  [134400/141921]\n",
      "loss: 0.544718  [137600/141921]\n",
      "loss: 0.442057  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.535489 \n",
      "\n",
      "Epoch 15\n",
      "---------------------------\n",
      "loss: 0.519371  [ 3200/141921]\n",
      "loss: 0.448719  [ 6400/141921]\n",
      "loss: 0.654294  [ 9600/141921]\n",
      "loss: 0.458037  [12800/141921]\n",
      "loss: 0.562704  [16000/141921]\n",
      "loss: 0.663047  [19200/141921]\n",
      "loss: 0.483775  [22400/141921]\n",
      "loss: 0.564822  [25600/141921]\n",
      "loss: 0.569716  [28800/141921]\n",
      "loss: 0.657776  [32000/141921]\n",
      "loss: 0.531190  [35200/141921]\n",
      "loss: 0.584726  [38400/141921]\n",
      "loss: 0.584080  [41600/141921]\n",
      "loss: 0.530384  [44800/141921]\n",
      "loss: 0.512564  [48000/141921]\n",
      "loss: 0.485260  [51200/141921]\n",
      "loss: 0.595872  [54400/141921]\n",
      "loss: 0.537874  [57600/141921]\n",
      "loss: 0.638655  [60800/141921]\n",
      "loss: 0.511772  [64000/141921]\n",
      "loss: 0.539830  [67200/141921]\n",
      "loss: 0.553673  [70400/141921]\n",
      "loss: 0.562995  [73600/141921]\n",
      "loss: 0.526162  [76800/141921]\n",
      "loss: 0.607423  [80000/141921]\n",
      "loss: 0.589470  [83200/141921]\n",
      "loss: 0.559651  [86400/141921]\n",
      "loss: 0.548813  [89600/141921]\n",
      "loss: 0.537708  [92800/141921]\n",
      "loss: 0.588734  [96000/141921]\n",
      "loss: 0.439733  [99200/141921]\n",
      "loss: 0.656187  [102400/141921]\n",
      "loss: 0.636836  [105600/141921]\n",
      "loss: 0.620810  [108800/141921]\n",
      "loss: 0.513473  [112000/141921]\n",
      "loss: 0.660818  [115200/141921]\n",
      "loss: 0.425701  [118400/141921]\n",
      "loss: 0.622479  [121600/141921]\n",
      "loss: 0.517668  [124800/141921]\n",
      "loss: 0.408482  [128000/141921]\n",
      "loss: 0.423561  [131200/141921]\n",
      "loss: 0.677750  [134400/141921]\n",
      "loss: 0.492035  [137600/141921]\n",
      "loss: 0.473099  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.533667 \n",
      "\n",
      "Epoch 16\n",
      "---------------------------\n",
      "loss: 0.653641  [ 3200/141921]\n",
      "loss: 0.513408  [ 6400/141921]\n",
      "loss: 0.579245  [ 9600/141921]\n",
      "loss: 0.505048  [12800/141921]\n",
      "loss: 0.542914  [16000/141921]\n",
      "loss: 0.521707  [19200/141921]\n",
      "loss: 0.567724  [22400/141921]\n",
      "loss: 0.534786  [25600/141921]\n",
      "loss: 0.463107  [28800/141921]\n",
      "loss: 0.517636  [32000/141921]\n",
      "loss: 0.606963  [35200/141921]\n",
      "loss: 0.560812  [38400/141921]\n",
      "loss: 0.562474  [41600/141921]\n",
      "loss: 0.566961  [44800/141921]\n",
      "loss: 0.489772  [48000/141921]\n",
      "loss: 0.530101  [51200/141921]\n",
      "loss: 0.511771  [54400/141921]\n",
      "loss: 0.574718  [57600/141921]\n",
      "loss: 0.474105  [60800/141921]\n",
      "loss: 0.603048  [64000/141921]\n",
      "loss: 0.548649  [67200/141921]\n",
      "loss: 0.583542  [70400/141921]\n",
      "loss: 0.637949  [73600/141921]\n",
      "loss: 0.462634  [76800/141921]\n",
      "loss: 0.561011  [80000/141921]\n",
      "loss: 0.563781  [83200/141921]\n",
      "loss: 0.420451  [86400/141921]\n",
      "loss: 0.433443  [89600/141921]\n",
      "loss: 0.483284  [92800/141921]\n",
      "loss: 0.541487  [96000/141921]\n",
      "loss: 0.457994  [99200/141921]\n",
      "loss: 0.469044  [102400/141921]\n",
      "loss: 0.645316  [105600/141921]\n",
      "loss: 0.549572  [108800/141921]\n",
      "loss: 0.422356  [112000/141921]\n",
      "loss: 0.747605  [115200/141921]\n",
      "loss: 0.531562  [118400/141921]\n",
      "loss: 0.573334  [121600/141921]\n",
      "loss: 0.502697  [124800/141921]\n",
      "loss: 0.668972  [128000/141921]\n",
      "loss: 0.551325  [131200/141921]\n",
      "loss: 0.688660  [134400/141921]\n",
      "loss: 0.525304  [137600/141921]\n",
      "loss: 0.405242  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.531209 \n",
      "\n",
      "Epoch 17\n",
      "---------------------------\n",
      "loss: 0.547516  [ 3200/141921]\n",
      "loss: 0.482570  [ 6400/141921]\n",
      "loss: 0.587839  [ 9600/141921]\n",
      "loss: 0.500224  [12800/141921]\n",
      "loss: 0.586584  [16000/141921]\n",
      "loss: 0.626848  [19200/141921]\n",
      "loss: 0.492596  [22400/141921]\n",
      "loss: 0.475499  [25600/141921]\n",
      "loss: 0.498169  [28800/141921]\n",
      "loss: 0.553804  [32000/141921]\n",
      "loss: 0.517781  [35200/141921]\n",
      "loss: 0.655857  [38400/141921]\n",
      "loss: 0.578644  [41600/141921]\n",
      "loss: 0.472173  [44800/141921]\n",
      "loss: 0.514768  [48000/141921]\n",
      "loss: 0.517913  [51200/141921]\n",
      "loss: 0.503998  [54400/141921]\n",
      "loss: 0.562239  [57600/141921]\n",
      "loss: 0.507273  [60800/141921]\n",
      "loss: 0.551142  [64000/141921]\n",
      "loss: 0.604751  [67200/141921]\n",
      "loss: 0.584927  [70400/141921]\n",
      "loss: 0.584769  [73600/141921]\n",
      "loss: 0.523814  [76800/141921]\n",
      "loss: 0.542226  [80000/141921]\n",
      "loss: 0.425903  [83200/141921]\n",
      "loss: 0.506462  [86400/141921]\n",
      "loss: 0.432634  [89600/141921]\n",
      "loss: 0.467084  [92800/141921]\n",
      "loss: 0.469937  [96000/141921]\n",
      "loss: 0.460872  [99200/141921]\n",
      "loss: 0.564227  [102400/141921]\n",
      "loss: 0.478038  [105600/141921]\n",
      "loss: 0.460287  [108800/141921]\n",
      "loss: 0.498659  [112000/141921]\n",
      "loss: 0.444427  [115200/141921]\n",
      "loss: 0.550721  [118400/141921]\n",
      "loss: 0.483930  [121600/141921]\n",
      "loss: 0.437247  [124800/141921]\n",
      "loss: 0.517760  [128000/141921]\n",
      "loss: 0.528229  [131200/141921]\n",
      "loss: 0.437793  [134400/141921]\n",
      "loss: 0.534867  [137600/141921]\n",
      "loss: 0.593702  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.528946 \n",
      "\n",
      "Epoch 18\n",
      "---------------------------\n",
      "loss: 0.473633  [ 3200/141921]\n",
      "loss: 0.590240  [ 6400/141921]\n",
      "loss: 0.414568  [ 9600/141921]\n",
      "loss: 0.489444  [12800/141921]\n",
      "loss: 0.480453  [16000/141921]\n",
      "loss: 0.435348  [19200/141921]\n",
      "loss: 0.391263  [22400/141921]\n",
      "loss: 0.549726  [25600/141921]\n",
      "loss: 0.459629  [28800/141921]\n",
      "loss: 0.536102  [32000/141921]\n",
      "loss: 0.463749  [35200/141921]\n",
      "loss: 0.480713  [38400/141921]\n",
      "loss: 0.603906  [41600/141921]\n",
      "loss: 0.469683  [44800/141921]\n",
      "loss: 0.399370  [48000/141921]\n",
      "loss: 0.505749  [51200/141921]\n",
      "loss: 0.460636  [54400/141921]\n",
      "loss: 0.463787  [57600/141921]\n",
      "loss: 0.437054  [60800/141921]\n",
      "loss: 0.630359  [64000/141921]\n",
      "loss: 0.536819  [67200/141921]\n",
      "loss: 0.483781  [70400/141921]\n",
      "loss: 0.374897  [73600/141921]\n",
      "loss: 0.617412  [76800/141921]\n",
      "loss: 0.576893  [80000/141921]\n",
      "loss: 0.499131  [83200/141921]\n",
      "loss: 0.504275  [86400/141921]\n",
      "loss: 0.526699  [89600/141921]\n",
      "loss: 0.499133  [92800/141921]\n",
      "loss: 0.397421  [96000/141921]\n",
      "loss: 0.555043  [99200/141921]\n",
      "loss: 0.679402  [102400/141921]\n",
      "loss: 0.658490  [105600/141921]\n",
      "loss: 0.717317  [108800/141921]\n",
      "loss: 0.485152  [112000/141921]\n",
      "loss: 0.495040  [115200/141921]\n",
      "loss: 0.538383  [118400/141921]\n",
      "loss: 0.584196  [121600/141921]\n",
      "loss: 0.411561  [124800/141921]\n",
      "loss: 0.542216  [128000/141921]\n",
      "loss: 0.454589  [131200/141921]\n",
      "loss: 0.490671  [134400/141921]\n",
      "loss: 0.527969  [137600/141921]\n",
      "loss: 0.591740  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.526218 \n",
      "\n",
      "Epoch 19\n",
      "---------------------------\n",
      "loss: 0.576742  [ 3200/141921]\n",
      "loss: 0.446110  [ 6400/141921]\n",
      "loss: 0.452085  [ 9600/141921]\n",
      "loss: 0.484444  [12800/141921]\n",
      "loss: 0.591505  [16000/141921]\n",
      "loss: 0.435797  [19200/141921]\n",
      "loss: 0.483247  [22400/141921]\n",
      "loss: 0.576792  [25600/141921]\n",
      "loss: 0.558532  [28800/141921]\n",
      "loss: 0.478574  [32000/141921]\n",
      "loss: 0.360697  [35200/141921]\n",
      "loss: 0.548777  [38400/141921]\n",
      "loss: 0.591036  [41600/141921]\n",
      "loss: 0.569922  [44800/141921]\n",
      "loss: 0.481979  [48000/141921]\n",
      "loss: 0.587621  [51200/141921]\n",
      "loss: 0.553705  [54400/141921]\n",
      "loss: 0.615499  [57600/141921]\n",
      "loss: 0.675093  [60800/141921]\n",
      "loss: 0.531022  [64000/141921]\n",
      "loss: 0.593432  [67200/141921]\n",
      "loss: 0.611258  [70400/141921]\n",
      "loss: 0.425365  [73600/141921]\n",
      "loss: 0.433572  [76800/141921]\n",
      "loss: 0.637003  [80000/141921]\n",
      "loss: 0.579487  [83200/141921]\n",
      "loss: 0.537395  [86400/141921]\n",
      "loss: 0.441245  [89600/141921]\n",
      "loss: 0.504912  [92800/141921]\n",
      "loss: 0.516627  [96000/141921]\n",
      "loss: 0.407649  [99200/141921]\n",
      "loss: 0.613864  [102400/141921]\n",
      "loss: 0.489723  [105600/141921]\n",
      "loss: 0.489615  [108800/141921]\n",
      "loss: 0.588648  [112000/141921]\n",
      "loss: 0.528272  [115200/141921]\n",
      "loss: 0.506691  [118400/141921]\n",
      "loss: 0.525129  [121600/141921]\n",
      "loss: 0.540098  [124800/141921]\n",
      "loss: 0.539698  [128000/141921]\n",
      "loss: 0.537003  [131200/141921]\n",
      "loss: 0.565275  [134400/141921]\n",
      "loss: 0.562694  [137600/141921]\n",
      "loss: 0.590825  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.523799 \n",
      "\n",
      "Epoch 20\n",
      "---------------------------\n",
      "loss: 0.532157  [ 3200/141921]\n",
      "loss: 0.574328  [ 6400/141921]\n",
      "loss: 0.488673  [ 9600/141921]\n",
      "loss: 0.438425  [12800/141921]\n",
      "loss: 0.620102  [16000/141921]\n",
      "loss: 0.484795  [19200/141921]\n",
      "loss: 0.646651  [22400/141921]\n",
      "loss: 0.463368  [25600/141921]\n",
      "loss: 0.518405  [28800/141921]\n",
      "loss: 0.562518  [32000/141921]\n",
      "loss: 0.682532  [35200/141921]\n",
      "loss: 0.420298  [38400/141921]\n",
      "loss: 0.366975  [41600/141921]\n",
      "loss: 0.347867  [44800/141921]\n",
      "loss: 0.560924  [48000/141921]\n",
      "loss: 0.518994  [51200/141921]\n",
      "loss: 0.473259  [54400/141921]\n",
      "loss: 0.539988  [57600/141921]\n",
      "loss: 0.471989  [60800/141921]\n",
      "loss: 0.452546  [64000/141921]\n",
      "loss: 0.570841  [67200/141921]\n",
      "loss: 0.547944  [70400/141921]\n",
      "loss: 0.369212  [73600/141921]\n",
      "loss: 0.537436  [76800/141921]\n",
      "loss: 0.465210  [80000/141921]\n",
      "loss: 0.515307  [83200/141921]\n",
      "loss: 0.414487  [86400/141921]\n",
      "loss: 0.508122  [89600/141921]\n",
      "loss: 0.525465  [92800/141921]\n",
      "loss: 0.518354  [96000/141921]\n",
      "loss: 0.517370  [99200/141921]\n",
      "loss: 0.543760  [102400/141921]\n",
      "loss: 0.480458  [105600/141921]\n",
      "loss: 0.513610  [108800/141921]\n",
      "loss: 0.443577  [112000/141921]\n",
      "loss: 0.473461  [115200/141921]\n",
      "loss: 0.534123  [118400/141921]\n",
      "loss: 0.623786  [121600/141921]\n",
      "loss: 0.567636  [124800/141921]\n",
      "loss: 0.576542  [128000/141921]\n",
      "loss: 0.460513  [131200/141921]\n",
      "loss: 0.404607  [134400/141921]\n",
      "loss: 0.565593  [137600/141921]\n",
      "loss: 0.546766  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.521873 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(sn_train_dataloader, sn_model, loss_fn, sn_optimizer)\n",
    "    test_loop(sn_test_dataloader, sn_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
