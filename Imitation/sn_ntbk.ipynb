{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75c69788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a02e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for data processing\n",
    "def card_to_num(card):\n",
    "    raw_rank = card[:-1]\n",
    "    \n",
    "    ranks = {\n",
    "        '2' : 0,\n",
    "        '3' : 1,\n",
    "        '4' : 2, \n",
    "        '5' : 3,\n",
    "        '6' : 4, \n",
    "        '7' : 5, \n",
    "        '8' : 6, \n",
    "        '9' : 7, \n",
    "        '10': 8, \n",
    "        'J' : 9, \n",
    "        'Q' : 10, \n",
    "        'K' : 11, \n",
    "        'A': 12\n",
    "    }\n",
    "\n",
    "    return ranks[raw_rank]\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_num(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1222d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_or_not_raw_df = pd.read_csv('CSVs/split_or_not.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb6ad32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned split_or_not\n",
    "split_or_not_raw_df['dealer_upcard'] = split_or_not_raw_df['dealer_upcard'].apply(card_to_num)\n",
    "split_or_not_raw_df['player_hand'] = split_or_not_raw_df['player_hand'].apply(hand_to_list)\n",
    "split_or_not_raw_df['player_hand'] = split_or_not_raw_df['player_hand'].apply(lambda hand: hand[0])\n",
    "split_or_not_df = split_or_not_raw_df.rename(columns = {'player_hand':'player_upcard'})\n",
    "\n",
    "# Turning into tensor matrices\n",
    "# split_or_not\n",
    "x1 = torch.tensor(split_or_not_df['player_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "x2 = torch.tensor(split_or_not_df['dealer_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(split_or_not_df['result'].values, dtype=torch.long)\n",
    "\n",
    "X = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "split_or_not_dataset = Blackjack_Dataset(X,y)\n",
    "train_sn, test_sn = train_test_split(split_or_not_dataset, test_size=0.2) #I might have to do this earlier, on the dataframe, but this was easier so let's see if it works\n",
    "\n",
    "sn_train_dataloader = DataLoader(train_sn, batch_size=batch_size, shuffle=True)\n",
    "sn_test_dataloader = DataLoader(test_sn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dbe5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "659c20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sn_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "sn_model = sn_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "epochs = 40\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sn_optimizer = torch.optim.SGD(sn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e267a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.607666  [ 3200/141921]\n",
      "loss: 0.677519  [ 6400/141921]\n",
      "loss: 0.639975  [ 9600/141921]\n",
      "loss: 0.638349  [12800/141921]\n",
      "loss: 0.624356  [16000/141921]\n",
      "loss: 0.471034  [19200/141921]\n",
      "loss: 0.504350  [22400/141921]\n",
      "loss: 0.669323  [25600/141921]\n",
      "loss: 0.648874  [28800/141921]\n",
      "loss: 0.561185  [32000/141921]\n",
      "loss: 0.522850  [35200/141921]\n",
      "loss: 0.549966  [38400/141921]\n",
      "loss: 0.583802  [41600/141921]\n",
      "loss: 0.521195  [44800/141921]\n",
      "loss: 0.529299  [48000/141921]\n",
      "loss: 0.689095  [51200/141921]\n",
      "loss: 0.747541  [54400/141921]\n",
      "loss: 0.552631  [57600/141921]\n",
      "loss: 0.692064  [60800/141921]\n",
      "loss: 0.605258  [64000/141921]\n",
      "loss: 0.613597  [67200/141921]\n",
      "loss: 0.753210  [70400/141921]\n",
      "loss: 0.734524  [73600/141921]\n",
      "loss: 0.602014  [76800/141921]\n",
      "loss: 0.500730  [80000/141921]\n",
      "loss: 0.539983  [83200/141921]\n",
      "loss: 0.611796  [86400/141921]\n",
      "loss: 0.661549  [89600/141921]\n",
      "loss: 0.532733  [92800/141921]\n",
      "loss: 0.508947  [96000/141921]\n",
      "loss: 0.547642  [99200/141921]\n",
      "loss: 0.535705  [102400/141921]\n",
      "loss: 0.684432  [105600/141921]\n",
      "loss: 0.603704  [108800/141921]\n",
      "loss: 0.690698  [112000/141921]\n",
      "loss: 0.577579  [115200/141921]\n",
      "loss: 0.518713  [118400/141921]\n",
      "loss: 0.606906  [121600/141921]\n",
      "loss: 0.630326  [124800/141921]\n",
      "loss: 0.518184  [128000/141921]\n",
      "loss: 0.520174  [131200/141921]\n",
      "loss: 0.516157  [134400/141921]\n",
      "loss: 0.450155  [137600/141921]\n",
      "loss: 0.588417  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.572697 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 0.453234  [ 3200/141921]\n",
      "loss: 0.494999  [ 6400/141921]\n",
      "loss: 0.586927  [ 9600/141921]\n",
      "loss: 0.536307  [12800/141921]\n",
      "loss: 0.555078  [16000/141921]\n",
      "loss: 0.511639  [19200/141921]\n",
      "loss: 0.463571  [22400/141921]\n",
      "loss: 0.593449  [25600/141921]\n",
      "loss: 0.565380  [28800/141921]\n",
      "loss: 0.456625  [32000/141921]\n",
      "loss: 0.559570  [35200/141921]\n",
      "loss: 0.671312  [38400/141921]\n",
      "loss: 0.568804  [41600/141921]\n",
      "loss: 0.551002  [44800/141921]\n",
      "loss: 0.616368  [48000/141921]\n",
      "loss: 0.639370  [51200/141921]\n",
      "loss: 0.604111  [54400/141921]\n",
      "loss: 0.575028  [57600/141921]\n",
      "loss: 0.654954  [60800/141921]\n",
      "loss: 0.514900  [64000/141921]\n",
      "loss: 0.511553  [67200/141921]\n",
      "loss: 0.588523  [70400/141921]\n",
      "loss: 0.562972  [73600/141921]\n",
      "loss: 0.641814  [76800/141921]\n",
      "loss: 0.539244  [80000/141921]\n",
      "loss: 0.731953  [83200/141921]\n",
      "loss: 0.559476  [86400/141921]\n",
      "loss: 0.599807  [89600/141921]\n",
      "loss: 0.525163  [92800/141921]\n",
      "loss: 0.502106  [96000/141921]\n",
      "loss: 0.558257  [99200/141921]\n",
      "loss: 0.651344  [102400/141921]\n",
      "loss: 0.622809  [105600/141921]\n",
      "loss: 0.572990  [108800/141921]\n",
      "loss: 0.506430  [112000/141921]\n",
      "loss: 0.550957  [115200/141921]\n",
      "loss: 0.636285  [118400/141921]\n",
      "loss: 0.609339  [121600/141921]\n",
      "loss: 0.632419  [124800/141921]\n",
      "loss: 0.483969  [128000/141921]\n",
      "loss: 0.647223  [131200/141921]\n",
      "loss: 0.583614  [134400/141921]\n",
      "loss: 0.495308  [137600/141921]\n",
      "loss: 0.579539  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.561396 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 0.546990  [ 3200/141921]\n",
      "loss: 0.602124  [ 6400/141921]\n",
      "loss: 0.552850  [ 9600/141921]\n",
      "loss: 0.662336  [12800/141921]\n",
      "loss: 0.525192  [16000/141921]\n",
      "loss: 0.598865  [19200/141921]\n",
      "loss: 0.531668  [22400/141921]\n",
      "loss: 0.567661  [25600/141921]\n",
      "loss: 0.600346  [28800/141921]\n",
      "loss: 0.530091  [32000/141921]\n",
      "loss: 0.390195  [35200/141921]\n",
      "loss: 0.536061  [38400/141921]\n",
      "loss: 0.511212  [41600/141921]\n",
      "loss: 0.531739  [44800/141921]\n",
      "loss: 0.603110  [48000/141921]\n",
      "loss: 0.506788  [51200/141921]\n",
      "loss: 0.457138  [54400/141921]\n",
      "loss: 0.591977  [57600/141921]\n",
      "loss: 0.752038  [60800/141921]\n",
      "loss: 0.544042  [64000/141921]\n",
      "loss: 0.590503  [67200/141921]\n",
      "loss: 0.525331  [70400/141921]\n",
      "loss: 0.678027  [73600/141921]\n",
      "loss: 0.628443  [76800/141921]\n",
      "loss: 0.499557  [80000/141921]\n",
      "loss: 0.601483  [83200/141921]\n",
      "loss: 0.575950  [86400/141921]\n",
      "loss: 0.699510  [89600/141921]\n",
      "loss: 0.627091  [92800/141921]\n",
      "loss: 0.492558  [96000/141921]\n",
      "loss: 0.640595  [99200/141921]\n",
      "loss: 0.561565  [102400/141921]\n",
      "loss: 0.595154  [105600/141921]\n",
      "loss: 0.477119  [108800/141921]\n",
      "loss: 0.609745  [112000/141921]\n",
      "loss: 0.653298  [115200/141921]\n",
      "loss: 0.560653  [118400/141921]\n",
      "loss: 0.539546  [121600/141921]\n",
      "loss: 0.558144  [124800/141921]\n",
      "loss: 0.609466  [128000/141921]\n",
      "loss: 0.727449  [131200/141921]\n",
      "loss: 0.454763  [134400/141921]\n",
      "loss: 0.495298  [137600/141921]\n",
      "loss: 0.579152  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.556084 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 0.574361  [ 3200/141921]\n",
      "loss: 0.530480  [ 6400/141921]\n",
      "loss: 0.484484  [ 9600/141921]\n",
      "loss: 0.666012  [12800/141921]\n",
      "loss: 0.541699  [16000/141921]\n",
      "loss: 0.579154  [19200/141921]\n",
      "loss: 0.685384  [22400/141921]\n",
      "loss: 0.510202  [25600/141921]\n",
      "loss: 0.529166  [28800/141921]\n",
      "loss: 0.665360  [32000/141921]\n",
      "loss: 0.628286  [35200/141921]\n",
      "loss: 0.549905  [38400/141921]\n",
      "loss: 0.647813  [41600/141921]\n",
      "loss: 0.771202  [44800/141921]\n",
      "loss: 0.860556  [48000/141921]\n",
      "loss: 0.604747  [51200/141921]\n",
      "loss: 0.573539  [54400/141921]\n",
      "loss: 0.535127  [57600/141921]\n",
      "loss: 0.429410  [60800/141921]\n",
      "loss: 0.562684  [64000/141921]\n",
      "loss: 0.568136  [67200/141921]\n",
      "loss: 0.631773  [70400/141921]\n",
      "loss: 0.562432  [73600/141921]\n",
      "loss: 0.626138  [76800/141921]\n",
      "loss: 0.606126  [80000/141921]\n",
      "loss: 0.683975  [83200/141921]\n",
      "loss: 0.668997  [86400/141921]\n",
      "loss: 0.719134  [89600/141921]\n",
      "loss: 0.606979  [92800/141921]\n",
      "loss: 0.664286  [96000/141921]\n",
      "loss: 0.545921  [99200/141921]\n",
      "loss: 0.624265  [102400/141921]\n",
      "loss: 0.655407  [105600/141921]\n",
      "loss: 0.598567  [108800/141921]\n",
      "loss: 0.562851  [112000/141921]\n",
      "loss: 0.491863  [115200/141921]\n",
      "loss: 0.581674  [118400/141921]\n",
      "loss: 0.449813  [121600/141921]\n",
      "loss: 0.565877  [124800/141921]\n",
      "loss: 0.529733  [128000/141921]\n",
      "loss: 0.428555  [131200/141921]\n",
      "loss: 0.581659  [134400/141921]\n",
      "loss: 0.581300  [137600/141921]\n",
      "loss: 0.556963  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.551006 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 0.521903  [ 3200/141921]\n",
      "loss: 0.421216  [ 6400/141921]\n",
      "loss: 0.561772  [ 9600/141921]\n",
      "loss: 0.518030  [12800/141921]\n",
      "loss: 0.674239  [16000/141921]\n",
      "loss: 0.535749  [19200/141921]\n",
      "loss: 0.626401  [22400/141921]\n",
      "loss: 0.726978  [25600/141921]\n",
      "loss: 0.538393  [28800/141921]\n",
      "loss: 0.557298  [32000/141921]\n",
      "loss: 0.480906  [35200/141921]\n",
      "loss: 0.545329  [38400/141921]\n",
      "loss: 0.481000  [41600/141921]\n",
      "loss: 0.522005  [44800/141921]\n",
      "loss: 0.654894  [48000/141921]\n",
      "loss: 0.517760  [51200/141921]\n",
      "loss: 0.456730  [54400/141921]\n",
      "loss: 0.557866  [57600/141921]\n",
      "loss: 0.605897  [60800/141921]\n",
      "loss: 0.546814  [64000/141921]\n",
      "loss: 0.535618  [67200/141921]\n",
      "loss: 0.570295  [70400/141921]\n",
      "loss: 0.597215  [73600/141921]\n",
      "loss: 0.715349  [76800/141921]\n",
      "loss: 0.526170  [80000/141921]\n",
      "loss: 0.746111  [83200/141921]\n",
      "loss: 0.539400  [86400/141921]\n",
      "loss: 0.485910  [89600/141921]\n",
      "loss: 0.519603  [92800/141921]\n",
      "loss: 0.569550  [96000/141921]\n",
      "loss: 0.609250  [99200/141921]\n",
      "loss: 0.484068  [102400/141921]\n",
      "loss: 0.540615  [105600/141921]\n",
      "loss: 0.538283  [108800/141921]\n",
      "loss: 0.542607  [112000/141921]\n",
      "loss: 0.507638  [115200/141921]\n",
      "loss: 0.471517  [118400/141921]\n",
      "loss: 0.468861  [121600/141921]\n",
      "loss: 0.629507  [124800/141921]\n",
      "loss: 0.540484  [128000/141921]\n",
      "loss: 0.577859  [131200/141921]\n",
      "loss: 0.558298  [134400/141921]\n",
      "loss: 0.517163  [137600/141921]\n",
      "loss: 0.615832  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.549019 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 0.623474  [ 3200/141921]\n",
      "loss: 0.542370  [ 6400/141921]\n",
      "loss: 0.429146  [ 9600/141921]\n",
      "loss: 0.491377  [12800/141921]\n",
      "loss: 0.564134  [16000/141921]\n",
      "loss: 0.562871  [19200/141921]\n",
      "loss: 0.548346  [22400/141921]\n",
      "loss: 0.550700  [25600/141921]\n",
      "loss: 0.489223  [28800/141921]\n",
      "loss: 0.353295  [32000/141921]\n",
      "loss: 0.617091  [35200/141921]\n",
      "loss: 0.485316  [38400/141921]\n",
      "loss: 0.536833  [41600/141921]\n",
      "loss: 0.568389  [44800/141921]\n",
      "loss: 0.500494  [48000/141921]\n",
      "loss: 0.606557  [51200/141921]\n",
      "loss: 0.733709  [54400/141921]\n",
      "loss: 0.562784  [57600/141921]\n",
      "loss: 0.554405  [60800/141921]\n",
      "loss: 0.543893  [64000/141921]\n",
      "loss: 0.419854  [67200/141921]\n",
      "loss: 0.446024  [70400/141921]\n",
      "loss: 0.499306  [73600/141921]\n",
      "loss: 0.656607  [76800/141921]\n",
      "loss: 0.598508  [80000/141921]\n",
      "loss: 0.569650  [83200/141921]\n",
      "loss: 0.567295  [86400/141921]\n",
      "loss: 0.574667  [89600/141921]\n",
      "loss: 0.545688  [92800/141921]\n",
      "loss: 0.590217  [96000/141921]\n",
      "loss: 0.534002  [99200/141921]\n",
      "loss: 0.563608  [102400/141921]\n",
      "loss: 0.590200  [105600/141921]\n",
      "loss: 0.491669  [108800/141921]\n",
      "loss: 0.545708  [112000/141921]\n",
      "loss: 0.560679  [115200/141921]\n",
      "loss: 0.578079  [118400/141921]\n",
      "loss: 0.507380  [121600/141921]\n",
      "loss: 0.478842  [124800/141921]\n",
      "loss: 0.434205  [128000/141921]\n",
      "loss: 0.473234  [131200/141921]\n",
      "loss: 0.546992  [134400/141921]\n",
      "loss: 0.717625  [137600/141921]\n",
      "loss: 0.563657  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.547028 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 0.522106  [ 3200/141921]\n",
      "loss: 0.540685  [ 6400/141921]\n",
      "loss: 0.453114  [ 9600/141921]\n",
      "loss: 0.458561  [12800/141921]\n",
      "loss: 0.433264  [16000/141921]\n",
      "loss: 0.703302  [19200/141921]\n",
      "loss: 0.420127  [22400/141921]\n",
      "loss: 0.544036  [25600/141921]\n",
      "loss: 0.463771  [28800/141921]\n",
      "loss: 0.501487  [32000/141921]\n",
      "loss: 0.546851  [35200/141921]\n",
      "loss: 0.414367  [38400/141921]\n",
      "loss: 0.595926  [41600/141921]\n",
      "loss: 0.631482  [44800/141921]\n",
      "loss: 0.391108  [48000/141921]\n",
      "loss: 0.413271  [51200/141921]\n",
      "loss: 0.547861  [54400/141921]\n",
      "loss: 0.424840  [57600/141921]\n",
      "loss: 0.586766  [60800/141921]\n",
      "loss: 0.611750  [64000/141921]\n",
      "loss: 0.515648  [67200/141921]\n",
      "loss: 0.635622  [70400/141921]\n",
      "loss: 0.551878  [73600/141921]\n",
      "loss: 0.428706  [76800/141921]\n",
      "loss: 0.577201  [80000/141921]\n",
      "loss: 0.523651  [83200/141921]\n",
      "loss: 0.755499  [86400/141921]\n",
      "loss: 0.502302  [89600/141921]\n",
      "loss: 0.488094  [92800/141921]\n",
      "loss: 0.534520  [96000/141921]\n",
      "loss: 0.714440  [99200/141921]\n",
      "loss: 0.583357  [102400/141921]\n",
      "loss: 0.667045  [105600/141921]\n",
      "loss: 0.600681  [108800/141921]\n",
      "loss: 0.388659  [112000/141921]\n",
      "loss: 0.470366  [115200/141921]\n",
      "loss: 0.588331  [118400/141921]\n",
      "loss: 0.446142  [121600/141921]\n",
      "loss: 0.722261  [124800/141921]\n",
      "loss: 0.525583  [128000/141921]\n",
      "loss: 0.519031  [131200/141921]\n",
      "loss: 0.561220  [134400/141921]\n",
      "loss: 0.599547  [137600/141921]\n",
      "loss: 0.622983  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.545252 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 0.600048  [ 3200/141921]\n",
      "loss: 0.499177  [ 6400/141921]\n",
      "loss: 0.536002  [ 9600/141921]\n",
      "loss: 0.603996  [12800/141921]\n",
      "loss: 0.606634  [16000/141921]\n",
      "loss: 0.585286  [19200/141921]\n",
      "loss: 0.449558  [22400/141921]\n",
      "loss: 0.581757  [25600/141921]\n",
      "loss: 0.516557  [28800/141921]\n",
      "loss: 0.531175  [32000/141921]\n",
      "loss: 0.573365  [35200/141921]\n",
      "loss: 0.454302  [38400/141921]\n",
      "loss: 0.624137  [41600/141921]\n",
      "loss: 0.405164  [44800/141921]\n",
      "loss: 0.465026  [48000/141921]\n",
      "loss: 0.462569  [51200/141921]\n",
      "loss: 0.611591  [54400/141921]\n",
      "loss: 0.556384  [57600/141921]\n",
      "loss: 0.673704  [60800/141921]\n",
      "loss: 0.645067  [64000/141921]\n",
      "loss: 0.504981  [67200/141921]\n",
      "loss: 0.443608  [70400/141921]\n",
      "loss: 0.573674  [73600/141921]\n",
      "loss: 0.402008  [76800/141921]\n",
      "loss: 0.557814  [80000/141921]\n",
      "loss: 0.572448  [83200/141921]\n",
      "loss: 0.506873  [86400/141921]\n",
      "loss: 0.592772  [89600/141921]\n",
      "loss: 0.568286  [92800/141921]\n",
      "loss: 0.625952  [96000/141921]\n",
      "loss: 0.543464  [99200/141921]\n",
      "loss: 0.428569  [102400/141921]\n",
      "loss: 0.482143  [105600/141921]\n",
      "loss: 0.636536  [108800/141921]\n",
      "loss: 0.462515  [112000/141921]\n",
      "loss: 0.628560  [115200/141921]\n",
      "loss: 0.570128  [118400/141921]\n",
      "loss: 0.530215  [121600/141921]\n",
      "loss: 0.509268  [124800/141921]\n",
      "loss: 0.629878  [128000/141921]\n",
      "loss: 0.529442  [131200/141921]\n",
      "loss: 0.542819  [134400/141921]\n",
      "loss: 0.476560  [137600/141921]\n",
      "loss: 0.527197  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.543979 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 0.580770  [ 3200/141921]\n",
      "loss: 0.712110  [ 6400/141921]\n",
      "loss: 0.533239  [ 9600/141921]\n",
      "loss: 0.464681  [12800/141921]\n",
      "loss: 0.556257  [16000/141921]\n",
      "loss: 0.585727  [19200/141921]\n",
      "loss: 0.635166  [22400/141921]\n",
      "loss: 0.404141  [25600/141921]\n",
      "loss: 0.399607  [28800/141921]\n",
      "loss: 0.521198  [32000/141921]\n",
      "loss: 0.472157  [35200/141921]\n",
      "loss: 0.515339  [38400/141921]\n",
      "loss: 0.518415  [41600/141921]\n",
      "loss: 0.546348  [44800/141921]\n",
      "loss: 0.482546  [48000/141921]\n",
      "loss: 0.476571  [51200/141921]\n",
      "loss: 0.701347  [54400/141921]\n",
      "loss: 0.559910  [57600/141921]\n",
      "loss: 0.474264  [60800/141921]\n",
      "loss: 0.433755  [64000/141921]\n",
      "loss: 0.508376  [67200/141921]\n",
      "loss: 0.686769  [70400/141921]\n",
      "loss: 0.624676  [73600/141921]\n",
      "loss: 0.480005  [76800/141921]\n",
      "loss: 0.643355  [80000/141921]\n",
      "loss: 0.484015  [83200/141921]\n",
      "loss: 0.526780  [86400/141921]\n",
      "loss: 0.503582  [89600/141921]\n",
      "loss: 0.502968  [92800/141921]\n",
      "loss: 0.633673  [96000/141921]\n",
      "loss: 0.461220  [99200/141921]\n",
      "loss: 0.770307  [102400/141921]\n",
      "loss: 0.649125  [105600/141921]\n",
      "loss: 0.631943  [108800/141921]\n",
      "loss: 0.483804  [112000/141921]\n",
      "loss: 0.599510  [115200/141921]\n",
      "loss: 0.726852  [118400/141921]\n",
      "loss: 0.527047  [121600/141921]\n",
      "loss: 0.533559  [124800/141921]\n",
      "loss: 0.501186  [128000/141921]\n",
      "loss: 0.484335  [131200/141921]\n",
      "loss: 0.493103  [134400/141921]\n",
      "loss: 0.571602  [137600/141921]\n",
      "loss: 0.496420  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.542035 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 0.724590  [ 3200/141921]\n",
      "loss: 0.534916  [ 6400/141921]\n",
      "loss: 0.387943  [ 9600/141921]\n",
      "loss: 0.404017  [12800/141921]\n",
      "loss: 0.468043  [16000/141921]\n",
      "loss: 0.551497  [19200/141921]\n",
      "loss: 0.791961  [22400/141921]\n",
      "loss: 0.482223  [25600/141921]\n",
      "loss: 0.487206  [28800/141921]\n",
      "loss: 0.428667  [32000/141921]\n",
      "loss: 0.472075  [35200/141921]\n",
      "loss: 0.509194  [38400/141921]\n",
      "loss: 0.650109  [41600/141921]\n",
      "loss: 0.503461  [44800/141921]\n",
      "loss: 0.536270  [48000/141921]\n",
      "loss: 0.419905  [51200/141921]\n",
      "loss: 0.517904  [54400/141921]\n",
      "loss: 0.454291  [57600/141921]\n",
      "loss: 0.701045  [60800/141921]\n",
      "loss: 0.565712  [64000/141921]\n",
      "loss: 0.680098  [67200/141921]\n",
      "loss: 0.417913  [70400/141921]\n",
      "loss: 0.492077  [73600/141921]\n",
      "loss: 0.548647  [76800/141921]\n",
      "loss: 0.647578  [80000/141921]\n",
      "loss: 0.449817  [83200/141921]\n",
      "loss: 0.559768  [86400/141921]\n",
      "loss: 0.650012  [89600/141921]\n",
      "loss: 0.415587  [92800/141921]\n",
      "loss: 0.508202  [96000/141921]\n",
      "loss: 0.492460  [99200/141921]\n",
      "loss: 0.516818  [102400/141921]\n",
      "loss: 0.431456  [105600/141921]\n",
      "loss: 0.457568  [108800/141921]\n",
      "loss: 0.522759  [112000/141921]\n",
      "loss: 0.515406  [115200/141921]\n",
      "loss: 0.465216  [118400/141921]\n",
      "loss: 0.517339  [121600/141921]\n",
      "loss: 0.452760  [124800/141921]\n",
      "loss: 0.464389  [128000/141921]\n",
      "loss: 0.541553  [131200/141921]\n",
      "loss: 0.576761  [134400/141921]\n",
      "loss: 0.661275  [137600/141921]\n",
      "loss: 0.622067  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.540129 \n",
      "\n",
      "Epoch 11\n",
      "---------------------------\n",
      "loss: 0.571379  [ 3200/141921]\n",
      "loss: 0.666387  [ 6400/141921]\n",
      "loss: 0.547067  [ 9600/141921]\n",
      "loss: 0.581063  [12800/141921]\n",
      "loss: 0.517352  [16000/141921]\n",
      "loss: 0.647130  [19200/141921]\n",
      "loss: 0.537646  [22400/141921]\n",
      "loss: 0.559605  [25600/141921]\n",
      "loss: 0.638238  [28800/141921]\n",
      "loss: 0.530964  [32000/141921]\n",
      "loss: 0.590706  [35200/141921]\n",
      "loss: 0.525778  [38400/141921]\n",
      "loss: 0.532720  [41600/141921]\n",
      "loss: 0.637843  [44800/141921]\n",
      "loss: 0.500744  [48000/141921]\n",
      "loss: 0.510965  [51200/141921]\n",
      "loss: 0.506641  [54400/141921]\n",
      "loss: 0.537964  [57600/141921]\n",
      "loss: 0.637814  [60800/141921]\n",
      "loss: 0.549425  [64000/141921]\n",
      "loss: 0.671321  [67200/141921]\n",
      "loss: 0.595462  [70400/141921]\n",
      "loss: 0.673168  [73600/141921]\n",
      "loss: 0.639756  [76800/141921]\n",
      "loss: 0.490428  [80000/141921]\n",
      "loss: 0.488282  [83200/141921]\n",
      "loss: 0.400106  [86400/141921]\n",
      "loss: 0.591271  [89600/141921]\n",
      "loss: 0.514268  [92800/141921]\n",
      "loss: 0.679406  [96000/141921]\n",
      "loss: 0.583754  [99200/141921]\n",
      "loss: 0.561197  [102400/141921]\n",
      "loss: 0.559451  [105600/141921]\n",
      "loss: 0.507096  [108800/141921]\n",
      "loss: 0.495546  [112000/141921]\n",
      "loss: 0.652896  [115200/141921]\n",
      "loss: 0.564282  [118400/141921]\n",
      "loss: 0.490855  [121600/141921]\n",
      "loss: 0.504258  [124800/141921]\n",
      "loss: 0.481228  [128000/141921]\n",
      "loss: 0.580433  [131200/141921]\n",
      "loss: 0.517919  [134400/141921]\n",
      "loss: 0.455336  [137600/141921]\n",
      "loss: 0.630832  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.542223 \n",
      "\n",
      "Epoch 12\n",
      "---------------------------\n",
      "loss: 0.460394  [ 3200/141921]\n",
      "loss: 0.518931  [ 6400/141921]\n",
      "loss: 0.530431  [ 9600/141921]\n",
      "loss: 0.657971  [12800/141921]\n",
      "loss: 0.618825  [16000/141921]\n",
      "loss: 0.761412  [19200/141921]\n",
      "loss: 0.480514  [22400/141921]\n",
      "loss: 0.450356  [25600/141921]\n",
      "loss: 0.620257  [28800/141921]\n",
      "loss: 0.560416  [32000/141921]\n",
      "loss: 0.562023  [35200/141921]\n",
      "loss: 0.501604  [38400/141921]\n",
      "loss: 0.613723  [41600/141921]\n",
      "loss: 0.572205  [44800/141921]\n",
      "loss: 0.463091  [48000/141921]\n",
      "loss: 0.580906  [51200/141921]\n",
      "loss: 0.506768  [54400/141921]\n",
      "loss: 0.521847  [57600/141921]\n",
      "loss: 0.445669  [60800/141921]\n",
      "loss: 0.496700  [64000/141921]\n",
      "loss: 0.532796  [67200/141921]\n",
      "loss: 0.475120  [70400/141921]\n",
      "loss: 0.554254  [73600/141921]\n",
      "loss: 0.563620  [76800/141921]\n",
      "loss: 0.508875  [80000/141921]\n",
      "loss: 0.361254  [83200/141921]\n",
      "loss: 0.497426  [86400/141921]\n",
      "loss: 0.411552  [89600/141921]\n",
      "loss: 0.511556  [92800/141921]\n",
      "loss: 0.627486  [96000/141921]\n",
      "loss: 0.516620  [99200/141921]\n",
      "loss: 0.536102  [102400/141921]\n",
      "loss: 0.543046  [105600/141921]\n",
      "loss: 0.622752  [108800/141921]\n",
      "loss: 0.577817  [112000/141921]\n",
      "loss: 0.449168  [115200/141921]\n",
      "loss: 0.662770  [118400/141921]\n",
      "loss: 0.633761  [121600/141921]\n",
      "loss: 0.562269  [124800/141921]\n",
      "loss: 0.617342  [128000/141921]\n",
      "loss: 0.442681  [131200/141921]\n",
      "loss: 0.677255  [134400/141921]\n",
      "loss: 0.552204  [137600/141921]\n",
      "loss: 0.600629  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.538975 \n",
      "\n",
      "Epoch 13\n",
      "---------------------------\n",
      "loss: 0.532858  [ 3200/141921]\n",
      "loss: 0.499131  [ 6400/141921]\n",
      "loss: 0.543335  [ 9600/141921]\n",
      "loss: 0.455120  [12800/141921]\n",
      "loss: 0.599499  [16000/141921]\n",
      "loss: 0.578659  [19200/141921]\n",
      "loss: 0.550401  [22400/141921]\n",
      "loss: 0.471210  [25600/141921]\n",
      "loss: 0.457681  [28800/141921]\n",
      "loss: 0.467361  [32000/141921]\n",
      "loss: 0.644160  [35200/141921]\n",
      "loss: 0.517276  [38400/141921]\n",
      "loss: 0.516871  [41600/141921]\n",
      "loss: 0.688657  [44800/141921]\n",
      "loss: 0.633040  [48000/141921]\n",
      "loss: 0.387504  [51200/141921]\n",
      "loss: 0.525286  [54400/141921]\n",
      "loss: 0.464555  [57600/141921]\n",
      "loss: 0.392505  [60800/141921]\n",
      "loss: 0.529157  [64000/141921]\n",
      "loss: 0.567819  [67200/141921]\n",
      "loss: 0.410852  [70400/141921]\n",
      "loss: 0.504494  [73600/141921]\n",
      "loss: 0.552829  [76800/141921]\n",
      "loss: 0.548913  [80000/141921]\n",
      "loss: 0.514386  [83200/141921]\n",
      "loss: 0.499431  [86400/141921]\n",
      "loss: 0.648517  [89600/141921]\n",
      "loss: 0.487349  [92800/141921]\n",
      "loss: 0.656366  [96000/141921]\n",
      "loss: 0.551454  [99200/141921]\n",
      "loss: 0.581193  [102400/141921]\n",
      "loss: 0.546684  [105600/141921]\n",
      "loss: 0.494793  [108800/141921]\n",
      "loss: 0.660425  [112000/141921]\n",
      "loss: 0.469080  [115200/141921]\n",
      "loss: 0.572582  [118400/141921]\n",
      "loss: 0.515872  [121600/141921]\n",
      "loss: 0.559389  [124800/141921]\n",
      "loss: 0.530088  [128000/141921]\n",
      "loss: 0.506652  [131200/141921]\n",
      "loss: 0.570142  [134400/141921]\n",
      "loss: 0.564933  [137600/141921]\n",
      "loss: 0.538076  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.534076 \n",
      "\n",
      "Epoch 14\n",
      "---------------------------\n",
      "loss: 0.554111  [ 3200/141921]\n",
      "loss: 0.502465  [ 6400/141921]\n",
      "loss: 0.690290  [ 9600/141921]\n",
      "loss: 0.603027  [12800/141921]\n",
      "loss: 0.426265  [16000/141921]\n",
      "loss: 0.420877  [19200/141921]\n",
      "loss: 0.609798  [22400/141921]\n",
      "loss: 0.672975  [25600/141921]\n",
      "loss: 0.659978  [28800/141921]\n",
      "loss: 0.501088  [32000/141921]\n",
      "loss: 0.411405  [35200/141921]\n",
      "loss: 0.525887  [38400/141921]\n",
      "loss: 0.469191  [41600/141921]\n",
      "loss: 0.417688  [44800/141921]\n",
      "loss: 0.637338  [48000/141921]\n",
      "loss: 0.526531  [51200/141921]\n",
      "loss: 0.436625  [54400/141921]\n",
      "loss: 0.540992  [57600/141921]\n",
      "loss: 0.456233  [60800/141921]\n",
      "loss: 0.575883  [64000/141921]\n",
      "loss: 0.538098  [67200/141921]\n",
      "loss: 0.508625  [70400/141921]\n",
      "loss: 0.631171  [73600/141921]\n",
      "loss: 0.522450  [76800/141921]\n",
      "loss: 0.487808  [80000/141921]\n",
      "loss: 0.658900  [83200/141921]\n",
      "loss: 0.455040  [86400/141921]\n",
      "loss: 0.632674  [89600/141921]\n",
      "loss: 0.478557  [92800/141921]\n",
      "loss: 0.466817  [96000/141921]\n",
      "loss: 0.518387  [99200/141921]\n",
      "loss: 0.600119  [102400/141921]\n",
      "loss: 0.603549  [105600/141921]\n",
      "loss: 0.498026  [108800/141921]\n",
      "loss: 0.385906  [112000/141921]\n",
      "loss: 0.486298  [115200/141921]\n",
      "loss: 0.489684  [118400/141921]\n",
      "loss: 0.573702  [121600/141921]\n",
      "loss: 0.609935  [124800/141921]\n",
      "loss: 0.428875  [128000/141921]\n",
      "loss: 0.675551  [131200/141921]\n",
      "loss: 0.506299  [134400/141921]\n",
      "loss: 0.539095  [137600/141921]\n",
      "loss: 0.423390  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.531236 \n",
      "\n",
      "Epoch 15\n",
      "---------------------------\n",
      "loss: 0.633909  [ 3200/141921]\n",
      "loss: 0.468294  [ 6400/141921]\n",
      "loss: 0.550000  [ 9600/141921]\n",
      "loss: 0.657189  [12800/141921]\n",
      "loss: 0.708014  [16000/141921]\n",
      "loss: 0.526882  [19200/141921]\n",
      "loss: 0.548431  [22400/141921]\n",
      "loss: 0.454341  [25600/141921]\n",
      "loss: 0.627427  [28800/141921]\n",
      "loss: 0.522610  [32000/141921]\n",
      "loss: 0.593368  [35200/141921]\n",
      "loss: 0.534572  [38400/141921]\n",
      "loss: 0.554106  [41600/141921]\n",
      "loss: 0.560552  [44800/141921]\n",
      "loss: 0.687352  [48000/141921]\n",
      "loss: 0.523968  [51200/141921]\n",
      "loss: 0.583822  [54400/141921]\n",
      "loss: 0.634675  [57600/141921]\n",
      "loss: 0.495292  [60800/141921]\n",
      "loss: 0.547033  [64000/141921]\n",
      "loss: 0.476847  [67200/141921]\n",
      "loss: 0.530797  [70400/141921]\n",
      "loss: 0.562547  [73600/141921]\n",
      "loss: 0.533491  [76800/141921]\n",
      "loss: 0.472297  [80000/141921]\n",
      "loss: 0.546039  [83200/141921]\n",
      "loss: 0.539033  [86400/141921]\n",
      "loss: 0.715398  [89600/141921]\n",
      "loss: 0.488889  [92800/141921]\n",
      "loss: 0.618368  [96000/141921]\n",
      "loss: 0.475158  [99200/141921]\n",
      "loss: 0.534097  [102400/141921]\n",
      "loss: 0.647610  [105600/141921]\n",
      "loss: 0.470876  [108800/141921]\n",
      "loss: 0.709581  [112000/141921]\n",
      "loss: 0.385501  [115200/141921]\n",
      "loss: 0.643086  [118400/141921]\n",
      "loss: 0.561436  [121600/141921]\n",
      "loss: 0.678986  [124800/141921]\n",
      "loss: 0.513118  [128000/141921]\n",
      "loss: 0.509666  [131200/141921]\n",
      "loss: 0.514574  [134400/141921]\n",
      "loss: 0.440331  [137600/141921]\n",
      "loss: 0.473238  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.528815 \n",
      "\n",
      "Epoch 16\n",
      "---------------------------\n",
      "loss: 0.428532  [ 3200/141921]\n",
      "loss: 0.525225  [ 6400/141921]\n",
      "loss: 0.691906  [ 9600/141921]\n",
      "loss: 0.555252  [12800/141921]\n",
      "loss: 0.439906  [16000/141921]\n",
      "loss: 0.490898  [19200/141921]\n",
      "loss: 0.580062  [22400/141921]\n",
      "loss: 0.632272  [25600/141921]\n",
      "loss: 0.545986  [28800/141921]\n",
      "loss: 0.666767  [32000/141921]\n",
      "loss: 0.496537  [35200/141921]\n",
      "loss: 0.517897  [38400/141921]\n",
      "loss: 0.553320  [41600/141921]\n",
      "loss: 0.501232  [44800/141921]\n",
      "loss: 0.466747  [48000/141921]\n",
      "loss: 0.628961  [51200/141921]\n",
      "loss: 0.654525  [54400/141921]\n",
      "loss: 0.504940  [57600/141921]\n",
      "loss: 0.485467  [60800/141921]\n",
      "loss: 0.506110  [64000/141921]\n",
      "loss: 0.524017  [67200/141921]\n",
      "loss: 0.650488  [70400/141921]\n",
      "loss: 0.469868  [73600/141921]\n",
      "loss: 0.675808  [76800/141921]\n",
      "loss: 0.646005  [80000/141921]\n",
      "loss: 0.530010  [83200/141921]\n",
      "loss: 0.405044  [86400/141921]\n",
      "loss: 0.461146  [89600/141921]\n",
      "loss: 0.591537  [92800/141921]\n",
      "loss: 0.514924  [96000/141921]\n",
      "loss: 0.501146  [99200/141921]\n",
      "loss: 0.565572  [102400/141921]\n",
      "loss: 0.375719  [105600/141921]\n",
      "loss: 0.535593  [108800/141921]\n",
      "loss: 0.631106  [112000/141921]\n",
      "loss: 0.545967  [115200/141921]\n",
      "loss: 0.625921  [118400/141921]\n",
      "loss: 0.344221  [121600/141921]\n",
      "loss: 0.497062  [124800/141921]\n",
      "loss: 0.425130  [128000/141921]\n",
      "loss: 0.798140  [131200/141921]\n",
      "loss: 0.593322  [134400/141921]\n",
      "loss: 0.589606  [137600/141921]\n",
      "loss: 0.567364  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.525300 \n",
      "\n",
      "Epoch 17\n",
      "---------------------------\n",
      "loss: 0.562747  [ 3200/141921]\n",
      "loss: 0.632921  [ 6400/141921]\n",
      "loss: 0.571397  [ 9600/141921]\n",
      "loss: 0.558847  [12800/141921]\n",
      "loss: 0.616402  [16000/141921]\n",
      "loss: 0.610528  [19200/141921]\n",
      "loss: 0.640529  [22400/141921]\n",
      "loss: 0.530234  [25600/141921]\n",
      "loss: 0.475215  [28800/141921]\n",
      "loss: 0.432770  [32000/141921]\n",
      "loss: 0.473181  [35200/141921]\n",
      "loss: 0.539484  [38400/141921]\n",
      "loss: 0.433306  [41600/141921]\n",
      "loss: 0.597649  [44800/141921]\n",
      "loss: 0.539464  [48000/141921]\n",
      "loss: 0.476510  [51200/141921]\n",
      "loss: 0.620145  [54400/141921]\n",
      "loss: 0.516615  [57600/141921]\n",
      "loss: 0.468771  [60800/141921]\n",
      "loss: 0.689706  [64000/141921]\n",
      "loss: 0.632910  [67200/141921]\n",
      "loss: 0.487624  [70400/141921]\n",
      "loss: 0.698766  [73600/141921]\n",
      "loss: 0.613531  [76800/141921]\n",
      "loss: 0.429125  [80000/141921]\n",
      "loss: 0.439787  [83200/141921]\n",
      "loss: 0.561496  [86400/141921]\n",
      "loss: 0.596603  [89600/141921]\n",
      "loss: 0.630481  [92800/141921]\n",
      "loss: 0.416807  [96000/141921]\n",
      "loss: 0.529514  [99200/141921]\n",
      "loss: 0.547946  [102400/141921]\n",
      "loss: 0.520991  [105600/141921]\n",
      "loss: 0.513874  [108800/141921]\n",
      "loss: 0.575966  [112000/141921]\n",
      "loss: 0.587695  [115200/141921]\n",
      "loss: 0.509945  [118400/141921]\n",
      "loss: 0.560355  [121600/141921]\n",
      "loss: 0.515327  [124800/141921]\n",
      "loss: 0.362559  [128000/141921]\n",
      "loss: 0.623348  [131200/141921]\n",
      "loss: 0.585147  [134400/141921]\n",
      "loss: 0.505443  [137600/141921]\n",
      "loss: 0.609280  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.523292 \n",
      "\n",
      "Epoch 18\n",
      "---------------------------\n",
      "loss: 0.491298  [ 3200/141921]\n",
      "loss: 0.557016  [ 6400/141921]\n",
      "loss: 0.390424  [ 9600/141921]\n",
      "loss: 0.592126  [12800/141921]\n",
      "loss: 0.418312  [16000/141921]\n",
      "loss: 0.416721  [19200/141921]\n",
      "loss: 0.605214  [22400/141921]\n",
      "loss: 0.548619  [25600/141921]\n",
      "loss: 0.520769  [28800/141921]\n",
      "loss: 0.520615  [32000/141921]\n",
      "loss: 0.572122  [35200/141921]\n",
      "loss: 0.512406  [38400/141921]\n",
      "loss: 0.491107  [41600/141921]\n",
      "loss: 0.512505  [44800/141921]\n",
      "loss: 0.506752  [48000/141921]\n",
      "loss: 0.557386  [51200/141921]\n",
      "loss: 0.539662  [54400/141921]\n",
      "loss: 0.464008  [57600/141921]\n",
      "loss: 0.545249  [60800/141921]\n",
      "loss: 0.556565  [64000/141921]\n",
      "loss: 0.548171  [67200/141921]\n",
      "loss: 0.454008  [70400/141921]\n",
      "loss: 0.496530  [73600/141921]\n",
      "loss: 0.355180  [76800/141921]\n",
      "loss: 0.442939  [80000/141921]\n",
      "loss: 0.570807  [83200/141921]\n",
      "loss: 0.497541  [86400/141921]\n",
      "loss: 0.486781  [89600/141921]\n",
      "loss: 0.575704  [92800/141921]\n",
      "loss: 0.587700  [96000/141921]\n",
      "loss: 0.446500  [99200/141921]\n",
      "loss: 0.491598  [102400/141921]\n",
      "loss: 0.550129  [105600/141921]\n",
      "loss: 0.481490  [108800/141921]\n",
      "loss: 0.541921  [112000/141921]\n",
      "loss: 0.341699  [115200/141921]\n",
      "loss: 0.658242  [118400/141921]\n",
      "loss: 0.484914  [121600/141921]\n",
      "loss: 0.504264  [124800/141921]\n",
      "loss: 0.501406  [128000/141921]\n",
      "loss: 0.471952  [131200/141921]\n",
      "loss: 0.513106  [134400/141921]\n",
      "loss: 0.619017  [137600/141921]\n",
      "loss: 0.494528  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.520136 \n",
      "\n",
      "Epoch 19\n",
      "---------------------------\n",
      "loss: 0.706636  [ 3200/141921]\n",
      "loss: 0.424051  [ 6400/141921]\n",
      "loss: 0.587475  [ 9600/141921]\n",
      "loss: 0.726532  [12800/141921]\n",
      "loss: 0.552188  [16000/141921]\n",
      "loss: 0.571208  [19200/141921]\n",
      "loss: 0.539303  [22400/141921]\n",
      "loss: 0.454313  [25600/141921]\n",
      "loss: 0.725361  [28800/141921]\n",
      "loss: 0.545138  [32000/141921]\n",
      "loss: 0.439090  [35200/141921]\n",
      "loss: 0.499803  [38400/141921]\n",
      "loss: 0.570332  [41600/141921]\n",
      "loss: 0.497527  [44800/141921]\n",
      "loss: 0.616838  [48000/141921]\n",
      "loss: 0.513925  [51200/141921]\n",
      "loss: 0.382442  [54400/141921]\n",
      "loss: 0.519942  [57600/141921]\n",
      "loss: 0.528460  [60800/141921]\n",
      "loss: 0.582168  [64000/141921]\n",
      "loss: 0.506982  [67200/141921]\n",
      "loss: 0.514192  [70400/141921]\n",
      "loss: 0.497039  [73600/141921]\n",
      "loss: 0.724424  [76800/141921]\n",
      "loss: 0.511900  [80000/141921]\n",
      "loss: 0.534112  [83200/141921]\n",
      "loss: 0.536738  [86400/141921]\n",
      "loss: 0.530778  [89600/141921]\n",
      "loss: 0.519756  [92800/141921]\n",
      "loss: 0.437703  [96000/141921]\n",
      "loss: 0.559386  [99200/141921]\n",
      "loss: 0.501100  [102400/141921]\n",
      "loss: 0.498454  [105600/141921]\n",
      "loss: 0.469765  [108800/141921]\n",
      "loss: 0.669916  [112000/141921]\n",
      "loss: 0.432230  [115200/141921]\n",
      "loss: 0.414975  [118400/141921]\n",
      "loss: 0.639706  [121600/141921]\n",
      "loss: 0.668261  [124800/141921]\n",
      "loss: 0.532496  [128000/141921]\n",
      "loss: 0.583343  [131200/141921]\n",
      "loss: 0.547833  [134400/141921]\n",
      "loss: 0.511589  [137600/141921]\n",
      "loss: 0.581481  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.516592 \n",
      "\n",
      "Epoch 20\n",
      "---------------------------\n",
      "loss: 0.559650  [ 3200/141921]\n",
      "loss: 0.564559  [ 6400/141921]\n",
      "loss: 0.550357  [ 9600/141921]\n",
      "loss: 0.486619  [12800/141921]\n",
      "loss: 0.481389  [16000/141921]\n",
      "loss: 0.499715  [19200/141921]\n",
      "loss: 0.353275  [22400/141921]\n",
      "loss: 0.688031  [25600/141921]\n",
      "loss: 0.493506  [28800/141921]\n",
      "loss: 0.405925  [32000/141921]\n",
      "loss: 0.529702  [35200/141921]\n",
      "loss: 0.616338  [38400/141921]\n",
      "loss: 0.579330  [41600/141921]\n",
      "loss: 0.570908  [44800/141921]\n",
      "loss: 0.445255  [48000/141921]\n",
      "loss: 0.363379  [51200/141921]\n",
      "loss: 0.564883  [54400/141921]\n",
      "loss: 0.498706  [57600/141921]\n",
      "loss: 0.486239  [60800/141921]\n",
      "loss: 0.632347  [64000/141921]\n",
      "loss: 0.412204  [67200/141921]\n",
      "loss: 0.472289  [70400/141921]\n",
      "loss: 0.468150  [73600/141921]\n",
      "loss: 0.510823  [76800/141921]\n",
      "loss: 0.485333  [80000/141921]\n",
      "loss: 0.491889  [83200/141921]\n",
      "loss: 0.571382  [86400/141921]\n",
      "loss: 0.647018  [89600/141921]\n",
      "loss: 0.608659  [92800/141921]\n",
      "loss: 0.561594  [96000/141921]\n",
      "loss: 0.487770  [99200/141921]\n",
      "loss: 0.582928  [102400/141921]\n",
      "loss: 0.671237  [105600/141921]\n",
      "loss: 0.461606  [108800/141921]\n",
      "loss: 0.543717  [112000/141921]\n",
      "loss: 0.440714  [115200/141921]\n",
      "loss: 0.441499  [118400/141921]\n",
      "loss: 0.541357  [121600/141921]\n",
      "loss: 0.603175  [124800/141921]\n",
      "loss: 0.571717  [128000/141921]\n",
      "loss: 0.581250  [131200/141921]\n",
      "loss: 0.424071  [134400/141921]\n",
      "loss: 0.429728  [137600/141921]\n",
      "loss: 0.412621  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.515111 \n",
      "\n",
      "Epoch 21\n",
      "---------------------------\n",
      "loss: 0.420000  [ 3200/141921]\n",
      "loss: 0.426041  [ 6400/141921]\n",
      "loss: 0.613946  [ 9600/141921]\n",
      "loss: 0.467274  [12800/141921]\n",
      "loss: 0.559277  [16000/141921]\n",
      "loss: 0.552861  [19200/141921]\n",
      "loss: 0.481171  [22400/141921]\n",
      "loss: 0.431894  [25600/141921]\n",
      "loss: 0.462461  [28800/141921]\n",
      "loss: 0.500305  [32000/141921]\n",
      "loss: 0.539909  [35200/141921]\n",
      "loss: 0.585197  [38400/141921]\n",
      "loss: 0.544635  [41600/141921]\n",
      "loss: 0.577393  [44800/141921]\n",
      "loss: 0.615324  [48000/141921]\n",
      "loss: 0.517707  [51200/141921]\n",
      "loss: 0.566265  [54400/141921]\n",
      "loss: 0.476583  [57600/141921]\n",
      "loss: 0.510865  [60800/141921]\n",
      "loss: 0.453277  [64000/141921]\n",
      "loss: 0.790809  [67200/141921]\n",
      "loss: 0.499749  [70400/141921]\n",
      "loss: 0.541291  [73600/141921]\n",
      "loss: 0.454324  [76800/141921]\n",
      "loss: 0.447974  [80000/141921]\n",
      "loss: 0.657361  [83200/141921]\n",
      "loss: 0.488547  [86400/141921]\n",
      "loss: 0.534221  [89600/141921]\n",
      "loss: 0.561064  [92800/141921]\n",
      "loss: 0.504051  [96000/141921]\n",
      "loss: 0.456413  [99200/141921]\n",
      "loss: 0.606612  [102400/141921]\n",
      "loss: 0.633734  [105600/141921]\n",
      "loss: 0.499244  [108800/141921]\n",
      "loss: 0.435842  [112000/141921]\n",
      "loss: 0.531592  [115200/141921]\n",
      "loss: 0.498055  [118400/141921]\n",
      "loss: 0.472845  [121600/141921]\n",
      "loss: 0.578865  [124800/141921]\n",
      "loss: 0.421688  [128000/141921]\n",
      "loss: 0.611818  [131200/141921]\n",
      "loss: 0.549948  [134400/141921]\n",
      "loss: 0.560541  [137600/141921]\n",
      "loss: 0.626949  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.511879 \n",
      "\n",
      "Epoch 22\n",
      "---------------------------\n",
      "loss: 0.506717  [ 3200/141921]\n",
      "loss: 0.467001  [ 6400/141921]\n",
      "loss: 0.542570  [ 9600/141921]\n",
      "loss: 0.488746  [12800/141921]\n",
      "loss: 0.434023  [16000/141921]\n",
      "loss: 0.475675  [19200/141921]\n",
      "loss: 0.571938  [22400/141921]\n",
      "loss: 0.495182  [25600/141921]\n",
      "loss: 0.519614  [28800/141921]\n",
      "loss: 0.555655  [32000/141921]\n",
      "loss: 0.501594  [35200/141921]\n",
      "loss: 0.400570  [38400/141921]\n",
      "loss: 0.523879  [41600/141921]\n",
      "loss: 0.376088  [44800/141921]\n",
      "loss: 0.431296  [48000/141921]\n",
      "loss: 0.476299  [51200/141921]\n",
      "loss: 0.504704  [54400/141921]\n",
      "loss: 0.495169  [57600/141921]\n",
      "loss: 0.427819  [60800/141921]\n",
      "loss: 0.546382  [64000/141921]\n",
      "loss: 0.482377  [67200/141921]\n",
      "loss: 0.555505  [70400/141921]\n",
      "loss: 0.592734  [73600/141921]\n",
      "loss: 0.442417  [76800/141921]\n",
      "loss: 0.637253  [80000/141921]\n",
      "loss: 0.670107  [83200/141921]\n",
      "loss: 0.458754  [86400/141921]\n",
      "loss: 0.546425  [89600/141921]\n",
      "loss: 0.490899  [92800/141921]\n",
      "loss: 0.482905  [96000/141921]\n",
      "loss: 0.506818  [99200/141921]\n",
      "loss: 0.577531  [102400/141921]\n",
      "loss: 0.479902  [105600/141921]\n",
      "loss: 0.457411  [108800/141921]\n",
      "loss: 0.521584  [112000/141921]\n",
      "loss: 0.598711  [115200/141921]\n",
      "loss: 0.552878  [118400/141921]\n",
      "loss: 0.512574  [121600/141921]\n",
      "loss: 0.505665  [124800/141921]\n",
      "loss: 0.468592  [128000/141921]\n",
      "loss: 0.663587  [131200/141921]\n",
      "loss: 0.393313  [134400/141921]\n",
      "loss: 0.558457  [137600/141921]\n",
      "loss: 0.340843  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.507721 \n",
      "\n",
      "Epoch 23\n",
      "---------------------------\n",
      "loss: 0.524424  [ 3200/141921]\n",
      "loss: 0.460793  [ 6400/141921]\n",
      "loss: 0.402156  [ 9600/141921]\n",
      "loss: 0.578687  [12800/141921]\n",
      "loss: 0.528133  [16000/141921]\n",
      "loss: 0.558361  [19200/141921]\n",
      "loss: 0.501137  [22400/141921]\n",
      "loss: 0.509780  [25600/141921]\n",
      "loss: 0.404861  [28800/141921]\n",
      "loss: 0.626913  [32000/141921]\n",
      "loss: 0.475107  [35200/141921]\n",
      "loss: 0.526980  [38400/141921]\n",
      "loss: 0.408395  [41600/141921]\n",
      "loss: 0.456724  [44800/141921]\n",
      "loss: 0.500512  [48000/141921]\n",
      "loss: 0.462429  [51200/141921]\n",
      "loss: 0.498220  [54400/141921]\n",
      "loss: 0.443911  [57600/141921]\n",
      "loss: 0.445121  [60800/141921]\n",
      "loss: 0.404183  [64000/141921]\n",
      "loss: 0.540339  [67200/141921]\n",
      "loss: 0.476132  [70400/141921]\n",
      "loss: 0.559354  [73600/141921]\n",
      "loss: 0.531946  [76800/141921]\n",
      "loss: 0.511485  [80000/141921]\n",
      "loss: 0.605050  [83200/141921]\n",
      "loss: 0.534079  [86400/141921]\n",
      "loss: 0.559123  [89600/141921]\n",
      "loss: 0.580132  [92800/141921]\n",
      "loss: 0.439978  [96000/141921]\n",
      "loss: 0.535416  [99200/141921]\n",
      "loss: 0.577879  [102400/141921]\n",
      "loss: 0.465507  [105600/141921]\n",
      "loss: 0.660513  [108800/141921]\n",
      "loss: 0.456159  [112000/141921]\n",
      "loss: 0.375614  [115200/141921]\n",
      "loss: 0.531558  [118400/141921]\n",
      "loss: 0.438368  [121600/141921]\n",
      "loss: 0.584059  [124800/141921]\n",
      "loss: 0.533047  [128000/141921]\n",
      "loss: 0.480780  [131200/141921]\n",
      "loss: 0.492058  [134400/141921]\n",
      "loss: 0.434306  [137600/141921]\n",
      "loss: 0.347956  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.524612 \n",
      "\n",
      "Epoch 24\n",
      "---------------------------\n",
      "loss: 0.605392  [ 3200/141921]\n",
      "loss: 0.685271  [ 6400/141921]\n",
      "loss: 0.570004  [ 9600/141921]\n",
      "loss: 0.408814  [12800/141921]\n",
      "loss: 0.617551  [16000/141921]\n",
      "loss: 0.552332  [19200/141921]\n",
      "loss: 0.441808  [22400/141921]\n",
      "loss: 0.475903  [25600/141921]\n",
      "loss: 0.390298  [28800/141921]\n",
      "loss: 0.485702  [32000/141921]\n",
      "loss: 0.495581  [35200/141921]\n",
      "loss: 0.520408  [38400/141921]\n",
      "loss: 0.385114  [41600/141921]\n",
      "loss: 0.353252  [44800/141921]\n",
      "loss: 0.477550  [48000/141921]\n",
      "loss: 0.414269  [51200/141921]\n",
      "loss: 0.416073  [54400/141921]\n",
      "loss: 0.594089  [57600/141921]\n",
      "loss: 0.518973  [60800/141921]\n",
      "loss: 0.508598  [64000/141921]\n",
      "loss: 0.503217  [67200/141921]\n",
      "loss: 0.430092  [70400/141921]\n",
      "loss: 0.598353  [73600/141921]\n",
      "loss: 0.543440  [76800/141921]\n",
      "loss: 0.539599  [80000/141921]\n",
      "loss: 0.409310  [83200/141921]\n",
      "loss: 0.506502  [86400/141921]\n",
      "loss: 0.508196  [89600/141921]\n",
      "loss: 0.515726  [92800/141921]\n",
      "loss: 0.408636  [96000/141921]\n",
      "loss: 0.511455  [99200/141921]\n",
      "loss: 0.551884  [102400/141921]\n",
      "loss: 0.534956  [105600/141921]\n",
      "loss: 0.540071  [108800/141921]\n",
      "loss: 0.394818  [112000/141921]\n",
      "loss: 0.561231  [115200/141921]\n",
      "loss: 0.509068  [118400/141921]\n",
      "loss: 0.467527  [121600/141921]\n",
      "loss: 0.520076  [124800/141921]\n",
      "loss: 0.558604  [128000/141921]\n",
      "loss: 0.539981  [131200/141921]\n",
      "loss: 0.538638  [134400/141921]\n",
      "loss: 0.677309  [137600/141921]\n",
      "loss: 0.475713  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.505018 \n",
      "\n",
      "Epoch 25\n",
      "---------------------------\n",
      "loss: 0.425238  [ 3200/141921]\n",
      "loss: 0.632166  [ 6400/141921]\n",
      "loss: 0.499791  [ 9600/141921]\n",
      "loss: 0.588867  [12800/141921]\n",
      "loss: 0.484834  [16000/141921]\n",
      "loss: 0.436280  [19200/141921]\n",
      "loss: 0.402701  [22400/141921]\n",
      "loss: 0.434109  [25600/141921]\n",
      "loss: 0.447900  [28800/141921]\n",
      "loss: 0.665573  [32000/141921]\n",
      "loss: 0.452575  [35200/141921]\n",
      "loss: 0.445105  [38400/141921]\n",
      "loss: 0.514921  [41600/141921]\n",
      "loss: 0.525866  [44800/141921]\n",
      "loss: 0.399546  [48000/141921]\n",
      "loss: 0.541137  [51200/141921]\n",
      "loss: 0.395080  [54400/141921]\n",
      "loss: 0.417089  [57600/141921]\n",
      "loss: 0.552047  [60800/141921]\n",
      "loss: 0.511422  [64000/141921]\n",
      "loss: 0.613220  [67200/141921]\n",
      "loss: 0.421829  [70400/141921]\n",
      "loss: 0.421234  [73600/141921]\n",
      "loss: 0.574664  [76800/141921]\n",
      "loss: 0.519599  [80000/141921]\n",
      "loss: 0.597020  [83200/141921]\n",
      "loss: 0.501155  [86400/141921]\n",
      "loss: 0.500229  [89600/141921]\n",
      "loss: 0.525358  [92800/141921]\n",
      "loss: 0.499323  [96000/141921]\n",
      "loss: 0.434137  [99200/141921]\n",
      "loss: 0.485677  [102400/141921]\n",
      "loss: 0.492053  [105600/141921]\n",
      "loss: 0.585909  [108800/141921]\n",
      "loss: 0.623742  [112000/141921]\n",
      "loss: 0.472771  [115200/141921]\n",
      "loss: 0.431553  [118400/141921]\n",
      "loss: 0.538084  [121600/141921]\n",
      "loss: 0.520739  [124800/141921]\n",
      "loss: 0.462995  [128000/141921]\n",
      "loss: 0.602182  [131200/141921]\n",
      "loss: 0.511442  [134400/141921]\n",
      "loss: 0.478346  [137600/141921]\n",
      "loss: 0.484999  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.502535 \n",
      "\n",
      "Epoch 26\n",
      "---------------------------\n",
      "loss: 0.523348  [ 3200/141921]\n",
      "loss: 0.533077  [ 6400/141921]\n",
      "loss: 0.429163  [ 9600/141921]\n",
      "loss: 0.511045  [12800/141921]\n",
      "loss: 0.503890  [16000/141921]\n",
      "loss: 0.691811  [19200/141921]\n",
      "loss: 0.479463  [22400/141921]\n",
      "loss: 0.535347  [25600/141921]\n",
      "loss: 0.401726  [28800/141921]\n",
      "loss: 0.337275  [32000/141921]\n",
      "loss: 0.518625  [35200/141921]\n",
      "loss: 0.682555  [38400/141921]\n",
      "loss: 0.527561  [41600/141921]\n",
      "loss: 0.452083  [44800/141921]\n",
      "loss: 0.426759  [48000/141921]\n",
      "loss: 0.503438  [51200/141921]\n",
      "loss: 0.376880  [54400/141921]\n",
      "loss: 0.541312  [57600/141921]\n",
      "loss: 0.503643  [60800/141921]\n",
      "loss: 0.353838  [64000/141921]\n",
      "loss: 0.495202  [67200/141921]\n",
      "loss: 0.494668  [70400/141921]\n",
      "loss: 0.472108  [73600/141921]\n",
      "loss: 0.440206  [76800/141921]\n",
      "loss: 0.494012  [80000/141921]\n",
      "loss: 0.523365  [83200/141921]\n",
      "loss: 0.438492  [86400/141921]\n",
      "loss: 0.487294  [89600/141921]\n",
      "loss: 0.389732  [92800/141921]\n",
      "loss: 0.486197  [96000/141921]\n",
      "loss: 0.436905  [99200/141921]\n",
      "loss: 0.544471  [102400/141921]\n",
      "loss: 0.577342  [105600/141921]\n",
      "loss: 0.578966  [108800/141921]\n",
      "loss: 0.366626  [112000/141921]\n",
      "loss: 0.494596  [115200/141921]\n",
      "loss: 0.530775  [118400/141921]\n",
      "loss: 0.539333  [121600/141921]\n",
      "loss: 0.480706  [124800/141921]\n",
      "loss: 0.748836  [128000/141921]\n",
      "loss: 0.469128  [131200/141921]\n",
      "loss: 0.555867  [134400/141921]\n",
      "loss: 0.551623  [137600/141921]\n",
      "loss: 0.515917  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.501741 \n",
      "\n",
      "Epoch 27\n",
      "---------------------------\n",
      "loss: 0.378175  [ 3200/141921]\n",
      "loss: 0.596079  [ 6400/141921]\n",
      "loss: 0.640375  [ 9600/141921]\n",
      "loss: 0.594608  [12800/141921]\n",
      "loss: 0.401432  [16000/141921]\n",
      "loss: 0.428149  [19200/141921]\n",
      "loss: 0.505978  [22400/141921]\n",
      "loss: 0.458370  [25600/141921]\n",
      "loss: 0.649748  [28800/141921]\n",
      "loss: 0.395263  [32000/141921]\n",
      "loss: 0.580646  [35200/141921]\n",
      "loss: 0.541779  [38400/141921]\n",
      "loss: 0.533368  [41600/141921]\n",
      "loss: 0.532627  [44800/141921]\n",
      "loss: 0.502825  [48000/141921]\n",
      "loss: 0.463323  [51200/141921]\n",
      "loss: 0.427017  [54400/141921]\n",
      "loss: 0.445223  [57600/141921]\n",
      "loss: 0.431634  [60800/141921]\n",
      "loss: 0.624127  [64000/141921]\n",
      "loss: 0.432414  [67200/141921]\n",
      "loss: 0.374182  [70400/141921]\n",
      "loss: 0.435843  [73600/141921]\n",
      "loss: 0.469809  [76800/141921]\n",
      "loss: 0.504142  [80000/141921]\n",
      "loss: 0.638936  [83200/141921]\n",
      "loss: 0.568307  [86400/141921]\n",
      "loss: 0.550365  [89600/141921]\n",
      "loss: 0.536368  [92800/141921]\n",
      "loss: 0.549984  [96000/141921]\n",
      "loss: 0.552757  [99200/141921]\n",
      "loss: 0.554306  [102400/141921]\n",
      "loss: 0.511092  [105600/141921]\n",
      "loss: 0.465974  [108800/141921]\n",
      "loss: 0.429745  [112000/141921]\n",
      "loss: 0.419128  [115200/141921]\n",
      "loss: 0.646505  [118400/141921]\n",
      "loss: 0.504008  [121600/141921]\n",
      "loss: 0.382829  [124800/141921]\n",
      "loss: 0.521003  [128000/141921]\n",
      "loss: 0.450249  [131200/141921]\n",
      "loss: 0.483100  [134400/141921]\n",
      "loss: 0.613235  [137600/141921]\n",
      "loss: 0.479366  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.497385 \n",
      "\n",
      "Epoch 28\n",
      "---------------------------\n",
      "loss: 0.456491  [ 3200/141921]\n",
      "loss: 0.466612  [ 6400/141921]\n",
      "loss: 0.512611  [ 9600/141921]\n",
      "loss: 0.480893  [12800/141921]\n",
      "loss: 0.362640  [16000/141921]\n",
      "loss: 0.566298  [19200/141921]\n",
      "loss: 0.541933  [22400/141921]\n",
      "loss: 0.423985  [25600/141921]\n",
      "loss: 0.532543  [28800/141921]\n",
      "loss: 0.647437  [32000/141921]\n",
      "loss: 0.539415  [35200/141921]\n",
      "loss: 0.448441  [38400/141921]\n",
      "loss: 0.500174  [41600/141921]\n",
      "loss: 0.660084  [44800/141921]\n",
      "loss: 0.493558  [48000/141921]\n",
      "loss: 0.494521  [51200/141921]\n",
      "loss: 0.523937  [54400/141921]\n",
      "loss: 0.618594  [57600/141921]\n",
      "loss: 0.462625  [60800/141921]\n",
      "loss: 0.588658  [64000/141921]\n",
      "loss: 0.449864  [67200/141921]\n",
      "loss: 0.504781  [70400/141921]\n",
      "loss: 0.565508  [73600/141921]\n",
      "loss: 0.455034  [76800/141921]\n",
      "loss: 0.542537  [80000/141921]\n",
      "loss: 0.386844  [83200/141921]\n",
      "loss: 0.443687  [86400/141921]\n",
      "loss: 0.435925  [89600/141921]\n",
      "loss: 0.454833  [92800/141921]\n",
      "loss: 0.507387  [96000/141921]\n",
      "loss: 0.474543  [99200/141921]\n",
      "loss: 0.496719  [102400/141921]\n",
      "loss: 0.455199  [105600/141921]\n",
      "loss: 0.395379  [108800/141921]\n",
      "loss: 0.624594  [112000/141921]\n",
      "loss: 0.550788  [115200/141921]\n",
      "loss: 0.456234  [118400/141921]\n",
      "loss: 0.420696  [121600/141921]\n",
      "loss: 0.533831  [124800/141921]\n",
      "loss: 0.540782  [128000/141921]\n",
      "loss: 0.501228  [131200/141921]\n",
      "loss: 0.510855  [134400/141921]\n",
      "loss: 0.537924  [137600/141921]\n",
      "loss: 0.439764  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.498893 \n",
      "\n",
      "Epoch 29\n",
      "---------------------------\n",
      "loss: 0.480721  [ 3200/141921]\n",
      "loss: 0.447545  [ 6400/141921]\n",
      "loss: 0.493610  [ 9600/141921]\n",
      "loss: 0.425031  [12800/141921]\n",
      "loss: 0.360149  [16000/141921]\n",
      "loss: 0.567141  [19200/141921]\n",
      "loss: 0.443898  [22400/141921]\n",
      "loss: 0.558502  [25600/141921]\n",
      "loss: 0.530774  [28800/141921]\n",
      "loss: 0.512681  [32000/141921]\n",
      "loss: 0.584439  [35200/141921]\n",
      "loss: 0.478981  [38400/141921]\n",
      "loss: 0.431576  [41600/141921]\n",
      "loss: 0.634986  [44800/141921]\n",
      "loss: 0.513431  [48000/141921]\n",
      "loss: 0.445758  [51200/141921]\n",
      "loss: 0.438615  [54400/141921]\n",
      "loss: 0.423523  [57600/141921]\n",
      "loss: 0.517280  [60800/141921]\n",
      "loss: 0.475451  [64000/141921]\n",
      "loss: 0.554365  [67200/141921]\n",
      "loss: 0.504701  [70400/141921]\n",
      "loss: 0.443756  [73600/141921]\n",
      "loss: 0.478020  [76800/141921]\n",
      "loss: 0.486813  [80000/141921]\n",
      "loss: 0.623847  [83200/141921]\n",
      "loss: 0.555667  [86400/141921]\n",
      "loss: 0.552399  [89600/141921]\n",
      "loss: 0.592351  [92800/141921]\n",
      "loss: 0.470541  [96000/141921]\n",
      "loss: 0.555922  [99200/141921]\n",
      "loss: 0.488625  [102400/141921]\n",
      "loss: 0.495620  [105600/141921]\n",
      "loss: 0.537622  [108800/141921]\n",
      "loss: 0.521594  [112000/141921]\n",
      "loss: 0.589592  [115200/141921]\n",
      "loss: 0.459849  [118400/141921]\n",
      "loss: 0.704906  [121600/141921]\n",
      "loss: 0.589228  [124800/141921]\n",
      "loss: 0.479850  [128000/141921]\n",
      "loss: 0.478865  [131200/141921]\n",
      "loss: 0.561301  [134400/141921]\n",
      "loss: 0.389673  [137600/141921]\n",
      "loss: 0.526245  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.498425 \n",
      "\n",
      "Epoch 30\n",
      "---------------------------\n",
      "loss: 0.376725  [ 3200/141921]\n",
      "loss: 0.504460  [ 6400/141921]\n",
      "loss: 0.605195  [ 9600/141921]\n",
      "loss: 0.524276  [12800/141921]\n",
      "loss: 0.490809  [16000/141921]\n",
      "loss: 0.524674  [19200/141921]\n",
      "loss: 0.524591  [22400/141921]\n",
      "loss: 0.458480  [25600/141921]\n",
      "loss: 0.521915  [28800/141921]\n",
      "loss: 0.405679  [32000/141921]\n",
      "loss: 0.551933  [35200/141921]\n",
      "loss: 0.584012  [38400/141921]\n",
      "loss: 0.466606  [41600/141921]\n",
      "loss: 0.584693  [44800/141921]\n",
      "loss: 0.631500  [48000/141921]\n",
      "loss: 0.681887  [51200/141921]\n",
      "loss: 0.528702  [54400/141921]\n",
      "loss: 0.526995  [57600/141921]\n",
      "loss: 0.429703  [60800/141921]\n",
      "loss: 0.548744  [64000/141921]\n",
      "loss: 0.562251  [67200/141921]\n",
      "loss: 0.444869  [70400/141921]\n",
      "loss: 0.630445  [73600/141921]\n",
      "loss: 0.456515  [76800/141921]\n",
      "loss: 0.500971  [80000/141921]\n",
      "loss: 0.633559  [83200/141921]\n",
      "loss: 0.495954  [86400/141921]\n",
      "loss: 0.413674  [89600/141921]\n",
      "loss: 0.516079  [92800/141921]\n",
      "loss: 0.532866  [96000/141921]\n",
      "loss: 0.504944  [99200/141921]\n",
      "loss: 0.443261  [102400/141921]\n",
      "loss: 0.489243  [105600/141921]\n",
      "loss: 0.530653  [108800/141921]\n",
      "loss: 0.515410  [112000/141921]\n",
      "loss: 0.430071  [115200/141921]\n",
      "loss: 0.453027  [118400/141921]\n",
      "loss: 0.477884  [121600/141921]\n",
      "loss: 0.476779  [124800/141921]\n",
      "loss: 0.386147  [128000/141921]\n",
      "loss: 0.488024  [131200/141921]\n",
      "loss: 0.439498  [134400/141921]\n",
      "loss: 0.436252  [137600/141921]\n",
      "loss: 0.420864  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.502079 \n",
      "\n",
      "Epoch 31\n",
      "---------------------------\n",
      "loss: 0.527608  [ 3200/141921]\n",
      "loss: 0.405054  [ 6400/141921]\n",
      "loss: 0.586387  [ 9600/141921]\n",
      "loss: 0.420252  [12800/141921]\n",
      "loss: 0.458514  [16000/141921]\n",
      "loss: 0.421147  [19200/141921]\n",
      "loss: 0.465292  [22400/141921]\n",
      "loss: 0.497884  [25600/141921]\n",
      "loss: 0.504105  [28800/141921]\n",
      "loss: 0.340483  [32000/141921]\n",
      "loss: 0.371832  [35200/141921]\n",
      "loss: 0.482125  [38400/141921]\n",
      "loss: 0.384280  [41600/141921]\n",
      "loss: 0.378540  [44800/141921]\n",
      "loss: 0.523772  [48000/141921]\n",
      "loss: 0.548924  [51200/141921]\n",
      "loss: 0.463165  [54400/141921]\n",
      "loss: 0.377422  [57600/141921]\n",
      "loss: 0.535110  [60800/141921]\n",
      "loss: 0.575707  [64000/141921]\n",
      "loss: 0.629655  [67200/141921]\n",
      "loss: 0.421048  [70400/141921]\n",
      "loss: 0.441378  [73600/141921]\n",
      "loss: 0.579579  [76800/141921]\n",
      "loss: 0.511828  [80000/141921]\n",
      "loss: 0.478173  [83200/141921]\n",
      "loss: 0.538863  [86400/141921]\n",
      "loss: 0.533673  [89600/141921]\n",
      "loss: 0.616107  [92800/141921]\n",
      "loss: 0.509712  [96000/141921]\n",
      "loss: 0.522475  [99200/141921]\n",
      "loss: 0.484155  [102400/141921]\n",
      "loss: 0.491723  [105600/141921]\n",
      "loss: 0.451622  [108800/141921]\n",
      "loss: 0.486811  [112000/141921]\n",
      "loss: 0.376588  [115200/141921]\n",
      "loss: 0.517560  [118400/141921]\n",
      "loss: 0.561885  [121600/141921]\n",
      "loss: 0.566992  [124800/141921]\n",
      "loss: 0.416920  [128000/141921]\n",
      "loss: 0.501428  [131200/141921]\n",
      "loss: 0.575479  [134400/141921]\n",
      "loss: 0.507751  [137600/141921]\n",
      "loss: 0.516702  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.487343 \n",
      "\n",
      "Epoch 32\n",
      "---------------------------\n",
      "loss: 0.425463  [ 3200/141921]\n",
      "loss: 0.497123  [ 6400/141921]\n",
      "loss: 0.424296  [ 9600/141921]\n",
      "loss: 0.691069  [12800/141921]\n",
      "loss: 0.347196  [16000/141921]\n",
      "loss: 0.538669  [19200/141921]\n",
      "loss: 0.469906  [22400/141921]\n",
      "loss: 0.464014  [25600/141921]\n",
      "loss: 0.462804  [28800/141921]\n",
      "loss: 0.396992  [32000/141921]\n",
      "loss: 0.437985  [35200/141921]\n",
      "loss: 0.423648  [38400/141921]\n",
      "loss: 0.407184  [41600/141921]\n",
      "loss: 0.513598  [44800/141921]\n",
      "loss: 0.434262  [48000/141921]\n",
      "loss: 0.392804  [51200/141921]\n",
      "loss: 0.597214  [54400/141921]\n",
      "loss: 0.441623  [57600/141921]\n",
      "loss: 0.400617  [60800/141921]\n",
      "loss: 0.431450  [64000/141921]\n",
      "loss: 0.461534  [67200/141921]\n",
      "loss: 0.473257  [70400/141921]\n",
      "loss: 0.462146  [73600/141921]\n",
      "loss: 0.500884  [76800/141921]\n",
      "loss: 0.423635  [80000/141921]\n",
      "loss: 0.523662  [83200/141921]\n",
      "loss: 0.420399  [86400/141921]\n",
      "loss: 0.448795  [89600/141921]\n",
      "loss: 0.520782  [92800/141921]\n",
      "loss: 0.556758  [96000/141921]\n",
      "loss: 0.484486  [99200/141921]\n",
      "loss: 0.530797  [102400/141921]\n",
      "loss: 0.528408  [105600/141921]\n",
      "loss: 0.564240  [108800/141921]\n",
      "loss: 0.494618  [112000/141921]\n",
      "loss: 0.479186  [115200/141921]\n",
      "loss: 0.505680  [118400/141921]\n",
      "loss: 0.478532  [121600/141921]\n",
      "loss: 0.509231  [124800/141921]\n",
      "loss: 0.446497  [128000/141921]\n",
      "loss: 0.367017  [131200/141921]\n",
      "loss: 0.409149  [134400/141921]\n",
      "loss: 0.442281  [137600/141921]\n",
      "loss: 0.366755  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.490030 \n",
      "\n",
      "Epoch 33\n",
      "---------------------------\n",
      "loss: 0.410625  [ 3200/141921]\n",
      "loss: 0.381734  [ 6400/141921]\n",
      "loss: 0.498974  [ 9600/141921]\n",
      "loss: 0.459911  [12800/141921]\n",
      "loss: 0.663050  [16000/141921]\n",
      "loss: 0.517927  [19200/141921]\n",
      "loss: 0.439289  [22400/141921]\n",
      "loss: 0.410694  [25600/141921]\n",
      "loss: 0.425363  [28800/141921]\n",
      "loss: 0.352329  [32000/141921]\n",
      "loss: 0.377444  [35200/141921]\n",
      "loss: 0.538124  [38400/141921]\n",
      "loss: 0.449293  [41600/141921]\n",
      "loss: 0.465943  [44800/141921]\n",
      "loss: 0.523630  [48000/141921]\n",
      "loss: 0.269707  [51200/141921]\n",
      "loss: 0.400095  [54400/141921]\n",
      "loss: 0.386858  [57600/141921]\n",
      "loss: 0.377815  [60800/141921]\n",
      "loss: 0.438067  [64000/141921]\n",
      "loss: 0.456763  [67200/141921]\n",
      "loss: 0.551372  [70400/141921]\n",
      "loss: 0.373862  [73600/141921]\n",
      "loss: 0.449389  [76800/141921]\n",
      "loss: 0.405844  [80000/141921]\n",
      "loss: 0.563821  [83200/141921]\n",
      "loss: 0.373888  [86400/141921]\n",
      "loss: 0.437594  [89600/141921]\n",
      "loss: 0.431137  [92800/141921]\n",
      "loss: 0.383572  [96000/141921]\n",
      "loss: 0.520811  [99200/141921]\n",
      "loss: 0.430739  [102400/141921]\n",
      "loss: 0.429830  [105600/141921]\n",
      "loss: 0.660610  [108800/141921]\n",
      "loss: 0.395915  [112000/141921]\n",
      "loss: 0.546125  [115200/141921]\n",
      "loss: 0.483147  [118400/141921]\n",
      "loss: 0.489967  [121600/141921]\n",
      "loss: 0.525734  [124800/141921]\n",
      "loss: 0.579655  [128000/141921]\n",
      "loss: 0.402276  [131200/141921]\n",
      "loss: 0.427397  [134400/141921]\n",
      "loss: 0.599311  [137600/141921]\n",
      "loss: 0.502810  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.494936 \n",
      "\n",
      "Epoch 34\n",
      "---------------------------\n",
      "loss: 0.407358  [ 3200/141921]\n",
      "loss: 0.493481  [ 6400/141921]\n",
      "loss: 0.472131  [ 9600/141921]\n",
      "loss: 0.370353  [12800/141921]\n",
      "loss: 0.541572  [16000/141921]\n",
      "loss: 0.468569  [19200/141921]\n",
      "loss: 0.534263  [22400/141921]\n",
      "loss: 0.444340  [25600/141921]\n",
      "loss: 0.473892  [28800/141921]\n",
      "loss: 0.339281  [32000/141921]\n",
      "loss: 0.488942  [35200/141921]\n",
      "loss: 0.470817  [38400/141921]\n",
      "loss: 0.495404  [41600/141921]\n",
      "loss: 0.488702  [44800/141921]\n",
      "loss: 0.598610  [48000/141921]\n",
      "loss: 0.411045  [51200/141921]\n",
      "loss: 0.457744  [54400/141921]\n",
      "loss: 0.513424  [57600/141921]\n",
      "loss: 0.482342  [60800/141921]\n",
      "loss: 0.559581  [64000/141921]\n",
      "loss: 0.588152  [67200/141921]\n",
      "loss: 0.632956  [70400/141921]\n",
      "loss: 0.370429  [73600/141921]\n",
      "loss: 0.544001  [76800/141921]\n",
      "loss: 0.513488  [80000/141921]\n",
      "loss: 0.458267  [83200/141921]\n",
      "loss: 0.453050  [86400/141921]\n",
      "loss: 0.649301  [89600/141921]\n",
      "loss: 0.423259  [92800/141921]\n",
      "loss: 0.548655  [96000/141921]\n",
      "loss: 0.471463  [99200/141921]\n",
      "loss: 0.578394  [102400/141921]\n",
      "loss: 0.471301  [105600/141921]\n",
      "loss: 0.560132  [108800/141921]\n",
      "loss: 0.536123  [112000/141921]\n",
      "loss: 0.406492  [115200/141921]\n",
      "loss: 0.563232  [118400/141921]\n",
      "loss: 0.563593  [121600/141921]\n",
      "loss: 0.517527  [124800/141921]\n",
      "loss: 0.448974  [128000/141921]\n",
      "loss: 0.419315  [131200/141921]\n",
      "loss: 0.551104  [134400/141921]\n",
      "loss: 0.414146  [137600/141921]\n",
      "loss: 0.339904  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.476091 \n",
      "\n",
      "Epoch 35\n",
      "---------------------------\n",
      "loss: 0.439553  [ 3200/141921]\n",
      "loss: 0.361363  [ 6400/141921]\n",
      "loss: 0.439028  [ 9600/141921]\n",
      "loss: 0.461361  [12800/141921]\n",
      "loss: 0.380860  [16000/141921]\n",
      "loss: 0.399395  [19200/141921]\n",
      "loss: 0.555098  [22400/141921]\n",
      "loss: 0.555574  [25600/141921]\n",
      "loss: 0.428740  [28800/141921]\n",
      "loss: 0.530088  [32000/141921]\n",
      "loss: 0.474980  [35200/141921]\n",
      "loss: 0.421233  [38400/141921]\n",
      "loss: 0.498440  [41600/141921]\n",
      "loss: 0.521441  [44800/141921]\n",
      "loss: 0.547508  [48000/141921]\n",
      "loss: 0.417199  [51200/141921]\n",
      "loss: 0.504158  [54400/141921]\n",
      "loss: 0.472989  [57600/141921]\n",
      "loss: 0.442321  [60800/141921]\n",
      "loss: 0.411332  [64000/141921]\n",
      "loss: 0.494713  [67200/141921]\n",
      "loss: 0.608842  [70400/141921]\n",
      "loss: 0.497785  [73600/141921]\n",
      "loss: 0.475712  [76800/141921]\n",
      "loss: 0.444455  [80000/141921]\n",
      "loss: 0.551806  [83200/141921]\n",
      "loss: 0.475180  [86400/141921]\n",
      "loss: 0.424831  [89600/141921]\n",
      "loss: 0.452830  [92800/141921]\n",
      "loss: 0.717296  [96000/141921]\n",
      "loss: 0.432554  [99200/141921]\n",
      "loss: 0.463775  [102400/141921]\n",
      "loss: 0.397435  [105600/141921]\n",
      "loss: 0.483889  [108800/141921]\n",
      "loss: 0.363548  [112000/141921]\n",
      "loss: 0.369796  [115200/141921]\n",
      "loss: 0.552177  [118400/141921]\n",
      "loss: 0.472778  [121600/141921]\n",
      "loss: 0.576389  [124800/141921]\n",
      "loss: 0.492512  [128000/141921]\n",
      "loss: 0.595151  [131200/141921]\n",
      "loss: 0.553303  [134400/141921]\n",
      "loss: 0.472468  [137600/141921]\n",
      "loss: 0.556234  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.583941 \n",
      "\n",
      "Epoch 36\n",
      "---------------------------\n",
      "loss: 0.459626  [ 3200/141921]\n",
      "loss: 0.499130  [ 6400/141921]\n",
      "loss: 0.589574  [ 9600/141921]\n",
      "loss: 0.500320  [12800/141921]\n",
      "loss: 0.514862  [16000/141921]\n",
      "loss: 0.602591  [19200/141921]\n",
      "loss: 0.535384  [22400/141921]\n",
      "loss: 0.483025  [25600/141921]\n",
      "loss: 0.416267  [28800/141921]\n",
      "loss: 0.447140  [32000/141921]\n",
      "loss: 0.409274  [35200/141921]\n",
      "loss: 0.482034  [38400/141921]\n",
      "loss: 0.588446  [41600/141921]\n",
      "loss: 0.548927  [44800/141921]\n",
      "loss: 0.519439  [48000/141921]\n",
      "loss: 0.429806  [51200/141921]\n",
      "loss: 0.411652  [54400/141921]\n",
      "loss: 0.348864  [57600/141921]\n",
      "loss: 0.564186  [60800/141921]\n",
      "loss: 0.396934  [64000/141921]\n",
      "loss: 0.413011  [67200/141921]\n",
      "loss: 0.434096  [70400/141921]\n",
      "loss: 0.416706  [73600/141921]\n",
      "loss: 0.482516  [76800/141921]\n",
      "loss: 0.564030  [80000/141921]\n",
      "loss: 0.408702  [83200/141921]\n",
      "loss: 0.466644  [86400/141921]\n",
      "loss: 0.398067  [89600/141921]\n",
      "loss: 0.560699  [92800/141921]\n",
      "loss: 0.438649  [96000/141921]\n",
      "loss: 0.445604  [99200/141921]\n",
      "loss: 0.388484  [102400/141921]\n",
      "loss: 0.610481  [105600/141921]\n",
      "loss: 0.521254  [108800/141921]\n",
      "loss: 0.413399  [112000/141921]\n",
      "loss: 0.496684  [115200/141921]\n",
      "loss: 0.371735  [118400/141921]\n",
      "loss: 0.431267  [121600/141921]\n",
      "loss: 0.333382  [124800/141921]\n",
      "loss: 0.508372  [128000/141921]\n",
      "loss: 0.456460  [131200/141921]\n",
      "loss: 0.467651  [134400/141921]\n",
      "loss: 0.435623  [137600/141921]\n",
      "loss: 0.416771  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.537290 \n",
      "\n",
      "Epoch 37\n",
      "---------------------------\n",
      "loss: 0.470020  [ 3200/141921]\n",
      "loss: 0.504028  [ 6400/141921]\n",
      "loss: 0.525201  [ 9600/141921]\n",
      "loss: 0.458061  [12800/141921]\n",
      "loss: 0.424162  [16000/141921]\n",
      "loss: 0.352978  [19200/141921]\n",
      "loss: 0.397243  [22400/141921]\n",
      "loss: 0.454004  [25600/141921]\n",
      "loss: 0.440985  [28800/141921]\n",
      "loss: 0.451759  [32000/141921]\n",
      "loss: 0.428553  [35200/141921]\n",
      "loss: 0.418085  [38400/141921]\n",
      "loss: 0.523220  [41600/141921]\n",
      "loss: 0.481211  [44800/141921]\n",
      "loss: 0.381242  [48000/141921]\n",
      "loss: 0.510013  [51200/141921]\n",
      "loss: 0.403634  [54400/141921]\n",
      "loss: 0.426950  [57600/141921]\n",
      "loss: 0.402544  [60800/141921]\n",
      "loss: 0.485567  [64000/141921]\n",
      "loss: 0.695069  [67200/141921]\n",
      "loss: 0.576594  [70400/141921]\n",
      "loss: 0.422737  [73600/141921]\n",
      "loss: 0.567570  [76800/141921]\n",
      "loss: 0.538079  [80000/141921]\n",
      "loss: 0.466498  [83200/141921]\n",
      "loss: 0.476544  [86400/141921]\n",
      "loss: 0.416876  [89600/141921]\n",
      "loss: 0.459232  [92800/141921]\n",
      "loss: 0.427212  [96000/141921]\n",
      "loss: 0.492082  [99200/141921]\n",
      "loss: 0.495400  [102400/141921]\n",
      "loss: 0.480193  [105600/141921]\n",
      "loss: 0.467620  [108800/141921]\n",
      "loss: 0.618658  [112000/141921]\n",
      "loss: 0.432718  [115200/141921]\n",
      "loss: 0.555688  [118400/141921]\n",
      "loss: 0.407397  [121600/141921]\n",
      "loss: 0.432866  [124800/141921]\n",
      "loss: 0.366477  [128000/141921]\n",
      "loss: 0.441655  [131200/141921]\n",
      "loss: 0.328834  [134400/141921]\n",
      "loss: 0.441008  [137600/141921]\n",
      "loss: 0.454679  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.468393 \n",
      "\n",
      "Epoch 38\n",
      "---------------------------\n",
      "loss: 0.423964  [ 3200/141921]\n",
      "loss: 0.502503  [ 6400/141921]\n",
      "loss: 0.450397  [ 9600/141921]\n",
      "loss: 0.494857  [12800/141921]\n",
      "loss: 0.458990  [16000/141921]\n",
      "loss: 0.470937  [19200/141921]\n",
      "loss: 0.579615  [22400/141921]\n",
      "loss: 0.514685  [25600/141921]\n",
      "loss: 0.469500  [28800/141921]\n",
      "loss: 0.564994  [32000/141921]\n",
      "loss: 0.432887  [35200/141921]\n",
      "loss: 0.373785  [38400/141921]\n",
      "loss: 0.527679  [41600/141921]\n",
      "loss: 0.431279  [44800/141921]\n",
      "loss: 0.455396  [48000/141921]\n",
      "loss: 0.490923  [51200/141921]\n",
      "loss: 0.648416  [54400/141921]\n",
      "loss: 0.413447  [57600/141921]\n",
      "loss: 0.426261  [60800/141921]\n",
      "loss: 0.381622  [64000/141921]\n",
      "loss: 0.458480  [67200/141921]\n",
      "loss: 0.436628  [70400/141921]\n",
      "loss: 0.308261  [73600/141921]\n",
      "loss: 0.638612  [76800/141921]\n",
      "loss: 0.524305  [80000/141921]\n",
      "loss: 0.473973  [83200/141921]\n",
      "loss: 0.583560  [86400/141921]\n",
      "loss: 0.483047  [89600/141921]\n",
      "loss: 0.395848  [92800/141921]\n",
      "loss: 0.471295  [96000/141921]\n",
      "loss: 0.502879  [99200/141921]\n",
      "loss: 0.482103  [102400/141921]\n",
      "loss: 0.417508  [105600/141921]\n",
      "loss: 0.498705  [108800/141921]\n",
      "loss: 0.434740  [112000/141921]\n",
      "loss: 0.411147  [115200/141921]\n",
      "loss: 0.519817  [118400/141921]\n",
      "loss: 0.467945  [121600/141921]\n",
      "loss: 0.561547  [124800/141921]\n",
      "loss: 0.629039  [128000/141921]\n",
      "loss: 0.530287  [131200/141921]\n",
      "loss: 0.537528  [134400/141921]\n",
      "loss: 0.401523  [137600/141921]\n",
      "loss: 0.568017  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.478006 \n",
      "\n",
      "Epoch 39\n",
      "---------------------------\n",
      "loss: 0.479743  [ 3200/141921]\n",
      "loss: 0.379110  [ 6400/141921]\n",
      "loss: 0.435636  [ 9600/141921]\n",
      "loss: 0.452611  [12800/141921]\n",
      "loss: 0.433768  [16000/141921]\n",
      "loss: 0.480576  [19200/141921]\n",
      "loss: 0.567094  [22400/141921]\n",
      "loss: 0.388021  [25600/141921]\n",
      "loss: 0.425529  [28800/141921]\n",
      "loss: 0.427134  [32000/141921]\n",
      "loss: 0.397707  [35200/141921]\n",
      "loss: 0.515868  [38400/141921]\n",
      "loss: 0.380000  [41600/141921]\n",
      "loss: 0.495120  [44800/141921]\n",
      "loss: 0.390383  [48000/141921]\n",
      "loss: 0.374621  [51200/141921]\n",
      "loss: 0.485932  [54400/141921]\n",
      "loss: 0.465663  [57600/141921]\n",
      "loss: 0.405382  [60800/141921]\n",
      "loss: 0.446142  [64000/141921]\n",
      "loss: 0.568010  [67200/141921]\n",
      "loss: 0.467414  [70400/141921]\n",
      "loss: 0.540843  [73600/141921]\n",
      "loss: 0.503805  [76800/141921]\n",
      "loss: 0.399682  [80000/141921]\n",
      "loss: 0.592946  [83200/141921]\n",
      "loss: 0.493480  [86400/141921]\n",
      "loss: 0.523131  [89600/141921]\n",
      "loss: 0.443436  [92800/141921]\n",
      "loss: 0.470629  [96000/141921]\n",
      "loss: 0.379807  [99200/141921]\n",
      "loss: 0.415514  [102400/141921]\n",
      "loss: 0.422588  [105600/141921]\n",
      "loss: 0.504616  [108800/141921]\n",
      "loss: 0.307212  [112000/141921]\n",
      "loss: 0.409059  [115200/141921]\n",
      "loss: 0.446778  [118400/141921]\n",
      "loss: 0.614041  [121600/141921]\n",
      "loss: 0.355500  [124800/141921]\n",
      "loss: 0.479004  [128000/141921]\n",
      "loss: 0.426221  [131200/141921]\n",
      "loss: 0.548137  [134400/141921]\n",
      "loss: 0.401752  [137600/141921]\n",
      "loss: 0.439695  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.474106 \n",
      "\n",
      "Epoch 40\n",
      "---------------------------\n",
      "loss: 0.463403  [ 3200/141921]\n",
      "loss: 0.379510  [ 6400/141921]\n",
      "loss: 0.529809  [ 9600/141921]\n",
      "loss: 0.448615  [12800/141921]\n",
      "loss: 0.450666  [16000/141921]\n",
      "loss: 0.465932  [19200/141921]\n",
      "loss: 0.406526  [22400/141921]\n",
      "loss: 0.498165  [25600/141921]\n",
      "loss: 0.402210  [28800/141921]\n",
      "loss: 0.481000  [32000/141921]\n",
      "loss: 0.356789  [35200/141921]\n",
      "loss: 0.496253  [38400/141921]\n",
      "loss: 0.371291  [41600/141921]\n",
      "loss: 0.325313  [44800/141921]\n",
      "loss: 0.458360  [48000/141921]\n",
      "loss: 0.475951  [51200/141921]\n",
      "loss: 0.361524  [54400/141921]\n",
      "loss: 0.461242  [57600/141921]\n",
      "loss: 0.523399  [60800/141921]\n",
      "loss: 0.426422  [64000/141921]\n",
      "loss: 0.480499  [67200/141921]\n",
      "loss: 0.343156  [70400/141921]\n",
      "loss: 0.466948  [73600/141921]\n",
      "loss: 0.507059  [76800/141921]\n",
      "loss: 0.422253  [80000/141921]\n",
      "loss: 0.617619  [83200/141921]\n",
      "loss: 0.458056  [86400/141921]\n",
      "loss: 0.452654  [89600/141921]\n",
      "loss: 0.398360  [92800/141921]\n",
      "loss: 0.437712  [96000/141921]\n",
      "loss: 0.518646  [99200/141921]\n",
      "loss: 0.447066  [102400/141921]\n",
      "loss: 0.313960  [105600/141921]\n",
      "loss: 0.508799  [108800/141921]\n",
      "loss: 0.525551  [112000/141921]\n",
      "loss: 0.380589  [115200/141921]\n",
      "loss: 0.493773  [118400/141921]\n",
      "loss: 0.513114  [121600/141921]\n",
      "loss: 0.398190  [124800/141921]\n",
      "loss: 0.364087  [128000/141921]\n",
      "loss: 0.573886  [131200/141921]\n",
      "loss: 0.278350  [134400/141921]\n",
      "loss: 0.607609  [137600/141921]\n",
      "loss: 0.501719  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.470020 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(sn_train_dataloader, sn_model, loss_fn, sn_optimizer)\n",
    "    test_loop(sn_test_dataloader, sn_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
