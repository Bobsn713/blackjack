{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "991806d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ceab1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n",
    "rank_to_index = {rank: i for i, rank in enumerate(ranks)}\n",
    "rank_len = len(ranks)\n",
    "\n",
    "#Helper functions for data processing\n",
    "def card_to_vec(card):\n",
    "    raw_rank = card[:-1]\n",
    "    one_hot_vector = [0] * rank_len\n",
    "    one_hot_vector[rank_to_index[raw_rank]] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_vec(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f9ef0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "hit_stand_dd_df = pd.read_csv('CSVs/hit_stand_dd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70b8eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsd_train_df, hsd_test_df = train_test_split(hit_stand_dd_df, test_size = 0.2)\n",
    "\n",
    "def clean_up(dataframe_raw):\n",
    "    # Cleaned hit_stand_dd\n",
    "    max_len = 7\n",
    "    dataframe_raw['dealer_upcard'] = dataframe_raw['dealer_upcard'].apply(card_to_vec)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(hand_to_list)\n",
    "    dataframe_raw['result'] = dataframe_raw['result'].map(result_mapping)\n",
    "    \n",
    "    zero_vector = [0] * rank_len\n",
    "    padded_hands = []\n",
    "    for hand in dataframe_raw['player_hand']:\n",
    "        if len(hand) < max_len:\n",
    "            padded_hand = hand + [zero_vector] * (max_len - len(hand))\n",
    "        else: \n",
    "            padded_hand = hand[:max_len]\n",
    "        padded_hands.append(padded_hand)\n",
    "    dataframe_raw['player_hand'] = padded_hands\n",
    "\n",
    "    # Flattening\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(lambda hand: [item for card_vec in hand for item in card_vec])\n",
    "    \n",
    "    # Turning into tensor matrices\n",
    "    # hit_stand_dd\n",
    "    x1 = torch.tensor(dataframe_raw['player_hand'].to_list(), dtype=torch.float32)\n",
    "    x2 = torch.tensor(dataframe_raw['dealer_upcard'].to_list(), dtype=torch.float32)\n",
    "    x3 = torch.tensor(dataframe_raw['can_double'].values, dtype=torch.float32).unsqueeze(1)\n",
    "    y = torch.tensor(dataframe_raw['result'].values, dtype=torch.long)\n",
    "\n",
    "    X = torch.cat([x1,x2,x3], dim=1)\n",
    "\n",
    "    return Blackjack_Dataset(X,y)\n",
    "\n",
    "hsd_train_dataset = clean_up(hsd_train_df)\n",
    "hsd_test_dataset = clean_up(hsd_test_df)\n",
    "\n",
    "hsd_train_dataloader = DataLoader(hsd_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "hsd_test_dataloader = DataLoader(hsd_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97c76ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 105])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X, y in hsd_train_dataloader:\n",
    "    print(X.shape)  # input batch shape: (batch_size, input_features)\n",
    "    print(y.shape)  # target batch shape: (batch_size,) or (batch_size, something)\n",
    "    break  # just one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7dd46cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    test_accs.append(100*correct)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93418e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hsd_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(105, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "hsd_model = hsd_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.02\n",
    "epochs = 80\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "hsd_optimizer = torch.optim.SGD(hsd_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6bb83a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.927867  [ 3200/209452]\n",
      "loss: 0.929596  [ 6400/209452]\n",
      "loss: 0.895415  [ 9600/209452]\n",
      "loss: 0.883648  [12800/209452]\n",
      "loss: 0.875630  [16000/209452]\n",
      "loss: 0.963801  [19200/209452]\n",
      "loss: 0.860956  [22400/209452]\n",
      "loss: 1.018355  [25600/209452]\n",
      "loss: 1.069070  [28800/209452]\n",
      "loss: 0.878399  [32000/209452]\n",
      "loss: 0.757014  [35200/209452]\n",
      "loss: 0.668822  [38400/209452]\n",
      "loss: 0.687241  [41600/209452]\n",
      "loss: 0.714075  [44800/209452]\n",
      "loss: 0.518746  [48000/209452]\n",
      "loss: 0.617971  [51200/209452]\n",
      "loss: 0.455782  [54400/209452]\n",
      "loss: 0.368785  [57600/209452]\n",
      "loss: 0.539719  [60800/209452]\n",
      "loss: 0.624676  [64000/209452]\n",
      "loss: 0.427964  [67200/209452]\n",
      "loss: 0.358485  [70400/209452]\n",
      "loss: 0.354833  [73600/209452]\n",
      "loss: 0.553433  [76800/209452]\n",
      "loss: 0.232051  [80000/209452]\n",
      "loss: 0.477006  [83200/209452]\n",
      "loss: 0.510763  [86400/209452]\n",
      "loss: 0.584278  [89600/209452]\n",
      "loss: 0.350896  [92800/209452]\n",
      "loss: 0.347620  [96000/209452]\n",
      "loss: 0.331902  [99200/209452]\n",
      "loss: 0.309565  [102400/209452]\n",
      "loss: 0.466898  [105600/209452]\n",
      "loss: 0.427087  [108800/209452]\n",
      "loss: 0.359054  [112000/209452]\n",
      "loss: 0.326292  [115200/209452]\n",
      "loss: 0.612058  [118400/209452]\n",
      "loss: 0.269548  [121600/209452]\n",
      "loss: 0.375219  [124800/209452]\n",
      "loss: 0.172434  [128000/209452]\n",
      "loss: 0.484008  [131200/209452]\n",
      "loss: 0.391763  [134400/209452]\n",
      "loss: 0.201219  [137600/209452]\n",
      "loss: 0.243569  [140800/209452]\n",
      "loss: 0.260967  [144000/209452]\n",
      "loss: 0.369202  [147200/209452]\n",
      "loss: 0.491963  [150400/209452]\n",
      "loss: 0.171280  [153600/209452]\n",
      "loss: 0.217865  [156800/209452]\n",
      "loss: 0.327453  [160000/209452]\n",
      "loss: 0.190173  [163200/209452]\n",
      "loss: 0.373856  [166400/209452]\n",
      "loss: 0.259105  [169600/209452]\n",
      "loss: 0.275353  [172800/209452]\n",
      "loss: 0.301253  [176000/209452]\n",
      "loss: 0.295886  [179200/209452]\n",
      "loss: 0.385072  [182400/209452]\n",
      "loss: 0.334961  [185600/209452]\n",
      "loss: 0.166450  [188800/209452]\n",
      "loss: 0.297153  [192000/209452]\n",
      "loss: 0.120068  [195200/209452]\n",
      "loss: 0.224027  [198400/209452]\n",
      "loss: 0.208151  [201600/209452]\n",
      "loss: 0.182460  [204800/209452]\n",
      "loss: 0.181373  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.232991 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 0.308016  [ 3200/209452]\n",
      "loss: 0.242076  [ 6400/209452]\n",
      "loss: 0.230623  [ 9600/209452]\n",
      "loss: 0.285781  [12800/209452]\n",
      "loss: 0.198349  [16000/209452]\n",
      "loss: 0.307021  [19200/209452]\n",
      "loss: 0.215725  [22400/209452]\n",
      "loss: 0.253776  [25600/209452]\n",
      "loss: 0.384332  [28800/209452]\n",
      "loss: 0.103644  [32000/209452]\n",
      "loss: 0.125819  [35200/209452]\n",
      "loss: 0.127664  [38400/209452]\n",
      "loss: 0.239056  [41600/209452]\n",
      "loss: 0.178619  [44800/209452]\n",
      "loss: 0.156697  [48000/209452]\n",
      "loss: 0.233376  [51200/209452]\n",
      "loss: 0.182174  [54400/209452]\n",
      "loss: 0.150308  [57600/209452]\n",
      "loss: 0.177473  [60800/209452]\n",
      "loss: 0.094245  [64000/209452]\n",
      "loss: 0.173019  [67200/209452]\n",
      "loss: 0.202598  [70400/209452]\n",
      "loss: 0.135076  [73600/209452]\n",
      "loss: 0.121449  [76800/209452]\n",
      "loss: 0.049028  [80000/209452]\n",
      "loss: 0.137559  [83200/209452]\n",
      "loss: 0.231901  [86400/209452]\n",
      "loss: 0.126689  [89600/209452]\n",
      "loss: 0.157584  [92800/209452]\n",
      "loss: 0.093372  [96000/209452]\n",
      "loss: 0.117770  [99200/209452]\n",
      "loss: 0.137418  [102400/209452]\n",
      "loss: 0.098039  [105600/209452]\n",
      "loss: 0.137814  [108800/209452]\n",
      "loss: 0.113563  [112000/209452]\n",
      "loss: 0.102234  [115200/209452]\n",
      "loss: 0.114254  [118400/209452]\n",
      "loss: 0.152627  [121600/209452]\n",
      "loss: 0.104890  [124800/209452]\n",
      "loss: 0.110895  [128000/209452]\n",
      "loss: 0.234394  [131200/209452]\n",
      "loss: 0.119473  [134400/209452]\n",
      "loss: 0.067525  [137600/209452]\n",
      "loss: 0.121549  [140800/209452]\n",
      "loss: 0.133642  [144000/209452]\n",
      "loss: 0.049356  [147200/209452]\n",
      "loss: 0.092678  [150400/209452]\n",
      "loss: 0.139313  [153600/209452]\n",
      "loss: 0.084083  [156800/209452]\n",
      "loss: 0.106919  [160000/209452]\n",
      "loss: 0.061780  [163200/209452]\n",
      "loss: 0.112662  [166400/209452]\n",
      "loss: 0.156816  [169600/209452]\n",
      "loss: 0.058117  [172800/209452]\n",
      "loss: 0.158029  [176000/209452]\n",
      "loss: 0.253686  [179200/209452]\n",
      "loss: 0.102219  [182400/209452]\n",
      "loss: 0.044211  [185600/209452]\n",
      "loss: 0.145070  [188800/209452]\n",
      "loss: 0.134076  [192000/209452]\n",
      "loss: 0.068468  [195200/209452]\n",
      "loss: 0.078293  [198400/209452]\n",
      "loss: 0.070981  [201600/209452]\n",
      "loss: 0.113860  [204800/209452]\n",
      "loss: 0.073222  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.089113 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 0.058492  [ 3200/209452]\n",
      "loss: 0.063393  [ 6400/209452]\n",
      "loss: 0.064782  [ 9600/209452]\n",
      "loss: 0.124823  [12800/209452]\n",
      "loss: 0.040132  [16000/209452]\n",
      "loss: 0.029060  [19200/209452]\n",
      "loss: 0.037686  [22400/209452]\n",
      "loss: 0.246017  [25600/209452]\n",
      "loss: 0.068870  [28800/209452]\n",
      "loss: 0.139955  [32000/209452]\n",
      "loss: 0.130827  [35200/209452]\n",
      "loss: 0.127920  [38400/209452]\n",
      "loss: 0.099839  [41600/209452]\n",
      "loss: 0.031334  [44800/209452]\n",
      "loss: 0.034688  [48000/209452]\n",
      "loss: 0.075049  [51200/209452]\n",
      "loss: 0.196034  [54400/209452]\n",
      "loss: 0.039151  [57600/209452]\n",
      "loss: 0.090185  [60800/209452]\n",
      "loss: 0.024491  [64000/209452]\n",
      "loss: 0.032072  [67200/209452]\n",
      "loss: 0.115393  [70400/209452]\n",
      "loss: 0.033193  [73600/209452]\n",
      "loss: 0.060617  [76800/209452]\n",
      "loss: 0.060439  [80000/209452]\n",
      "loss: 0.040179  [83200/209452]\n",
      "loss: 0.138800  [86400/209452]\n",
      "loss: 0.087655  [89600/209452]\n",
      "loss: 0.042967  [92800/209452]\n",
      "loss: 0.060838  [96000/209452]\n",
      "loss: 0.091862  [99200/209452]\n",
      "loss: 0.091941  [102400/209452]\n",
      "loss: 0.069083  [105600/209452]\n",
      "loss: 0.023620  [108800/209452]\n",
      "loss: 0.016997  [112000/209452]\n",
      "loss: 0.165805  [115200/209452]\n",
      "loss: 0.017535  [118400/209452]\n",
      "loss: 0.024887  [121600/209452]\n",
      "loss: 0.070186  [124800/209452]\n",
      "loss: 0.040516  [128000/209452]\n",
      "loss: 0.021574  [131200/209452]\n",
      "loss: 0.030597  [134400/209452]\n",
      "loss: 0.040901  [137600/209452]\n",
      "loss: 0.067750  [140800/209452]\n",
      "loss: 0.031728  [144000/209452]\n",
      "loss: 0.027223  [147200/209452]\n",
      "loss: 0.074589  [150400/209452]\n",
      "loss: 0.079835  [153600/209452]\n",
      "loss: 0.045190  [156800/209452]\n",
      "loss: 0.027798  [160000/209452]\n",
      "loss: 0.056477  [163200/209452]\n",
      "loss: 0.031241  [166400/209452]\n",
      "loss: 0.070299  [169600/209452]\n",
      "loss: 0.094081  [172800/209452]\n",
      "loss: 0.058550  [176000/209452]\n",
      "loss: 0.093442  [179200/209452]\n",
      "loss: 0.013427  [182400/209452]\n",
      "loss: 0.033950  [185600/209452]\n",
      "loss: 0.027229  [188800/209452]\n",
      "loss: 0.060805  [192000/209452]\n",
      "loss: 0.016575  [195200/209452]\n",
      "loss: 0.019123  [198400/209452]\n",
      "loss: 0.042830  [201600/209452]\n",
      "loss: 0.033742  [204800/209452]\n",
      "loss: 0.032791  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.047782 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 0.022682  [ 3200/209452]\n",
      "loss: 0.005074  [ 6400/209452]\n",
      "loss: 0.027002  [ 9600/209452]\n",
      "loss: 0.008507  [12800/209452]\n",
      "loss: 0.054961  [16000/209452]\n",
      "loss: 0.149716  [19200/209452]\n",
      "loss: 0.053052  [22400/209452]\n",
      "loss: 0.056062  [25600/209452]\n",
      "loss: 0.045383  [28800/209452]\n",
      "loss: 0.041532  [32000/209452]\n",
      "loss: 0.121886  [35200/209452]\n",
      "loss: 0.053583  [38400/209452]\n",
      "loss: 0.044977  [41600/209452]\n",
      "loss: 0.018096  [44800/209452]\n",
      "loss: 0.027700  [48000/209452]\n",
      "loss: 0.009410  [51200/209452]\n",
      "loss: 0.036763  [54400/209452]\n",
      "loss: 0.040626  [57600/209452]\n",
      "loss: 0.012527  [60800/209452]\n",
      "loss: 0.030876  [64000/209452]\n",
      "loss: 0.060451  [67200/209452]\n",
      "loss: 0.103075  [70400/209452]\n",
      "loss: 0.017942  [73600/209452]\n",
      "loss: 0.018785  [76800/209452]\n",
      "loss: 0.069520  [80000/209452]\n",
      "loss: 0.014891  [83200/209452]\n",
      "loss: 0.033149  [86400/209452]\n",
      "loss: 0.011626  [89600/209452]\n",
      "loss: 0.013023  [92800/209452]\n",
      "loss: 0.011636  [96000/209452]\n",
      "loss: 0.022881  [99200/209452]\n",
      "loss: 0.018480  [102400/209452]\n",
      "loss: 0.022990  [105600/209452]\n",
      "loss: 0.052680  [108800/209452]\n",
      "loss: 0.006875  [112000/209452]\n",
      "loss: 0.152827  [115200/209452]\n",
      "loss: 0.036669  [118400/209452]\n",
      "loss: 0.130288  [121600/209452]\n",
      "loss: 0.016418  [124800/209452]\n",
      "loss: 0.060548  [128000/209452]\n",
      "loss: 0.038723  [131200/209452]\n",
      "loss: 0.024549  [134400/209452]\n",
      "loss: 0.050823  [137600/209452]\n",
      "loss: 0.017829  [140800/209452]\n",
      "loss: 0.032423  [144000/209452]\n",
      "loss: 0.026528  [147200/209452]\n",
      "loss: 0.014674  [150400/209452]\n",
      "loss: 0.029411  [153600/209452]\n",
      "loss: 0.012887  [156800/209452]\n",
      "loss: 0.059646  [160000/209452]\n",
      "loss: 0.021393  [163200/209452]\n",
      "loss: 0.048431  [166400/209452]\n",
      "loss: 0.017138  [169600/209452]\n",
      "loss: 0.012262  [172800/209452]\n",
      "loss: 0.042515  [176000/209452]\n",
      "loss: 0.032673  [179200/209452]\n",
      "loss: 0.037330  [182400/209452]\n",
      "loss: 0.020847  [185600/209452]\n",
      "loss: 0.018784  [188800/209452]\n",
      "loss: 0.009700  [192000/209452]\n",
      "loss: 0.013762  [195200/209452]\n",
      "loss: 0.060788  [198400/209452]\n",
      "loss: 0.015644  [201600/209452]\n",
      "loss: 0.021501  [204800/209452]\n",
      "loss: 0.023040  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033092 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 0.032083  [ 3200/209452]\n",
      "loss: 0.032670  [ 6400/209452]\n",
      "loss: 0.023538  [ 9600/209452]\n",
      "loss: 0.004215  [12800/209452]\n",
      "loss: 0.036480  [16000/209452]\n",
      "loss: 0.198186  [19200/209452]\n",
      "loss: 0.014683  [22400/209452]\n",
      "loss: 0.010427  [25600/209452]\n",
      "loss: 0.015722  [28800/209452]\n",
      "loss: 0.010599  [32000/209452]\n",
      "loss: 0.009175  [35200/209452]\n",
      "loss: 0.020532  [38400/209452]\n",
      "loss: 0.018885  [41600/209452]\n",
      "loss: 0.028768  [44800/209452]\n",
      "loss: 0.086915  [48000/209452]\n",
      "loss: 0.034503  [51200/209452]\n",
      "loss: 0.014097  [54400/209452]\n",
      "loss: 0.014483  [57600/209452]\n",
      "loss: 0.053231  [60800/209452]\n",
      "loss: 0.018947  [64000/209452]\n",
      "loss: 0.024513  [67200/209452]\n",
      "loss: 0.027510  [70400/209452]\n",
      "loss: 0.025607  [73600/209452]\n",
      "loss: 0.081826  [76800/209452]\n",
      "loss: 0.033506  [80000/209452]\n",
      "loss: 0.004171  [83200/209452]\n",
      "loss: 0.010405  [86400/209452]\n",
      "loss: 0.023377  [89600/209452]\n",
      "loss: 0.018107  [92800/209452]\n",
      "loss: 0.021156  [96000/209452]\n",
      "loss: 0.015756  [99200/209452]\n",
      "loss: 0.079210  [102400/209452]\n",
      "loss: 0.030174  [105600/209452]\n",
      "loss: 0.030951  [108800/209452]\n",
      "loss: 0.082395  [112000/209452]\n",
      "loss: 0.003120  [115200/209452]\n",
      "loss: 0.007064  [118400/209452]\n",
      "loss: 0.036123  [121600/209452]\n",
      "loss: 0.004736  [124800/209452]\n",
      "loss: 0.007698  [128000/209452]\n",
      "loss: 0.026267  [131200/209452]\n",
      "loss: 0.011466  [134400/209452]\n",
      "loss: 0.016677  [137600/209452]\n",
      "loss: 0.009871  [140800/209452]\n",
      "loss: 0.041876  [144000/209452]\n",
      "loss: 0.013825  [147200/209452]\n",
      "loss: 0.015170  [150400/209452]\n",
      "loss: 0.005517  [153600/209452]\n",
      "loss: 0.045693  [156800/209452]\n",
      "loss: 0.038255  [160000/209452]\n",
      "loss: 0.005918  [163200/209452]\n",
      "loss: 0.005863  [166400/209452]\n",
      "loss: 0.026530  [169600/209452]\n",
      "loss: 0.014625  [172800/209452]\n",
      "loss: 0.010259  [176000/209452]\n",
      "loss: 0.010793  [179200/209452]\n",
      "loss: 0.087789  [182400/209452]\n",
      "loss: 0.027909  [185600/209452]\n",
      "loss: 0.017206  [188800/209452]\n",
      "loss: 0.066971  [192000/209452]\n",
      "loss: 0.003112  [195200/209452]\n",
      "loss: 0.029271  [198400/209452]\n",
      "loss: 0.031845  [201600/209452]\n",
      "loss: 0.030870  [204800/209452]\n",
      "loss: 0.021258  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.024116 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 0.017916  [ 3200/209452]\n",
      "loss: 0.015274  [ 6400/209452]\n",
      "loss: 0.003847  [ 9600/209452]\n",
      "loss: 0.019674  [12800/209452]\n",
      "loss: 0.017451  [16000/209452]\n",
      "loss: 0.009128  [19200/209452]\n",
      "loss: 0.006998  [22400/209452]\n",
      "loss: 0.010341  [25600/209452]\n",
      "loss: 0.018407  [28800/209452]\n",
      "loss: 0.026726  [32000/209452]\n",
      "loss: 0.009214  [35200/209452]\n",
      "loss: 0.012614  [38400/209452]\n",
      "loss: 0.069764  [41600/209452]\n",
      "loss: 0.004764  [44800/209452]\n",
      "loss: 0.004649  [48000/209452]\n",
      "loss: 0.104938  [51200/209452]\n",
      "loss: 0.001570  [54400/209452]\n",
      "loss: 0.009385  [57600/209452]\n",
      "loss: 0.002256  [60800/209452]\n",
      "loss: 0.039746  [64000/209452]\n",
      "loss: 0.006272  [67200/209452]\n",
      "loss: 0.008899  [70400/209452]\n",
      "loss: 0.040407  [73600/209452]\n",
      "loss: 0.005722  [76800/209452]\n",
      "loss: 0.004297  [80000/209452]\n",
      "loss: 0.037032  [83200/209452]\n",
      "loss: 0.035409  [86400/209452]\n",
      "loss: 0.005744  [89600/209452]\n",
      "loss: 0.012084  [92800/209452]\n",
      "loss: 0.023687  [96000/209452]\n",
      "loss: 0.008474  [99200/209452]\n",
      "loss: 0.003502  [102400/209452]\n",
      "loss: 0.003630  [105600/209452]\n",
      "loss: 0.011698  [108800/209452]\n",
      "loss: 0.007109  [112000/209452]\n",
      "loss: 0.037137  [115200/209452]\n",
      "loss: 0.004055  [118400/209452]\n",
      "loss: 0.024264  [121600/209452]\n",
      "loss: 0.029736  [124800/209452]\n",
      "loss: 0.008461  [128000/209452]\n",
      "loss: 0.049354  [131200/209452]\n",
      "loss: 0.005237  [134400/209452]\n",
      "loss: 0.015359  [137600/209452]\n",
      "loss: 0.009518  [140800/209452]\n",
      "loss: 0.035685  [144000/209452]\n",
      "loss: 0.001869  [147200/209452]\n",
      "loss: 0.082569  [150400/209452]\n",
      "loss: 0.008687  [153600/209452]\n",
      "loss: 0.010773  [156800/209452]\n",
      "loss: 0.017566  [160000/209452]\n",
      "loss: 0.006943  [163200/209452]\n",
      "loss: 0.016499  [166400/209452]\n",
      "loss: 0.009337  [169600/209452]\n",
      "loss: 0.011345  [172800/209452]\n",
      "loss: 0.052972  [176000/209452]\n",
      "loss: 0.009018  [179200/209452]\n",
      "loss: 0.009719  [182400/209452]\n",
      "loss: 0.034063  [185600/209452]\n",
      "loss: 0.019464  [188800/209452]\n",
      "loss: 0.021392  [192000/209452]\n",
      "loss: 0.016020  [195200/209452]\n",
      "loss: 0.017911  [198400/209452]\n",
      "loss: 0.010895  [201600/209452]\n",
      "loss: 0.006405  [204800/209452]\n",
      "loss: 0.011844  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.018707 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 0.007095  [ 3200/209452]\n",
      "loss: 0.008067  [ 6400/209452]\n",
      "loss: 0.003376  [ 9600/209452]\n",
      "loss: 0.055199  [12800/209452]\n",
      "loss: 0.011301  [16000/209452]\n",
      "loss: 0.006354  [19200/209452]\n",
      "loss: 0.006106  [22400/209452]\n",
      "loss: 0.010063  [25600/209452]\n",
      "loss: 0.008131  [28800/209452]\n",
      "loss: 0.005371  [32000/209452]\n",
      "loss: 0.005645  [35200/209452]\n",
      "loss: 0.004100  [38400/209452]\n",
      "loss: 0.008002  [41600/209452]\n",
      "loss: 0.029596  [44800/209452]\n",
      "loss: 0.020902  [48000/209452]\n",
      "loss: 0.028994  [51200/209452]\n",
      "loss: 0.016200  [54400/209452]\n",
      "loss: 0.012630  [57600/209452]\n",
      "loss: 0.045509  [60800/209452]\n",
      "loss: 0.003967  [64000/209452]\n",
      "loss: 0.006692  [67200/209452]\n",
      "loss: 0.002647  [70400/209452]\n",
      "loss: 0.006056  [73600/209452]\n",
      "loss: 0.019353  [76800/209452]\n",
      "loss: 0.005247  [80000/209452]\n",
      "loss: 0.033050  [83200/209452]\n",
      "loss: 0.019719  [86400/209452]\n",
      "loss: 0.016716  [89600/209452]\n",
      "loss: 0.009690  [92800/209452]\n",
      "loss: 0.010023  [96000/209452]\n",
      "loss: 0.010165  [99200/209452]\n",
      "loss: 0.001260  [102400/209452]\n",
      "loss: 0.003124  [105600/209452]\n",
      "loss: 0.089839  [108800/209452]\n",
      "loss: 0.030313  [112000/209452]\n",
      "loss: 0.004748  [115200/209452]\n",
      "loss: 0.004755  [118400/209452]\n",
      "loss: 0.005841  [121600/209452]\n",
      "loss: 0.014453  [124800/209452]\n",
      "loss: 0.002131  [128000/209452]\n",
      "loss: 0.031567  [131200/209452]\n",
      "loss: 0.057104  [134400/209452]\n",
      "loss: 0.006173  [137600/209452]\n",
      "loss: 0.003848  [140800/209452]\n",
      "loss: 0.001751  [144000/209452]\n",
      "loss: 0.007298  [147200/209452]\n",
      "loss: 0.008195  [150400/209452]\n",
      "loss: 0.009190  [153600/209452]\n",
      "loss: 0.020347  [156800/209452]\n",
      "loss: 0.002315  [160000/209452]\n",
      "loss: 0.001968  [163200/209452]\n",
      "loss: 0.000339  [166400/209452]\n",
      "loss: 0.025481  [169600/209452]\n",
      "loss: 0.076896  [172800/209452]\n",
      "loss: 0.004680  [176000/209452]\n",
      "loss: 0.002408  [179200/209452]\n",
      "loss: 0.013604  [182400/209452]\n",
      "loss: 0.013907  [185600/209452]\n",
      "loss: 0.002901  [188800/209452]\n",
      "loss: 0.088222  [192000/209452]\n",
      "loss: 0.005139  [195200/209452]\n",
      "loss: 0.002086  [198400/209452]\n",
      "loss: 0.008122  [201600/209452]\n",
      "loss: 0.007720  [204800/209452]\n",
      "loss: 0.003717  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.014945 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 0.001344  [ 3200/209452]\n",
      "loss: 0.099304  [ 6400/209452]\n",
      "loss: 0.006902  [ 9600/209452]\n",
      "loss: 0.006753  [12800/209452]\n",
      "loss: 0.002251  [16000/209452]\n",
      "loss: 0.056297  [19200/209452]\n",
      "loss: 0.011966  [22400/209452]\n",
      "loss: 0.001290  [25600/209452]\n",
      "loss: 0.008742  [28800/209452]\n",
      "loss: 0.004961  [32000/209452]\n",
      "loss: 0.006792  [35200/209452]\n",
      "loss: 0.001009  [38400/209452]\n",
      "loss: 0.001239  [41600/209452]\n",
      "loss: 0.012264  [44800/209452]\n",
      "loss: 0.001773  [48000/209452]\n",
      "loss: 0.020231  [51200/209452]\n",
      "loss: 0.011535  [54400/209452]\n",
      "loss: 0.004553  [57600/209452]\n",
      "loss: 0.006845  [60800/209452]\n",
      "loss: 0.031633  [64000/209452]\n",
      "loss: 0.006375  [67200/209452]\n",
      "loss: 0.014086  [70400/209452]\n",
      "loss: 0.009267  [73600/209452]\n",
      "loss: 0.014990  [76800/209452]\n",
      "loss: 0.021033  [80000/209452]\n",
      "loss: 0.013790  [83200/209452]\n",
      "loss: 0.001792  [86400/209452]\n",
      "loss: 0.038776  [89600/209452]\n",
      "loss: 0.001641  [92800/209452]\n",
      "loss: 0.030368  [96000/209452]\n",
      "loss: 0.001453  [99200/209452]\n",
      "loss: 0.006296  [102400/209452]\n",
      "loss: 0.001247  [105600/209452]\n",
      "loss: 0.022593  [108800/209452]\n",
      "loss: 0.002735  [112000/209452]\n",
      "loss: 0.005422  [115200/209452]\n",
      "loss: 0.005500  [118400/209452]\n",
      "loss: 0.002726  [121600/209452]\n",
      "loss: 0.012736  [124800/209452]\n",
      "loss: 0.009236  [128000/209452]\n",
      "loss: 0.009766  [131200/209452]\n",
      "loss: 0.001575  [134400/209452]\n",
      "loss: 0.014488  [137600/209452]\n",
      "loss: 0.026674  [140800/209452]\n",
      "loss: 0.003804  [144000/209452]\n",
      "loss: 0.002691  [147200/209452]\n",
      "loss: 0.014090  [150400/209452]\n",
      "loss: 0.005467  [153600/209452]\n",
      "loss: 0.003711  [156800/209452]\n",
      "loss: 0.003026  [160000/209452]\n",
      "loss: 0.046027  [163200/209452]\n",
      "loss: 0.004239  [166400/209452]\n",
      "loss: 0.000749  [169600/209452]\n",
      "loss: 0.003223  [172800/209452]\n",
      "loss: 0.044644  [176000/209452]\n",
      "loss: 0.001645  [179200/209452]\n",
      "loss: 0.015111  [182400/209452]\n",
      "loss: 0.019770  [185600/209452]\n",
      "loss: 0.003220  [188800/209452]\n",
      "loss: 0.005504  [192000/209452]\n",
      "loss: 0.013510  [195200/209452]\n",
      "loss: 0.001063  [198400/209452]\n",
      "loss: 0.016627  [201600/209452]\n",
      "loss: 0.001982  [204800/209452]\n",
      "loss: 0.001924  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.013161 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 0.004752  [ 3200/209452]\n",
      "loss: 0.001006  [ 6400/209452]\n",
      "loss: 0.003073  [ 9600/209452]\n",
      "loss: 0.000562  [12800/209452]\n",
      "loss: 0.002078  [16000/209452]\n",
      "loss: 0.001265  [19200/209452]\n",
      "loss: 0.023042  [22400/209452]\n",
      "loss: 0.024793  [25600/209452]\n",
      "loss: 0.002156  [28800/209452]\n",
      "loss: 0.021443  [32000/209452]\n",
      "loss: 0.003225  [35200/209452]\n",
      "loss: 0.001707  [38400/209452]\n",
      "loss: 0.002783  [41600/209452]\n",
      "loss: 0.021883  [44800/209452]\n",
      "loss: 0.044786  [48000/209452]\n",
      "loss: 0.011074  [51200/209452]\n",
      "loss: 0.010158  [54400/209452]\n",
      "loss: 0.004423  [57600/209452]\n",
      "loss: 0.059054  [60800/209452]\n",
      "loss: 0.002045  [64000/209452]\n",
      "loss: 0.013494  [67200/209452]\n",
      "loss: 0.026537  [70400/209452]\n",
      "loss: 0.004897  [73600/209452]\n",
      "loss: 0.009552  [76800/209452]\n",
      "loss: 0.005373  [80000/209452]\n",
      "loss: 0.011707  [83200/209452]\n",
      "loss: 0.010669  [86400/209452]\n",
      "loss: 0.001578  [89600/209452]\n",
      "loss: 0.001719  [92800/209452]\n",
      "loss: 0.002633  [96000/209452]\n",
      "loss: 0.006484  [99200/209452]\n",
      "loss: 0.005127  [102400/209452]\n",
      "loss: 0.004093  [105600/209452]\n",
      "loss: 0.004884  [108800/209452]\n",
      "loss: 0.000594  [112000/209452]\n",
      "loss: 0.004749  [115200/209452]\n",
      "loss: 0.004454  [118400/209452]\n",
      "loss: 0.006190  [121600/209452]\n",
      "loss: 0.038891  [124800/209452]\n",
      "loss: 0.006333  [128000/209452]\n",
      "loss: 0.060229  [131200/209452]\n",
      "loss: 0.011762  [134400/209452]\n",
      "loss: 0.001395  [137600/209452]\n",
      "loss: 0.004699  [140800/209452]\n",
      "loss: 0.033169  [144000/209452]\n",
      "loss: 0.015560  [147200/209452]\n",
      "loss: 0.005160  [150400/209452]\n",
      "loss: 0.002735  [153600/209452]\n",
      "loss: 0.099380  [156800/209452]\n",
      "loss: 0.030803  [160000/209452]\n",
      "loss: 0.008445  [163200/209452]\n",
      "loss: 0.000829  [166400/209452]\n",
      "loss: 0.002170  [169600/209452]\n",
      "loss: 0.001689  [172800/209452]\n",
      "loss: 0.005501  [176000/209452]\n",
      "loss: 0.005337  [179200/209452]\n",
      "loss: 0.002310  [182400/209452]\n",
      "loss: 0.002358  [185600/209452]\n",
      "loss: 0.000956  [188800/209452]\n",
      "loss: 0.010132  [192000/209452]\n",
      "loss: 0.002199  [195200/209452]\n",
      "loss: 0.006813  [198400/209452]\n",
      "loss: 0.027725  [201600/209452]\n",
      "loss: 0.025125  [204800/209452]\n",
      "loss: 0.009913  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.011421 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 0.011566  [ 3200/209452]\n",
      "loss: 0.013350  [ 6400/209452]\n",
      "loss: 0.001630  [ 9600/209452]\n",
      "loss: 0.024924  [12800/209452]\n",
      "loss: 0.016663  [16000/209452]\n",
      "loss: 0.002297  [19200/209452]\n",
      "loss: 0.002026  [22400/209452]\n",
      "loss: 0.001448  [25600/209452]\n",
      "loss: 0.011419  [28800/209452]\n",
      "loss: 0.004255  [32000/209452]\n",
      "loss: 0.001477  [35200/209452]\n",
      "loss: 0.001934  [38400/209452]\n",
      "loss: 0.007484  [41600/209452]\n",
      "loss: 0.025804  [44800/209452]\n",
      "loss: 0.001928  [48000/209452]\n",
      "loss: 0.019356  [51200/209452]\n",
      "loss: 0.040884  [54400/209452]\n",
      "loss: 0.001565  [57600/209452]\n",
      "loss: 0.002938  [60800/209452]\n",
      "loss: 0.001058  [64000/209452]\n",
      "loss: 0.003103  [67200/209452]\n",
      "loss: 0.008062  [70400/209452]\n",
      "loss: 0.014127  [73600/209452]\n",
      "loss: 0.025293  [76800/209452]\n",
      "loss: 0.011816  [80000/209452]\n",
      "loss: 0.002923  [83200/209452]\n",
      "loss: 0.001373  [86400/209452]\n",
      "loss: 0.000896  [89600/209452]\n",
      "loss: 0.014547  [92800/209452]\n",
      "loss: 0.002662  [96000/209452]\n",
      "loss: 0.000699  [99200/209452]\n",
      "loss: 0.003615  [102400/209452]\n",
      "loss: 0.012891  [105600/209452]\n",
      "loss: 0.001619  [108800/209452]\n",
      "loss: 0.001400  [112000/209452]\n",
      "loss: 0.016353  [115200/209452]\n",
      "loss: 0.000556  [118400/209452]\n",
      "loss: 0.004218  [121600/209452]\n",
      "loss: 0.005611  [124800/209452]\n",
      "loss: 0.001140  [128000/209452]\n",
      "loss: 0.005572  [131200/209452]\n",
      "loss: 0.005919  [134400/209452]\n",
      "loss: 0.009427  [137600/209452]\n",
      "loss: 0.060915  [140800/209452]\n",
      "loss: 0.000791  [144000/209452]\n",
      "loss: 0.012575  [147200/209452]\n",
      "loss: 0.015925  [150400/209452]\n",
      "loss: 0.004484  [153600/209452]\n",
      "loss: 0.000482  [156800/209452]\n",
      "loss: 0.000233  [160000/209452]\n",
      "loss: 0.048995  [163200/209452]\n",
      "loss: 0.072858  [166400/209452]\n",
      "loss: 0.001465  [169600/209452]\n",
      "loss: 0.001350  [172800/209452]\n",
      "loss: 0.001934  [176000/209452]\n",
      "loss: 0.000592  [179200/209452]\n",
      "loss: 0.000348  [182400/209452]\n",
      "loss: 0.003306  [185600/209452]\n",
      "loss: 0.001952  [188800/209452]\n",
      "loss: 0.002796  [192000/209452]\n",
      "loss: 0.000584  [195200/209452]\n",
      "loss: 0.005927  [198400/209452]\n",
      "loss: 0.004440  [201600/209452]\n",
      "loss: 0.002002  [204800/209452]\n",
      "loss: 0.012250  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.010601 \n",
      "\n",
      "Epoch 11\n",
      "---------------------------\n",
      "loss: 0.001253  [ 3200/209452]\n",
      "loss: 0.033696  [ 6400/209452]\n",
      "loss: 0.009835  [ 9600/209452]\n",
      "loss: 0.003020  [12800/209452]\n",
      "loss: 0.016636  [16000/209452]\n",
      "loss: 0.003313  [19200/209452]\n",
      "loss: 0.001756  [22400/209452]\n",
      "loss: 0.000086  [25600/209452]\n",
      "loss: 0.014796  [28800/209452]\n",
      "loss: 0.004266  [32000/209452]\n",
      "loss: 0.003139  [35200/209452]\n",
      "loss: 0.011568  [38400/209452]\n",
      "loss: 0.001632  [41600/209452]\n",
      "loss: 0.015788  [44800/209452]\n",
      "loss: 0.005529  [48000/209452]\n",
      "loss: 0.008161  [51200/209452]\n",
      "loss: 0.023695  [54400/209452]\n",
      "loss: 0.000315  [57600/209452]\n",
      "loss: 0.001439  [60800/209452]\n",
      "loss: 0.001228  [64000/209452]\n",
      "loss: 0.013535  [67200/209452]\n",
      "loss: 0.002171  [70400/209452]\n",
      "loss: 0.040409  [73600/209452]\n",
      "loss: 0.000732  [76800/209452]\n",
      "loss: 0.006982  [80000/209452]\n",
      "loss: 0.008033  [83200/209452]\n",
      "loss: 0.003400  [86400/209452]\n",
      "loss: 0.004683  [89600/209452]\n",
      "loss: 0.002247  [92800/209452]\n",
      "loss: 0.005059  [96000/209452]\n",
      "loss: 0.005686  [99200/209452]\n",
      "loss: 0.001732  [102400/209452]\n",
      "loss: 0.000914  [105600/209452]\n",
      "loss: 0.001461  [108800/209452]\n",
      "loss: 0.001491  [112000/209452]\n",
      "loss: 0.001343  [115200/209452]\n",
      "loss: 0.009436  [118400/209452]\n",
      "loss: 0.002996  [121600/209452]\n",
      "loss: 0.002463  [124800/209452]\n",
      "loss: 0.005434  [128000/209452]\n",
      "loss: 0.001836  [131200/209452]\n",
      "loss: 0.000907  [134400/209452]\n",
      "loss: 0.006028  [137600/209452]\n",
      "loss: 0.000797  [140800/209452]\n",
      "loss: 0.001999  [144000/209452]\n",
      "loss: 0.000763  [147200/209452]\n",
      "loss: 0.002465  [150400/209452]\n",
      "loss: 0.001119  [153600/209452]\n",
      "loss: 0.002293  [156800/209452]\n",
      "loss: 0.001956  [160000/209452]\n",
      "loss: 0.001153  [163200/209452]\n",
      "loss: 0.000589  [166400/209452]\n",
      "loss: 0.009775  [169600/209452]\n",
      "loss: 0.011970  [172800/209452]\n",
      "loss: 0.016350  [176000/209452]\n",
      "loss: 0.000682  [179200/209452]\n",
      "loss: 0.001117  [182400/209452]\n",
      "loss: 0.018014  [185600/209452]\n",
      "loss: 0.003744  [188800/209452]\n",
      "loss: 0.001442  [192000/209452]\n",
      "loss: 0.003661  [195200/209452]\n",
      "loss: 0.006022  [198400/209452]\n",
      "loss: 0.002074  [201600/209452]\n",
      "loss: 0.000490  [204800/209452]\n",
      "loss: 0.000326  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.009318 \n",
      "\n",
      "Epoch 12\n",
      "---------------------------\n",
      "loss: 0.002429  [ 3200/209452]\n",
      "loss: 0.004039  [ 6400/209452]\n",
      "loss: 0.001448  [ 9600/209452]\n",
      "loss: 0.005584  [12800/209452]\n",
      "loss: 0.008180  [16000/209452]\n",
      "loss: 0.004137  [19200/209452]\n",
      "loss: 0.026407  [22400/209452]\n",
      "loss: 0.005279  [25600/209452]\n",
      "loss: 0.004496  [28800/209452]\n",
      "loss: 0.005915  [32000/209452]\n",
      "loss: 0.002771  [35200/209452]\n",
      "loss: 0.003703  [38400/209452]\n",
      "loss: 0.002126  [41600/209452]\n",
      "loss: 0.001135  [44800/209452]\n",
      "loss: 0.000632  [48000/209452]\n",
      "loss: 0.001320  [51200/209452]\n",
      "loss: 0.004779  [54400/209452]\n",
      "loss: 0.000575  [57600/209452]\n",
      "loss: 0.002117  [60800/209452]\n",
      "loss: 0.001589  [64000/209452]\n",
      "loss: 0.000827  [67200/209452]\n",
      "loss: 0.001793  [70400/209452]\n",
      "loss: 0.000435  [73600/209452]\n",
      "loss: 0.000480  [76800/209452]\n",
      "loss: 0.019590  [80000/209452]\n",
      "loss: 0.005761  [83200/209452]\n",
      "loss: 0.000478  [86400/209452]\n",
      "loss: 0.004923  [89600/209452]\n",
      "loss: 0.015918  [92800/209452]\n",
      "loss: 0.004927  [96000/209452]\n",
      "loss: 0.004159  [99200/209452]\n",
      "loss: 0.001201  [102400/209452]\n",
      "loss: 0.019297  [105600/209452]\n",
      "loss: 0.008153  [108800/209452]\n",
      "loss: 0.021101  [112000/209452]\n",
      "loss: 0.001233  [115200/209452]\n",
      "loss: 0.000847  [118400/209452]\n",
      "loss: 0.006071  [121600/209452]\n",
      "loss: 0.003435  [124800/209452]\n",
      "loss: 0.000265  [128000/209452]\n",
      "loss: 0.001886  [131200/209452]\n",
      "loss: 0.000729  [134400/209452]\n",
      "loss: 0.011453  [137600/209452]\n",
      "loss: 0.004034  [140800/209452]\n",
      "loss: 0.000528  [144000/209452]\n",
      "loss: 0.002842  [147200/209452]\n",
      "loss: 0.006765  [150400/209452]\n",
      "loss: 0.000972  [153600/209452]\n",
      "loss: 0.002326  [156800/209452]\n",
      "loss: 0.000498  [160000/209452]\n",
      "loss: 0.024341  [163200/209452]\n",
      "loss: 0.001359  [166400/209452]\n",
      "loss: 0.003756  [169600/209452]\n",
      "loss: 0.018001  [172800/209452]\n",
      "loss: 0.004413  [176000/209452]\n",
      "loss: 0.017099  [179200/209452]\n",
      "loss: 0.001196  [182400/209452]\n",
      "loss: 0.001858  [185600/209452]\n",
      "loss: 0.001645  [188800/209452]\n",
      "loss: 0.000432  [192000/209452]\n",
      "loss: 0.000348  [195200/209452]\n",
      "loss: 0.000726  [198400/209452]\n",
      "loss: 0.000357  [201600/209452]\n",
      "loss: 0.001458  [204800/209452]\n",
      "loss: 0.008477  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.007874 \n",
      "\n",
      "Epoch 13\n",
      "---------------------------\n",
      "loss: 0.011371  [ 3200/209452]\n",
      "loss: 0.001479  [ 6400/209452]\n",
      "loss: 0.019192  [ 9600/209452]\n",
      "loss: 0.005662  [12800/209452]\n",
      "loss: 0.001425  [16000/209452]\n",
      "loss: 0.000510  [19200/209452]\n",
      "loss: 0.066326  [22400/209452]\n",
      "loss: 0.001033  [25600/209452]\n",
      "loss: 0.002240  [28800/209452]\n",
      "loss: 0.000924  [32000/209452]\n",
      "loss: 0.001126  [35200/209452]\n",
      "loss: 0.002079  [38400/209452]\n",
      "loss: 0.010725  [41600/209452]\n",
      "loss: 0.020442  [44800/209452]\n",
      "loss: 0.010082  [48000/209452]\n",
      "loss: 0.009240  [51200/209452]\n",
      "loss: 0.004113  [54400/209452]\n",
      "loss: 0.006247  [57600/209452]\n",
      "loss: 0.001003  [60800/209452]\n",
      "loss: 0.001981  [64000/209452]\n",
      "loss: 0.013169  [67200/209452]\n",
      "loss: 0.001662  [70400/209452]\n",
      "loss: 0.001897  [73600/209452]\n",
      "loss: 0.002259  [76800/209452]\n",
      "loss: 0.010107  [80000/209452]\n",
      "loss: 0.000324  [83200/209452]\n",
      "loss: 0.003992  [86400/209452]\n",
      "loss: 0.007575  [89600/209452]\n",
      "loss: 0.000508  [92800/209452]\n",
      "loss: 0.000154  [96000/209452]\n",
      "loss: 0.002434  [99200/209452]\n",
      "loss: 0.003488  [102400/209452]\n",
      "loss: 0.005889  [105600/209452]\n",
      "loss: 0.008771  [108800/209452]\n",
      "loss: 0.021376  [112000/209452]\n",
      "loss: 0.026362  [115200/209452]\n",
      "loss: 0.001403  [118400/209452]\n",
      "loss: 0.000398  [121600/209452]\n",
      "loss: 0.040916  [124800/209452]\n",
      "loss: 0.011099  [128000/209452]\n",
      "loss: 0.009361  [131200/209452]\n",
      "loss: 0.001401  [134400/209452]\n",
      "loss: 0.001410  [137600/209452]\n",
      "loss: 0.019204  [140800/209452]\n",
      "loss: 0.003510  [144000/209452]\n",
      "loss: 0.002948  [147200/209452]\n",
      "loss: 0.001059  [150400/209452]\n",
      "loss: 0.018961  [153600/209452]\n",
      "loss: 0.004275  [156800/209452]\n",
      "loss: 0.000526  [160000/209452]\n",
      "loss: 0.001034  [163200/209452]\n",
      "loss: 0.006024  [166400/209452]\n",
      "loss: 0.008611  [169600/209452]\n",
      "loss: 0.009076  [172800/209452]\n",
      "loss: 0.000463  [176000/209452]\n",
      "loss: 0.021698  [179200/209452]\n",
      "loss: 0.001095  [182400/209452]\n",
      "loss: 0.003387  [185600/209452]\n",
      "loss: 0.000469  [188800/209452]\n",
      "loss: 0.000786  [192000/209452]\n",
      "loss: 0.000993  [195200/209452]\n",
      "loss: 0.003331  [198400/209452]\n",
      "loss: 0.001203  [201600/209452]\n",
      "loss: 0.000889  [204800/209452]\n",
      "loss: 0.000408  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.008336 \n",
      "\n",
      "Epoch 14\n",
      "---------------------------\n",
      "loss: 0.000857  [ 3200/209452]\n",
      "loss: 0.001209  [ 6400/209452]\n",
      "loss: 0.000322  [ 9600/209452]\n",
      "loss: 0.001945  [12800/209452]\n",
      "loss: 0.013554  [16000/209452]\n",
      "loss: 0.000253  [19200/209452]\n",
      "loss: 0.001344  [22400/209452]\n",
      "loss: 0.002278  [25600/209452]\n",
      "loss: 0.001806  [28800/209452]\n",
      "loss: 0.000896  [32000/209452]\n",
      "loss: 0.001638  [35200/209452]\n",
      "loss: 0.003717  [38400/209452]\n",
      "loss: 0.008552  [41600/209452]\n",
      "loss: 0.003180  [44800/209452]\n",
      "loss: 0.000930  [48000/209452]\n",
      "loss: 0.001024  [51200/209452]\n",
      "loss: 0.000594  [54400/209452]\n",
      "loss: 0.001827  [57600/209452]\n",
      "loss: 0.001175  [60800/209452]\n",
      "loss: 0.003250  [64000/209452]\n",
      "loss: 0.000183  [67200/209452]\n",
      "loss: 0.005834  [70400/209452]\n",
      "loss: 0.000490  [73600/209452]\n",
      "loss: 0.009321  [76800/209452]\n",
      "loss: 0.000775  [80000/209452]\n",
      "loss: 0.002158  [83200/209452]\n",
      "loss: 0.008005  [86400/209452]\n",
      "loss: 0.000837  [89600/209452]\n",
      "loss: 0.002395  [92800/209452]\n",
      "loss: 0.001506  [96000/209452]\n",
      "loss: 0.004883  [99200/209452]\n",
      "loss: 0.000444  [102400/209452]\n",
      "loss: 0.002895  [105600/209452]\n",
      "loss: 0.000390  [108800/209452]\n",
      "loss: 0.000630  [112000/209452]\n",
      "loss: 0.000864  [115200/209452]\n",
      "loss: 0.000626  [118400/209452]\n",
      "loss: 0.003704  [121600/209452]\n",
      "loss: 0.000093  [124800/209452]\n",
      "loss: 0.001123  [128000/209452]\n",
      "loss: 0.000226  [131200/209452]\n",
      "loss: 0.001298  [134400/209452]\n",
      "loss: 0.013030  [137600/209452]\n",
      "loss: 0.001217  [140800/209452]\n",
      "loss: 0.005505  [144000/209452]\n",
      "loss: 0.001346  [147200/209452]\n",
      "loss: 0.004175  [150400/209452]\n",
      "loss: 0.002418  [153600/209452]\n",
      "loss: 0.000652  [156800/209452]\n",
      "loss: 0.000754  [160000/209452]\n",
      "loss: 0.004847  [163200/209452]\n",
      "loss: 0.002012  [166400/209452]\n",
      "loss: 0.000431  [169600/209452]\n",
      "loss: 0.002829  [172800/209452]\n",
      "loss: 0.010404  [176000/209452]\n",
      "loss: 0.010032  [179200/209452]\n",
      "loss: 0.008431  [182400/209452]\n",
      "loss: 0.002619  [185600/209452]\n",
      "loss: 0.000715  [188800/209452]\n",
      "loss: 0.001829  [192000/209452]\n",
      "loss: 0.001293  [195200/209452]\n",
      "loss: 0.002066  [198400/209452]\n",
      "loss: 0.002144  [201600/209452]\n",
      "loss: 0.000450  [204800/209452]\n",
      "loss: 0.004943  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.006494 \n",
      "\n",
      "Epoch 15\n",
      "---------------------------\n",
      "loss: 0.030573  [ 3200/209452]\n",
      "loss: 0.002013  [ 6400/209452]\n",
      "loss: 0.003395  [ 9600/209452]\n",
      "loss: 0.010036  [12800/209452]\n",
      "loss: 0.056638  [16000/209452]\n",
      "loss: 0.001282  [19200/209452]\n",
      "loss: 0.026171  [22400/209452]\n",
      "loss: 0.000587  [25600/209452]\n",
      "loss: 0.001901  [28800/209452]\n",
      "loss: 0.004267  [32000/209452]\n",
      "loss: 0.001409  [35200/209452]\n",
      "loss: 0.002559  [38400/209452]\n",
      "loss: 0.002299  [41600/209452]\n",
      "loss: 0.002386  [44800/209452]\n",
      "loss: 0.001218  [48000/209452]\n",
      "loss: 0.005657  [51200/209452]\n",
      "loss: 0.007003  [54400/209452]\n",
      "loss: 0.002186  [57600/209452]\n",
      "loss: 0.003207  [60800/209452]\n",
      "loss: 0.004772  [64000/209452]\n",
      "loss: 0.000584  [67200/209452]\n",
      "loss: 0.001757  [70400/209452]\n",
      "loss: 0.000532  [73600/209452]\n",
      "loss: 0.000970  [76800/209452]\n",
      "loss: 0.002160  [80000/209452]\n",
      "loss: 0.001344  [83200/209452]\n",
      "loss: 0.009887  [86400/209452]\n",
      "loss: 0.002836  [89600/209452]\n",
      "loss: 0.006128  [92800/209452]\n",
      "loss: 0.000221  [96000/209452]\n",
      "loss: 0.003268  [99200/209452]\n",
      "loss: 0.009772  [102400/209452]\n",
      "loss: 0.004233  [105600/209452]\n",
      "loss: 0.001182  [108800/209452]\n",
      "loss: 0.000545  [112000/209452]\n",
      "loss: 0.000271  [115200/209452]\n",
      "loss: 0.020953  [118400/209452]\n",
      "loss: 0.000128  [121600/209452]\n",
      "loss: 0.004450  [124800/209452]\n",
      "loss: 0.000473  [128000/209452]\n",
      "loss: 0.006586  [131200/209452]\n",
      "loss: 0.000836  [134400/209452]\n",
      "loss: 0.006348  [137600/209452]\n",
      "loss: 0.000321  [140800/209452]\n",
      "loss: 0.001077  [144000/209452]\n",
      "loss: 0.017619  [147200/209452]\n",
      "loss: 0.017473  [150400/209452]\n",
      "loss: 0.002915  [153600/209452]\n",
      "loss: 0.004793  [156800/209452]\n",
      "loss: 0.001563  [160000/209452]\n",
      "loss: 0.005212  [163200/209452]\n",
      "loss: 0.039425  [166400/209452]\n",
      "loss: 0.000797  [169600/209452]\n",
      "loss: 0.000056  [172800/209452]\n",
      "loss: 0.001428  [176000/209452]\n",
      "loss: 0.001612  [179200/209452]\n",
      "loss: 0.000385  [182400/209452]\n",
      "loss: 0.011224  [185600/209452]\n",
      "loss: 0.001296  [188800/209452]\n",
      "loss: 0.000296  [192000/209452]\n",
      "loss: 0.001819  [195200/209452]\n",
      "loss: 0.002761  [198400/209452]\n",
      "loss: 0.011644  [201600/209452]\n",
      "loss: 0.001309  [204800/209452]\n",
      "loss: 0.074876  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.006630 \n",
      "\n",
      "Epoch 16\n",
      "---------------------------\n",
      "loss: 0.000574  [ 3200/209452]\n",
      "loss: 0.000252  [ 6400/209452]\n",
      "loss: 0.001235  [ 9600/209452]\n",
      "loss: 0.000715  [12800/209452]\n",
      "loss: 0.000680  [16000/209452]\n",
      "loss: 0.000395  [19200/209452]\n",
      "loss: 0.002643  [22400/209452]\n",
      "loss: 0.002175  [25600/209452]\n",
      "loss: 0.015099  [28800/209452]\n",
      "loss: 0.001163  [32000/209452]\n",
      "loss: 0.004638  [35200/209452]\n",
      "loss: 0.000501  [38400/209452]\n",
      "loss: 0.007128  [41600/209452]\n",
      "loss: 0.000103  [44800/209452]\n",
      "loss: 0.006662  [48000/209452]\n",
      "loss: 0.000674  [51200/209452]\n",
      "loss: 0.007010  [54400/209452]\n",
      "loss: 0.005431  [57600/209452]\n",
      "loss: 0.000566  [60800/209452]\n",
      "loss: 0.000972  [64000/209452]\n",
      "loss: 0.005088  [67200/209452]\n",
      "loss: 0.000405  [70400/209452]\n",
      "loss: 0.008539  [73600/209452]\n",
      "loss: 0.000840  [76800/209452]\n",
      "loss: 0.005051  [80000/209452]\n",
      "loss: 0.007777  [83200/209452]\n",
      "loss: 0.001607  [86400/209452]\n",
      "loss: 0.000187  [89600/209452]\n",
      "loss: 0.005840  [92800/209452]\n",
      "loss: 0.006064  [96000/209452]\n",
      "loss: 0.000771  [99200/209452]\n",
      "loss: 0.008588  [102400/209452]\n",
      "loss: 0.003205  [105600/209452]\n",
      "loss: 0.001317  [108800/209452]\n",
      "loss: 0.002125  [112000/209452]\n",
      "loss: 0.000493  [115200/209452]\n",
      "loss: 0.000764  [118400/209452]\n",
      "loss: 0.002669  [121600/209452]\n",
      "loss: 0.003402  [124800/209452]\n",
      "loss: 0.001896  [128000/209452]\n",
      "loss: 0.035252  [131200/209452]\n",
      "loss: 0.002760  [134400/209452]\n",
      "loss: 0.001137  [137600/209452]\n",
      "loss: 0.002704  [140800/209452]\n",
      "loss: 0.000246  [144000/209452]\n",
      "loss: 0.003743  [147200/209452]\n",
      "loss: 0.000956  [150400/209452]\n",
      "loss: 0.011307  [153600/209452]\n",
      "loss: 0.002145  [156800/209452]\n",
      "loss: 0.001704  [160000/209452]\n",
      "loss: 0.004751  [163200/209452]\n",
      "loss: 0.001523  [166400/209452]\n",
      "loss: 0.001609  [169600/209452]\n",
      "loss: 0.002004  [172800/209452]\n",
      "loss: 0.000667  [176000/209452]\n",
      "loss: 0.033643  [179200/209452]\n",
      "loss: 0.001793  [182400/209452]\n",
      "loss: 0.000524  [185600/209452]\n",
      "loss: 0.001011  [188800/209452]\n",
      "loss: 0.000728  [192000/209452]\n",
      "loss: 0.000438  [195200/209452]\n",
      "loss: 0.000305  [198400/209452]\n",
      "loss: 0.002917  [201600/209452]\n",
      "loss: 0.000311  [204800/209452]\n",
      "loss: 0.000385  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.005710 \n",
      "\n",
      "Epoch 17\n",
      "---------------------------\n",
      "loss: 0.002496  [ 3200/209452]\n",
      "loss: 0.001344  [ 6400/209452]\n",
      "loss: 0.001810  [ 9600/209452]\n",
      "loss: 0.001982  [12800/209452]\n",
      "loss: 0.000701  [16000/209452]\n",
      "loss: 0.000162  [19200/209452]\n",
      "loss: 0.000639  [22400/209452]\n",
      "loss: 0.002084  [25600/209452]\n",
      "loss: 0.016303  [28800/209452]\n",
      "loss: 0.000125  [32000/209452]\n",
      "loss: 0.000469  [35200/209452]\n",
      "loss: 0.000148  [38400/209452]\n",
      "loss: 0.001539  [41600/209452]\n",
      "loss: 0.000676  [44800/209452]\n",
      "loss: 0.016091  [48000/209452]\n",
      "loss: 0.000133  [51200/209452]\n",
      "loss: 0.004844  [54400/209452]\n",
      "loss: 0.000554  [57600/209452]\n",
      "loss: 0.006679  [60800/209452]\n",
      "loss: 0.007445  [64000/209452]\n",
      "loss: 0.004732  [67200/209452]\n",
      "loss: 0.003584  [70400/209452]\n",
      "loss: 0.003257  [73600/209452]\n",
      "loss: 0.000415  [76800/209452]\n",
      "loss: 0.001499  [80000/209452]\n",
      "loss: 0.002531  [83200/209452]\n",
      "loss: 0.000312  [86400/209452]\n",
      "loss: 0.001330  [89600/209452]\n",
      "loss: 0.004096  [92800/209452]\n",
      "loss: 0.002042  [96000/209452]\n",
      "loss: 0.001605  [99200/209452]\n",
      "loss: 0.003116  [102400/209452]\n",
      "loss: 0.001318  [105600/209452]\n",
      "loss: 0.000577  [108800/209452]\n",
      "loss: 0.003538  [112000/209452]\n",
      "loss: 0.004361  [115200/209452]\n",
      "loss: 0.024971  [118400/209452]\n",
      "loss: 0.000587  [121600/209452]\n",
      "loss: 0.000886  [124800/209452]\n",
      "loss: 0.001463  [128000/209452]\n",
      "loss: 0.002465  [131200/209452]\n",
      "loss: 0.001014  [134400/209452]\n",
      "loss: 0.000600  [137600/209452]\n",
      "loss: 0.002504  [140800/209452]\n",
      "loss: 0.000621  [144000/209452]\n",
      "loss: 0.007257  [147200/209452]\n",
      "loss: 0.004638  [150400/209452]\n",
      "loss: 0.000356  [153600/209452]\n",
      "loss: 0.002119  [156800/209452]\n",
      "loss: 0.000131  [160000/209452]\n",
      "loss: 0.000274  [163200/209452]\n",
      "loss: 0.023922  [166400/209452]\n",
      "loss: 0.000864  [169600/209452]\n",
      "loss: 0.000452  [172800/209452]\n",
      "loss: 0.000469  [176000/209452]\n",
      "loss: 0.001368  [179200/209452]\n",
      "loss: 0.000695  [182400/209452]\n",
      "loss: 0.000703  [185600/209452]\n",
      "loss: 0.002210  [188800/209452]\n",
      "loss: 0.000358  [192000/209452]\n",
      "loss: 0.000354  [195200/209452]\n",
      "loss: 0.000276  [198400/209452]\n",
      "loss: 0.000713  [201600/209452]\n",
      "loss: 0.001013  [204800/209452]\n",
      "loss: 0.002620  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.005353 \n",
      "\n",
      "Epoch 18\n",
      "---------------------------\n",
      "loss: 0.000187  [ 3200/209452]\n",
      "loss: 0.000344  [ 6400/209452]\n",
      "loss: 0.002771  [ 9600/209452]\n",
      "loss: 0.000436  [12800/209452]\n",
      "loss: 0.000955  [16000/209452]\n",
      "loss: 0.003760  [19200/209452]\n",
      "loss: 0.000951  [22400/209452]\n",
      "loss: 0.003040  [25600/209452]\n",
      "loss: 0.001193  [28800/209452]\n",
      "loss: 0.001801  [32000/209452]\n",
      "loss: 0.001671  [35200/209452]\n",
      "loss: 0.000331  [38400/209452]\n",
      "loss: 0.000093  [41600/209452]\n",
      "loss: 0.000541  [44800/209452]\n",
      "loss: 0.009454  [48000/209452]\n",
      "loss: 0.000410  [51200/209452]\n",
      "loss: 0.000183  [54400/209452]\n",
      "loss: 0.001031  [57600/209452]\n",
      "loss: 0.001365  [60800/209452]\n",
      "loss: 0.000407  [64000/209452]\n",
      "loss: 0.003539  [67200/209452]\n",
      "loss: 0.003217  [70400/209452]\n",
      "loss: 0.000432  [73600/209452]\n",
      "loss: 0.001258  [76800/209452]\n",
      "loss: 0.002055  [80000/209452]\n",
      "loss: 0.029822  [83200/209452]\n",
      "loss: 0.002410  [86400/209452]\n",
      "loss: 0.000958  [89600/209452]\n",
      "loss: 0.004140  [92800/209452]\n",
      "loss: 0.008436  [96000/209452]\n",
      "loss: 0.003987  [99200/209452]\n",
      "loss: 0.001218  [102400/209452]\n",
      "loss: 0.008074  [105600/209452]\n",
      "loss: 0.000592  [108800/209452]\n",
      "loss: 0.000512  [112000/209452]\n",
      "loss: 0.001630  [115200/209452]\n",
      "loss: 0.000593  [118400/209452]\n",
      "loss: 0.000583  [121600/209452]\n",
      "loss: 0.000423  [124800/209452]\n",
      "loss: 0.000355  [128000/209452]\n",
      "loss: 0.000582  [131200/209452]\n",
      "loss: 0.000202  [134400/209452]\n",
      "loss: 0.002288  [137600/209452]\n",
      "loss: 0.003667  [140800/209452]\n",
      "loss: 0.005053  [144000/209452]\n",
      "loss: 0.013541  [147200/209452]\n",
      "loss: 0.000284  [150400/209452]\n",
      "loss: 0.000269  [153600/209452]\n",
      "loss: 0.000184  [156800/209452]\n",
      "loss: 0.001115  [160000/209452]\n",
      "loss: 0.000127  [163200/209452]\n",
      "loss: 0.001079  [166400/209452]\n",
      "loss: 0.001256  [169600/209452]\n",
      "loss: 0.000626  [172800/209452]\n",
      "loss: 0.001817  [176000/209452]\n",
      "loss: 0.010233  [179200/209452]\n",
      "loss: 0.000348  [182400/209452]\n",
      "loss: 0.007881  [185600/209452]\n",
      "loss: 0.000236  [188800/209452]\n",
      "loss: 0.015831  [192000/209452]\n",
      "loss: 0.000530  [195200/209452]\n",
      "loss: 0.002088  [198400/209452]\n",
      "loss: 0.006716  [201600/209452]\n",
      "loss: 0.000912  [204800/209452]\n",
      "loss: 0.008006  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.005165 \n",
      "\n",
      "Epoch 19\n",
      "---------------------------\n",
      "loss: 0.001026  [ 3200/209452]\n",
      "loss: 0.014729  [ 6400/209452]\n",
      "loss: 0.000683  [ 9600/209452]\n",
      "loss: 0.001253  [12800/209452]\n",
      "loss: 0.002484  [16000/209452]\n",
      "loss: 0.000764  [19200/209452]\n",
      "loss: 0.000304  [22400/209452]\n",
      "loss: 0.000715  [25600/209452]\n",
      "loss: 0.000646  [28800/209452]\n",
      "loss: 0.003042  [32000/209452]\n",
      "loss: 0.008032  [35200/209452]\n",
      "loss: 0.000953  [38400/209452]\n",
      "loss: 0.003008  [41600/209452]\n",
      "loss: 0.017656  [44800/209452]\n",
      "loss: 0.003588  [48000/209452]\n",
      "loss: 0.000310  [51200/209452]\n",
      "loss: 0.001092  [54400/209452]\n",
      "loss: 0.000229  [57600/209452]\n",
      "loss: 0.000126  [60800/209452]\n",
      "loss: 0.001027  [64000/209452]\n",
      "loss: 0.002085  [67200/209452]\n",
      "loss: 0.000336  [70400/209452]\n",
      "loss: 0.001571  [73600/209452]\n",
      "loss: 0.001041  [76800/209452]\n",
      "loss: 0.005885  [80000/209452]\n",
      "loss: 0.006879  [83200/209452]\n",
      "loss: 0.001039  [86400/209452]\n",
      "loss: 0.000276  [89600/209452]\n",
      "loss: 0.000425  [92800/209452]\n",
      "loss: 0.003330  [96000/209452]\n",
      "loss: 0.000310  [99200/209452]\n",
      "loss: 0.006973  [102400/209452]\n",
      "loss: 0.002198  [105600/209452]\n",
      "loss: 0.001777  [108800/209452]\n",
      "loss: 0.001413  [112000/209452]\n",
      "loss: 0.000184  [115200/209452]\n",
      "loss: 0.002199  [118400/209452]\n",
      "loss: 0.006104  [121600/209452]\n",
      "loss: 0.000935  [124800/209452]\n",
      "loss: 0.000348  [128000/209452]\n",
      "loss: 0.001622  [131200/209452]\n",
      "loss: 0.001830  [134400/209452]\n",
      "loss: 0.000930  [137600/209452]\n",
      "loss: 0.005713  [140800/209452]\n",
      "loss: 0.001809  [144000/209452]\n",
      "loss: 0.001726  [147200/209452]\n",
      "loss: 0.000679  [150400/209452]\n",
      "loss: 0.000475  [153600/209452]\n",
      "loss: 0.002913  [156800/209452]\n",
      "loss: 0.000503  [160000/209452]\n",
      "loss: 0.001458  [163200/209452]\n",
      "loss: 0.000402  [166400/209452]\n",
      "loss: 0.002258  [169600/209452]\n",
      "loss: 0.000311  [172800/209452]\n",
      "loss: 0.008632  [176000/209452]\n",
      "loss: 0.000982  [179200/209452]\n",
      "loss: 0.000400  [182400/209452]\n",
      "loss: 0.000145  [185600/209452]\n",
      "loss: 0.000678  [188800/209452]\n",
      "loss: 0.000485  [192000/209452]\n",
      "loss: 0.000737  [195200/209452]\n",
      "loss: 0.001051  [198400/209452]\n",
      "loss: 0.000191  [201600/209452]\n",
      "loss: 0.003499  [204800/209452]\n",
      "loss: 0.000650  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.005203 \n",
      "\n",
      "Epoch 20\n",
      "---------------------------\n",
      "loss: 0.003647  [ 3200/209452]\n",
      "loss: 0.000557  [ 6400/209452]\n",
      "loss: 0.000097  [ 9600/209452]\n",
      "loss: 0.000169  [12800/209452]\n",
      "loss: 0.000490  [16000/209452]\n",
      "loss: 0.000925  [19200/209452]\n",
      "loss: 0.000686  [22400/209452]\n",
      "loss: 0.000548  [25600/209452]\n",
      "loss: 0.002376  [28800/209452]\n",
      "loss: 0.000613  [32000/209452]\n",
      "loss: 0.000730  [35200/209452]\n",
      "loss: 0.000829  [38400/209452]\n",
      "loss: 0.000798  [41600/209452]\n",
      "loss: 0.000339  [44800/209452]\n",
      "loss: 0.000925  [48000/209452]\n",
      "loss: 0.001984  [51200/209452]\n",
      "loss: 0.009367  [54400/209452]\n",
      "loss: 0.000821  [57600/209452]\n",
      "loss: 0.003575  [60800/209452]\n",
      "loss: 0.008839  [64000/209452]\n",
      "loss: 0.002276  [67200/209452]\n",
      "loss: 0.000674  [70400/209452]\n",
      "loss: 0.000395  [73600/209452]\n",
      "loss: 0.009021  [76800/209452]\n",
      "loss: 0.001800  [80000/209452]\n",
      "loss: 0.000590  [83200/209452]\n",
      "loss: 0.003126  [86400/209452]\n",
      "loss: 0.002537  [89600/209452]\n",
      "loss: 0.000283  [92800/209452]\n",
      "loss: 0.005672  [96000/209452]\n",
      "loss: 0.001502  [99200/209452]\n",
      "loss: 0.020595  [102400/209452]\n",
      "loss: 0.001305  [105600/209452]\n",
      "loss: 0.000787  [108800/209452]\n",
      "loss: 0.002506  [112000/209452]\n",
      "loss: 0.007147  [115200/209452]\n",
      "loss: 0.000068  [118400/209452]\n",
      "loss: 0.001909  [121600/209452]\n",
      "loss: 0.002096  [124800/209452]\n",
      "loss: 0.000202  [128000/209452]\n",
      "loss: 0.000995  [131200/209452]\n",
      "loss: 0.000113  [134400/209452]\n",
      "loss: 0.000468  [137600/209452]\n",
      "loss: 0.003985  [140800/209452]\n",
      "loss: 0.002014  [144000/209452]\n",
      "loss: 0.000513  [147200/209452]\n",
      "loss: 0.000175  [150400/209452]\n",
      "loss: 0.005050  [153600/209452]\n",
      "loss: 0.000552  [156800/209452]\n",
      "loss: 0.001438  [160000/209452]\n",
      "loss: 0.020775  [163200/209452]\n",
      "loss: 0.000110  [166400/209452]\n",
      "loss: 0.000490  [169600/209452]\n",
      "loss: 0.000684  [172800/209452]\n",
      "loss: 0.000545  [176000/209452]\n",
      "loss: 0.000408  [179200/209452]\n",
      "loss: 0.000820  [182400/209452]\n",
      "loss: 0.000132  [185600/209452]\n",
      "loss: 0.000417  [188800/209452]\n",
      "loss: 0.002576  [192000/209452]\n",
      "loss: 0.009684  [195200/209452]\n",
      "loss: 0.000068  [198400/209452]\n",
      "loss: 0.026271  [201600/209452]\n",
      "loss: 0.001166  [204800/209452]\n",
      "loss: 0.000635  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004696 \n",
      "\n",
      "Epoch 21\n",
      "---------------------------\n",
      "loss: 0.005374  [ 3200/209452]\n",
      "loss: 0.000500  [ 6400/209452]\n",
      "loss: 0.005376  [ 9600/209452]\n",
      "loss: 0.000205  [12800/209452]\n",
      "loss: 0.001196  [16000/209452]\n",
      "loss: 0.003786  [19200/209452]\n",
      "loss: 0.000327  [22400/209452]\n",
      "loss: 0.000703  [25600/209452]\n",
      "loss: 0.000091  [28800/209452]\n",
      "loss: 0.000561  [32000/209452]\n",
      "loss: 0.001565  [35200/209452]\n",
      "loss: 0.001380  [38400/209452]\n",
      "loss: 0.000820  [41600/209452]\n",
      "loss: 0.002027  [44800/209452]\n",
      "loss: 0.002248  [48000/209452]\n",
      "loss: 0.000276  [51200/209452]\n",
      "loss: 0.000268  [54400/209452]\n",
      "loss: 0.000436  [57600/209452]\n",
      "loss: 0.000761  [60800/209452]\n",
      "loss: 0.000594  [64000/209452]\n",
      "loss: 0.000817  [67200/209452]\n",
      "loss: 0.000153  [70400/209452]\n",
      "loss: 0.001354  [73600/209452]\n",
      "loss: 0.032738  [76800/209452]\n",
      "loss: 0.000159  [80000/209452]\n",
      "loss: 0.000838  [83200/209452]\n",
      "loss: 0.003644  [86400/209452]\n",
      "loss: 0.007023  [89600/209452]\n",
      "loss: 0.000227  [92800/209452]\n",
      "loss: 0.000545  [96000/209452]\n",
      "loss: 0.002420  [99200/209452]\n",
      "loss: 0.000601  [102400/209452]\n",
      "loss: 0.002174  [105600/209452]\n",
      "loss: 0.000231  [108800/209452]\n",
      "loss: 0.000213  [112000/209452]\n",
      "loss: 0.000193  [115200/209452]\n",
      "loss: 0.000323  [118400/209452]\n",
      "loss: 0.003695  [121600/209452]\n",
      "loss: 0.014546  [124800/209452]\n",
      "loss: 0.004695  [128000/209452]\n",
      "loss: 0.001261  [131200/209452]\n",
      "loss: 0.002211  [134400/209452]\n",
      "loss: 0.000284  [137600/209452]\n",
      "loss: 0.000254  [140800/209452]\n",
      "loss: 0.001765  [144000/209452]\n",
      "loss: 0.001704  [147200/209452]\n",
      "loss: 0.000916  [150400/209452]\n",
      "loss: 0.002049  [153600/209452]\n",
      "loss: 0.000243  [156800/209452]\n",
      "loss: 0.000181  [160000/209452]\n",
      "loss: 0.001238  [163200/209452]\n",
      "loss: 0.000259  [166400/209452]\n",
      "loss: 0.003280  [169600/209452]\n",
      "loss: 0.001381  [172800/209452]\n",
      "loss: 0.015160  [176000/209452]\n",
      "loss: 0.000337  [179200/209452]\n",
      "loss: 0.001833  [182400/209452]\n",
      "loss: 0.000573  [185600/209452]\n",
      "loss: 0.012996  [188800/209452]\n",
      "loss: 0.000197  [192000/209452]\n",
      "loss: 0.000089  [195200/209452]\n",
      "loss: 0.071590  [198400/209452]\n",
      "loss: 0.010523  [201600/209452]\n",
      "loss: 0.000239  [204800/209452]\n",
      "loss: 0.000166  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.005131 \n",
      "\n",
      "Epoch 22\n",
      "---------------------------\n",
      "loss: 0.000242  [ 3200/209452]\n",
      "loss: 0.013869  [ 6400/209452]\n",
      "loss: 0.000384  [ 9600/209452]\n",
      "loss: 0.002213  [12800/209452]\n",
      "loss: 0.000046  [16000/209452]\n",
      "loss: 0.000089  [19200/209452]\n",
      "loss: 0.005362  [22400/209452]\n",
      "loss: 0.000611  [25600/209452]\n",
      "loss: 0.000390  [28800/209452]\n",
      "loss: 0.001663  [32000/209452]\n",
      "loss: 0.000166  [35200/209452]\n",
      "loss: 0.024565  [38400/209452]\n",
      "loss: 0.014077  [41600/209452]\n",
      "loss: 0.000954  [44800/209452]\n",
      "loss: 0.008213  [48000/209452]\n",
      "loss: 0.001287  [51200/209452]\n",
      "loss: 0.002615  [54400/209452]\n",
      "loss: 0.001429  [57600/209452]\n",
      "loss: 0.001747  [60800/209452]\n",
      "loss: 0.004809  [64000/209452]\n",
      "loss: 0.005902  [67200/209452]\n",
      "loss: 0.001032  [70400/209452]\n",
      "loss: 0.000335  [73600/209452]\n",
      "loss: 0.001570  [76800/209452]\n",
      "loss: 0.000141  [80000/209452]\n",
      "loss: 0.000253  [83200/209452]\n",
      "loss: 0.001606  [86400/209452]\n",
      "loss: 0.000334  [89600/209452]\n",
      "loss: 0.000254  [92800/209452]\n",
      "loss: 0.000562  [96000/209452]\n",
      "loss: 0.001725  [99200/209452]\n",
      "loss: 0.000320  [102400/209452]\n",
      "loss: 0.001115  [105600/209452]\n",
      "loss: 0.000239  [108800/209452]\n",
      "loss: 0.000872  [112000/209452]\n",
      "loss: 0.001810  [115200/209452]\n",
      "loss: 0.004734  [118400/209452]\n",
      "loss: 0.000241  [121600/209452]\n",
      "loss: 0.001568  [124800/209452]\n",
      "loss: 0.005489  [128000/209452]\n",
      "loss: 0.000523  [131200/209452]\n",
      "loss: 0.000313  [134400/209452]\n",
      "loss: 0.000623  [137600/209452]\n",
      "loss: 0.001406  [140800/209452]\n",
      "loss: 0.000667  [144000/209452]\n",
      "loss: 0.000565  [147200/209452]\n",
      "loss: 0.006611  [150400/209452]\n",
      "loss: 0.000103  [153600/209452]\n",
      "loss: 0.000663  [156800/209452]\n",
      "loss: 0.000777  [160000/209452]\n",
      "loss: 0.003569  [163200/209452]\n",
      "loss: 0.000269  [166400/209452]\n",
      "loss: 0.000977  [169600/209452]\n",
      "loss: 0.000364  [172800/209452]\n",
      "loss: 0.000086  [176000/209452]\n",
      "loss: 0.001429  [179200/209452]\n",
      "loss: 0.000705  [182400/209452]\n",
      "loss: 0.000214  [185600/209452]\n",
      "loss: 0.000595  [188800/209452]\n",
      "loss: 0.000396  [192000/209452]\n",
      "loss: 0.019072  [195200/209452]\n",
      "loss: 0.000145  [198400/209452]\n",
      "loss: 0.000613  [201600/209452]\n",
      "loss: 0.000453  [204800/209452]\n",
      "loss: 0.000434  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004822 \n",
      "\n",
      "Epoch 23\n",
      "---------------------------\n",
      "loss: 0.005698  [ 3200/209452]\n",
      "loss: 0.000342  [ 6400/209452]\n",
      "loss: 0.000198  [ 9600/209452]\n",
      "loss: 0.000304  [12800/209452]\n",
      "loss: 0.000201  [16000/209452]\n",
      "loss: 0.004984  [19200/209452]\n",
      "loss: 0.001421  [22400/209452]\n",
      "loss: 0.000270  [25600/209452]\n",
      "loss: 0.000360  [28800/209452]\n",
      "loss: 0.000050  [32000/209452]\n",
      "loss: 0.000591  [35200/209452]\n",
      "loss: 0.000298  [38400/209452]\n",
      "loss: 0.003328  [41600/209452]\n",
      "loss: 0.000453  [44800/209452]\n",
      "loss: 0.001324  [48000/209452]\n",
      "loss: 0.000159  [51200/209452]\n",
      "loss: 0.002229  [54400/209452]\n",
      "loss: 0.000605  [57600/209452]\n",
      "loss: 0.001838  [60800/209452]\n",
      "loss: 0.000214  [64000/209452]\n",
      "loss: 0.001398  [67200/209452]\n",
      "loss: 0.000257  [70400/209452]\n",
      "loss: 0.000701  [73600/209452]\n",
      "loss: 0.000815  [76800/209452]\n",
      "loss: 0.002241  [80000/209452]\n",
      "loss: 0.000253  [83200/209452]\n",
      "loss: 0.000195  [86400/209452]\n",
      "loss: 0.005363  [89600/209452]\n",
      "loss: 0.000359  [92800/209452]\n",
      "loss: 0.002627  [96000/209452]\n",
      "loss: 0.003160  [99200/209452]\n",
      "loss: 0.002473  [102400/209452]\n",
      "loss: 0.000488  [105600/209452]\n",
      "loss: 0.000159  [108800/209452]\n",
      "loss: 0.000673  [112000/209452]\n",
      "loss: 0.002420  [115200/209452]\n",
      "loss: 0.002602  [118400/209452]\n",
      "loss: 0.000160  [121600/209452]\n",
      "loss: 0.000506  [124800/209452]\n",
      "loss: 0.001126  [128000/209452]\n",
      "loss: 0.000081  [131200/209452]\n",
      "loss: 0.001063  [134400/209452]\n",
      "loss: 0.003913  [137600/209452]\n",
      "loss: 0.000121  [140800/209452]\n",
      "loss: 0.001113  [144000/209452]\n",
      "loss: 0.002239  [147200/209452]\n",
      "loss: 0.000316  [150400/209452]\n",
      "loss: 0.000644  [153600/209452]\n",
      "loss: 0.000777  [156800/209452]\n",
      "loss: 0.000959  [160000/209452]\n",
      "loss: 0.002312  [163200/209452]\n",
      "loss: 0.000156  [166400/209452]\n",
      "loss: 0.000107  [169600/209452]\n",
      "loss: 0.000047  [172800/209452]\n",
      "loss: 0.000503  [176000/209452]\n",
      "loss: 0.000102  [179200/209452]\n",
      "loss: 0.000321  [182400/209452]\n",
      "loss: 0.000047  [185600/209452]\n",
      "loss: 0.002896  [188800/209452]\n",
      "loss: 0.000553  [192000/209452]\n",
      "loss: 0.000577  [195200/209452]\n",
      "loss: 0.000135  [198400/209452]\n",
      "loss: 0.000338  [201600/209452]\n",
      "loss: 0.002980  [204800/209452]\n",
      "loss: 0.000176  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004401 \n",
      "\n",
      "Epoch 24\n",
      "---------------------------\n",
      "loss: 0.000432  [ 3200/209452]\n",
      "loss: 0.000181  [ 6400/209452]\n",
      "loss: 0.000706  [ 9600/209452]\n",
      "loss: 0.010179  [12800/209452]\n",
      "loss: 0.000239  [16000/209452]\n",
      "loss: 0.000848  [19200/209452]\n",
      "loss: 0.000166  [22400/209452]\n",
      "loss: 0.001134  [25600/209452]\n",
      "loss: 0.000292  [28800/209452]\n",
      "loss: 0.000645  [32000/209452]\n",
      "loss: 0.000276  [35200/209452]\n",
      "loss: 0.000667  [38400/209452]\n",
      "loss: 0.000155  [41600/209452]\n",
      "loss: 0.000555  [44800/209452]\n",
      "loss: 0.002043  [48000/209452]\n",
      "loss: 0.000060  [51200/209452]\n",
      "loss: 0.003849  [54400/209452]\n",
      "loss: 0.000043  [57600/209452]\n",
      "loss: 0.000376  [60800/209452]\n",
      "loss: 0.003544  [64000/209452]\n",
      "loss: 0.000472  [67200/209452]\n",
      "loss: 0.009121  [70400/209452]\n",
      "loss: 0.001326  [73600/209452]\n",
      "loss: 0.000167  [76800/209452]\n",
      "loss: 0.000024  [80000/209452]\n",
      "loss: 0.000248  [83200/209452]\n",
      "loss: 0.000863  [86400/209452]\n",
      "loss: 0.000034  [89600/209452]\n",
      "loss: 0.000253  [92800/209452]\n",
      "loss: 0.002429  [96000/209452]\n",
      "loss: 0.000280  [99200/209452]\n",
      "loss: 0.000632  [102400/209452]\n",
      "loss: 0.002521  [105600/209452]\n",
      "loss: 0.000465  [108800/209452]\n",
      "loss: 0.000670  [112000/209452]\n",
      "loss: 0.000056  [115200/209452]\n",
      "loss: 0.002782  [118400/209452]\n",
      "loss: 0.000157  [121600/209452]\n",
      "loss: 0.001726  [124800/209452]\n",
      "loss: 0.001079  [128000/209452]\n",
      "loss: 0.000397  [131200/209452]\n",
      "loss: 0.001655  [134400/209452]\n",
      "loss: 0.008359  [137600/209452]\n",
      "loss: 0.002020  [140800/209452]\n",
      "loss: 0.000047  [144000/209452]\n",
      "loss: 0.003748  [147200/209452]\n",
      "loss: 0.000062  [150400/209452]\n",
      "loss: 0.000208  [153600/209452]\n",
      "loss: 0.000458  [156800/209452]\n",
      "loss: 0.000114  [160000/209452]\n",
      "loss: 0.001068  [163200/209452]\n",
      "loss: 0.002184  [166400/209452]\n",
      "loss: 0.032384  [169600/209452]\n",
      "loss: 0.001485  [172800/209452]\n",
      "loss: 0.000293  [176000/209452]\n",
      "loss: 0.000976  [179200/209452]\n",
      "loss: 0.000366  [182400/209452]\n",
      "loss: 0.001413  [185600/209452]\n",
      "loss: 0.000231  [188800/209452]\n",
      "loss: 0.000479  [192000/209452]\n",
      "loss: 0.000345  [195200/209452]\n",
      "loss: 0.000269  [198400/209452]\n",
      "loss: 0.000175  [201600/209452]\n",
      "loss: 0.000505  [204800/209452]\n",
      "loss: 0.000501  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004192 \n",
      "\n",
      "Epoch 25\n",
      "---------------------------\n",
      "loss: 0.000383  [ 3200/209452]\n",
      "loss: 0.001138  [ 6400/209452]\n",
      "loss: 0.000250  [ 9600/209452]\n",
      "loss: 0.000100  [12800/209452]\n",
      "loss: 0.000424  [16000/209452]\n",
      "loss: 0.000178  [19200/209452]\n",
      "loss: 0.000344  [22400/209452]\n",
      "loss: 0.005643  [25600/209452]\n",
      "loss: 0.000398  [28800/209452]\n",
      "loss: 0.000255  [32000/209452]\n",
      "loss: 0.000346  [35200/209452]\n",
      "loss: 0.000294  [38400/209452]\n",
      "loss: 0.001284  [41600/209452]\n",
      "loss: 0.001979  [44800/209452]\n",
      "loss: 0.000784  [48000/209452]\n",
      "loss: 0.000205  [51200/209452]\n",
      "loss: 0.002646  [54400/209452]\n",
      "loss: 0.000072  [57600/209452]\n",
      "loss: 0.001114  [60800/209452]\n",
      "loss: 0.000350  [64000/209452]\n",
      "loss: 0.000253  [67200/209452]\n",
      "loss: 0.000214  [70400/209452]\n",
      "loss: 0.000872  [73600/209452]\n",
      "loss: 0.000266  [76800/209452]\n",
      "loss: 0.000543  [80000/209452]\n",
      "loss: 0.000282  [83200/209452]\n",
      "loss: 0.001055  [86400/209452]\n",
      "loss: 0.002038  [89600/209452]\n",
      "loss: 0.000387  [92800/209452]\n",
      "loss: 0.002097  [96000/209452]\n",
      "loss: 0.003133  [99200/209452]\n",
      "loss: 0.000226  [102400/209452]\n",
      "loss: 0.000538  [105600/209452]\n",
      "loss: 0.001169  [108800/209452]\n",
      "loss: 0.000843  [112000/209452]\n",
      "loss: 0.000343  [115200/209452]\n",
      "loss: 0.000404  [118400/209452]\n",
      "loss: 0.003619  [121600/209452]\n",
      "loss: 0.000280  [124800/209452]\n",
      "loss: 0.000747  [128000/209452]\n",
      "loss: 0.000385  [131200/209452]\n",
      "loss: 0.003280  [134400/209452]\n",
      "loss: 0.000305  [137600/209452]\n",
      "loss: 0.000230  [140800/209452]\n",
      "loss: 0.001421  [144000/209452]\n",
      "loss: 0.001178  [147200/209452]\n",
      "loss: 0.001115  [150400/209452]\n",
      "loss: 0.000223  [153600/209452]\n",
      "loss: 0.000649  [156800/209452]\n",
      "loss: 0.039930  [160000/209452]\n",
      "loss: 0.000141  [163200/209452]\n",
      "loss: 0.000894  [166400/209452]\n",
      "loss: 0.000577  [169600/209452]\n",
      "loss: 0.001440  [172800/209452]\n",
      "loss: 0.000409  [176000/209452]\n",
      "loss: 0.000340  [179200/209452]\n",
      "loss: 0.000582  [182400/209452]\n",
      "loss: 0.000156  [185600/209452]\n",
      "loss: 0.019347  [188800/209452]\n",
      "loss: 0.000427  [192000/209452]\n",
      "loss: 0.002644  [195200/209452]\n",
      "loss: 0.000183  [198400/209452]\n",
      "loss: 0.000634  [201600/209452]\n",
      "loss: 0.000064  [204800/209452]\n",
      "loss: 0.000544  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004039 \n",
      "\n",
      "Epoch 26\n",
      "---------------------------\n",
      "loss: 0.001355  [ 3200/209452]\n",
      "loss: 0.000170  [ 6400/209452]\n",
      "loss: 0.000116  [ 9600/209452]\n",
      "loss: 0.000922  [12800/209452]\n",
      "loss: 0.001198  [16000/209452]\n",
      "loss: 0.000053  [19200/209452]\n",
      "loss: 0.003166  [22400/209452]\n",
      "loss: 0.054348  [25600/209452]\n",
      "loss: 0.000185  [28800/209452]\n",
      "loss: 0.000172  [32000/209452]\n",
      "loss: 0.000127  [35200/209452]\n",
      "loss: 0.000289  [38400/209452]\n",
      "loss: 0.000160  [41600/209452]\n",
      "loss: 0.002782  [44800/209452]\n",
      "loss: 0.000818  [48000/209452]\n",
      "loss: 0.000233  [51200/209452]\n",
      "loss: 0.000116  [54400/209452]\n",
      "loss: 0.001024  [57600/209452]\n",
      "loss: 0.000324  [60800/209452]\n",
      "loss: 0.001540  [64000/209452]\n",
      "loss: 0.001434  [67200/209452]\n",
      "loss: 0.000458  [70400/209452]\n",
      "loss: 0.000114  [73600/209452]\n",
      "loss: 0.000401  [76800/209452]\n",
      "loss: 0.000889  [80000/209452]\n",
      "loss: 0.001005  [83200/209452]\n",
      "loss: 0.000215  [86400/209452]\n",
      "loss: 0.001156  [89600/209452]\n",
      "loss: 0.005745  [92800/209452]\n",
      "loss: 0.013242  [96000/209452]\n",
      "loss: 0.000213  [99200/209452]\n",
      "loss: 0.000941  [102400/209452]\n",
      "loss: 0.000153  [105600/209452]\n",
      "loss: 0.000206  [108800/209452]\n",
      "loss: 0.000400  [112000/209452]\n",
      "loss: 0.002164  [115200/209452]\n",
      "loss: 0.004099  [118400/209452]\n",
      "loss: 0.000304  [121600/209452]\n",
      "loss: 0.003701  [124800/209452]\n",
      "loss: 0.022598  [128000/209452]\n",
      "loss: 0.000137  [131200/209452]\n",
      "loss: 0.000155  [134400/209452]\n",
      "loss: 0.001545  [137600/209452]\n",
      "loss: 0.004771  [140800/209452]\n",
      "loss: 0.000986  [144000/209452]\n",
      "loss: 0.001270  [147200/209452]\n",
      "loss: 0.000152  [150400/209452]\n",
      "loss: 0.000213  [153600/209452]\n",
      "loss: 0.000562  [156800/209452]\n",
      "loss: 0.000369  [160000/209452]\n",
      "loss: 0.000235  [163200/209452]\n",
      "loss: 0.000953  [166400/209452]\n",
      "loss: 0.013168  [169600/209452]\n",
      "loss: 0.006253  [172800/209452]\n",
      "loss: 0.034183  [176000/209452]\n",
      "loss: 0.006184  [179200/209452]\n",
      "loss: 0.000301  [182400/209452]\n",
      "loss: 0.000248  [185600/209452]\n",
      "loss: 0.000133  [188800/209452]\n",
      "loss: 0.000187  [192000/209452]\n",
      "loss: 0.000107  [195200/209452]\n",
      "loss: 0.000149  [198400/209452]\n",
      "loss: 0.000487  [201600/209452]\n",
      "loss: 0.004800  [204800/209452]\n",
      "loss: 0.001950  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004083 \n",
      "\n",
      "Epoch 27\n",
      "---------------------------\n",
      "loss: 0.000568  [ 3200/209452]\n",
      "loss: 0.000172  [ 6400/209452]\n",
      "loss: 0.000214  [ 9600/209452]\n",
      "loss: 0.008113  [12800/209452]\n",
      "loss: 0.000037  [16000/209452]\n",
      "loss: 0.000441  [19200/209452]\n",
      "loss: 0.002038  [22400/209452]\n",
      "loss: 0.000221  [25600/209452]\n",
      "loss: 0.000055  [28800/209452]\n",
      "loss: 0.000350  [32000/209452]\n",
      "loss: 0.000460  [35200/209452]\n",
      "loss: 0.000311  [38400/209452]\n",
      "loss: 0.000327  [41600/209452]\n",
      "loss: 0.000831  [44800/209452]\n",
      "loss: 0.000432  [48000/209452]\n",
      "loss: 0.002711  [51200/209452]\n",
      "loss: 0.001217  [54400/209452]\n",
      "loss: 0.000406  [57600/209452]\n",
      "loss: 0.000426  [60800/209452]\n",
      "loss: 0.002525  [64000/209452]\n",
      "loss: 0.000035  [67200/209452]\n",
      "loss: 0.003020  [70400/209452]\n",
      "loss: 0.002932  [73600/209452]\n",
      "loss: 0.000224  [76800/209452]\n",
      "loss: 0.000637  [80000/209452]\n",
      "loss: 0.000822  [83200/209452]\n",
      "loss: 0.000264  [86400/209452]\n",
      "loss: 0.000455  [89600/209452]\n",
      "loss: 0.003849  [92800/209452]\n",
      "loss: 0.000392  [96000/209452]\n",
      "loss: 0.000199  [99200/209452]\n",
      "loss: 0.009133  [102400/209452]\n",
      "loss: 0.000371  [105600/209452]\n",
      "loss: 0.000239  [108800/209452]\n",
      "loss: 0.000533  [112000/209452]\n",
      "loss: 0.004212  [115200/209452]\n",
      "loss: 0.005537  [118400/209452]\n",
      "loss: 0.000613  [121600/209452]\n",
      "loss: 0.000716  [124800/209452]\n",
      "loss: 0.000725  [128000/209452]\n",
      "loss: 0.000345  [131200/209452]\n",
      "loss: 0.000190  [134400/209452]\n",
      "loss: 0.004088  [137600/209452]\n",
      "loss: 0.000124  [140800/209452]\n",
      "loss: 0.000190  [144000/209452]\n",
      "loss: 0.000633  [147200/209452]\n",
      "loss: 0.002709  [150400/209452]\n",
      "loss: 0.000531  [153600/209452]\n",
      "loss: 0.002499  [156800/209452]\n",
      "loss: 0.000772  [160000/209452]\n",
      "loss: 0.004302  [163200/209452]\n",
      "loss: 0.000143  [166400/209452]\n",
      "loss: 0.000475  [169600/209452]\n",
      "loss: 0.000411  [172800/209452]\n",
      "loss: 0.001002  [176000/209452]\n",
      "loss: 0.000491  [179200/209452]\n",
      "loss: 0.000176  [182400/209452]\n",
      "loss: 0.000087  [185600/209452]\n",
      "loss: 0.000099  [188800/209452]\n",
      "loss: 0.001160  [192000/209452]\n",
      "loss: 0.000181  [195200/209452]\n",
      "loss: 0.002334  [198400/209452]\n",
      "loss: 0.000268  [201600/209452]\n",
      "loss: 0.000699  [204800/209452]\n",
      "loss: 0.001004  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004582 \n",
      "\n",
      "Epoch 28\n",
      "---------------------------\n",
      "loss: 0.000548  [ 3200/209452]\n",
      "loss: 0.000483  [ 6400/209452]\n",
      "loss: 0.000297  [ 9600/209452]\n",
      "loss: 0.000152  [12800/209452]\n",
      "loss: 0.000458  [16000/209452]\n",
      "loss: 0.000026  [19200/209452]\n",
      "loss: 0.000109  [22400/209452]\n",
      "loss: 0.000129  [25600/209452]\n",
      "loss: 0.000018  [28800/209452]\n",
      "loss: 0.000385  [32000/209452]\n",
      "loss: 0.000367  [35200/209452]\n",
      "loss: 0.020486  [38400/209452]\n",
      "loss: 0.000457  [41600/209452]\n",
      "loss: 0.000514  [44800/209452]\n",
      "loss: 0.000954  [48000/209452]\n",
      "loss: 0.003450  [51200/209452]\n",
      "loss: 0.000712  [54400/209452]\n",
      "loss: 0.000493  [57600/209452]\n",
      "loss: 0.002813  [60800/209452]\n",
      "loss: 0.000156  [64000/209452]\n",
      "loss: 0.000124  [67200/209452]\n",
      "loss: 0.000260  [70400/209452]\n",
      "loss: 0.000889  [73600/209452]\n",
      "loss: 0.003779  [76800/209452]\n",
      "loss: 0.000260  [80000/209452]\n",
      "loss: 0.001145  [83200/209452]\n",
      "loss: 0.000327  [86400/209452]\n",
      "loss: 0.000626  [89600/209452]\n",
      "loss: 0.001225  [92800/209452]\n",
      "loss: 0.000595  [96000/209452]\n",
      "loss: 0.000214  [99200/209452]\n",
      "loss: 0.004552  [102400/209452]\n",
      "loss: 0.019983  [105600/209452]\n",
      "loss: 0.000393  [108800/209452]\n",
      "loss: 0.000868  [112000/209452]\n",
      "loss: 0.000517  [115200/209452]\n",
      "loss: 0.000241  [118400/209452]\n",
      "loss: 0.000430  [121600/209452]\n",
      "loss: 0.000655  [124800/209452]\n",
      "loss: 0.000573  [128000/209452]\n",
      "loss: 0.000250  [131200/209452]\n",
      "loss: 0.000292  [134400/209452]\n",
      "loss: 0.000168  [137600/209452]\n",
      "loss: 0.000650  [140800/209452]\n",
      "loss: 0.001252  [144000/209452]\n",
      "loss: 0.000581  [147200/209452]\n",
      "loss: 0.001807  [150400/209452]\n",
      "loss: 0.001651  [153600/209452]\n",
      "loss: 0.000092  [156800/209452]\n",
      "loss: 0.000443  [160000/209452]\n",
      "loss: 0.000055  [163200/209452]\n",
      "loss: 0.006806  [166400/209452]\n",
      "loss: 0.001188  [169600/209452]\n",
      "loss: 0.001271  [172800/209452]\n",
      "loss: 0.000091  [176000/209452]\n",
      "loss: 0.000209  [179200/209452]\n",
      "loss: 0.000409  [182400/209452]\n",
      "loss: 0.000415  [185600/209452]\n",
      "loss: 0.000507  [188800/209452]\n",
      "loss: 0.001684  [192000/209452]\n",
      "loss: 0.000629  [195200/209452]\n",
      "loss: 0.000602  [198400/209452]\n",
      "loss: 0.000701  [201600/209452]\n",
      "loss: 0.000075  [204800/209452]\n",
      "loss: 0.000834  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.004051 \n",
      "\n",
      "Epoch 29\n",
      "---------------------------\n",
      "loss: 0.000500  [ 3200/209452]\n",
      "loss: 0.003442  [ 6400/209452]\n",
      "loss: 0.000139  [ 9600/209452]\n",
      "loss: 0.001541  [12800/209452]\n",
      "loss: 0.000411  [16000/209452]\n",
      "loss: 0.000232  [19200/209452]\n",
      "loss: 0.003109  [22400/209452]\n",
      "loss: 0.000376  [25600/209452]\n",
      "loss: 0.000086  [28800/209452]\n",
      "loss: 0.000356  [32000/209452]\n",
      "loss: 0.001036  [35200/209452]\n",
      "loss: 0.000173  [38400/209452]\n",
      "loss: 0.001442  [41600/209452]\n",
      "loss: 0.000985  [44800/209452]\n",
      "loss: 0.000170  [48000/209452]\n",
      "loss: 0.000205  [51200/209452]\n",
      "loss: 0.000387  [54400/209452]\n",
      "loss: 0.001731  [57600/209452]\n",
      "loss: 0.018851  [60800/209452]\n",
      "loss: 0.000361  [64000/209452]\n",
      "loss: 0.000094  [67200/209452]\n",
      "loss: 0.000223  [70400/209452]\n",
      "loss: 0.004690  [73600/209452]\n",
      "loss: 0.008006  [76800/209452]\n",
      "loss: 0.000321  [80000/209452]\n",
      "loss: 0.000404  [83200/209452]\n",
      "loss: 0.000242  [86400/209452]\n",
      "loss: 0.001231  [89600/209452]\n",
      "loss: 0.001197  [92800/209452]\n",
      "loss: 0.000332  [96000/209452]\n",
      "loss: 0.001459  [99200/209452]\n",
      "loss: 0.000165  [102400/209452]\n",
      "loss: 0.000282  [105600/209452]\n",
      "loss: 0.000273  [108800/209452]\n",
      "loss: 0.000254  [112000/209452]\n",
      "loss: 0.000126  [115200/209452]\n",
      "loss: 0.001100  [118400/209452]\n",
      "loss: 0.000066  [121600/209452]\n",
      "loss: 0.000287  [124800/209452]\n",
      "loss: 0.000109  [128000/209452]\n",
      "loss: 0.018123  [131200/209452]\n",
      "loss: 0.000136  [134400/209452]\n",
      "loss: 0.000150  [137600/209452]\n",
      "loss: 0.022849  [140800/209452]\n",
      "loss: 0.000501  [144000/209452]\n",
      "loss: 0.000176  [147200/209452]\n",
      "loss: 0.001493  [150400/209452]\n",
      "loss: 0.000139  [153600/209452]\n",
      "loss: 0.002512  [156800/209452]\n",
      "loss: 0.001195  [160000/209452]\n",
      "loss: 0.000236  [163200/209452]\n",
      "loss: 0.009640  [166400/209452]\n",
      "loss: 0.000308  [169600/209452]\n",
      "loss: 0.000238  [172800/209452]\n",
      "loss: 0.000348  [176000/209452]\n",
      "loss: 0.000287  [179200/209452]\n",
      "loss: 0.000080  [182400/209452]\n",
      "loss: 0.000037  [185600/209452]\n",
      "loss: 0.001909  [188800/209452]\n",
      "loss: 0.000985  [192000/209452]\n",
      "loss: 0.001291  [195200/209452]\n",
      "loss: 0.000523  [198400/209452]\n",
      "loss: 0.002929  [201600/209452]\n",
      "loss: 0.000540  [204800/209452]\n",
      "loss: 0.000241  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003655 \n",
      "\n",
      "Epoch 30\n",
      "---------------------------\n",
      "loss: 0.000224  [ 3200/209452]\n",
      "loss: 0.000216  [ 6400/209452]\n",
      "loss: 0.000190  [ 9600/209452]\n",
      "loss: 0.000507  [12800/209452]\n",
      "loss: 0.000101  [16000/209452]\n",
      "loss: 0.012733  [19200/209452]\n",
      "loss: 0.000764  [22400/209452]\n",
      "loss: 0.000769  [25600/209452]\n",
      "loss: 0.001562  [28800/209452]\n",
      "loss: 0.000582  [32000/209452]\n",
      "loss: 0.000226  [35200/209452]\n",
      "loss: 0.002491  [38400/209452]\n",
      "loss: 0.000175  [41600/209452]\n",
      "loss: 0.000267  [44800/209452]\n",
      "loss: 0.000244  [48000/209452]\n",
      "loss: 0.000289  [51200/209452]\n",
      "loss: 0.000172  [54400/209452]\n",
      "loss: 0.000205  [57600/209452]\n",
      "loss: 0.000439  [60800/209452]\n",
      "loss: 0.000079  [64000/209452]\n",
      "loss: 0.000389  [67200/209452]\n",
      "loss: 0.000058  [70400/209452]\n",
      "loss: 0.004364  [73600/209452]\n",
      "loss: 0.000197  [76800/209452]\n",
      "loss: 0.000225  [80000/209452]\n",
      "loss: 0.001518  [83200/209452]\n",
      "loss: 0.000344  [86400/209452]\n",
      "loss: 0.000066  [89600/209452]\n",
      "loss: 0.010915  [92800/209452]\n",
      "loss: 0.000075  [96000/209452]\n",
      "loss: 0.000404  [99200/209452]\n",
      "loss: 0.000430  [102400/209452]\n",
      "loss: 0.000373  [105600/209452]\n",
      "loss: 0.000281  [108800/209452]\n",
      "loss: 0.000248  [112000/209452]\n",
      "loss: 0.000678  [115200/209452]\n",
      "loss: 0.005104  [118400/209452]\n",
      "loss: 0.010121  [121600/209452]\n",
      "loss: 0.001631  [124800/209452]\n",
      "loss: 0.000774  [128000/209452]\n",
      "loss: 0.000549  [131200/209452]\n",
      "loss: 0.000262  [134400/209452]\n",
      "loss: 0.002112  [137600/209452]\n",
      "loss: 0.000747  [140800/209452]\n",
      "loss: 0.019793  [144000/209452]\n",
      "loss: 0.000090  [147200/209452]\n",
      "loss: 0.000136  [150400/209452]\n",
      "loss: 0.001355  [153600/209452]\n",
      "loss: 0.000074  [156800/209452]\n",
      "loss: 0.000403  [160000/209452]\n",
      "loss: 0.000099  [163200/209452]\n",
      "loss: 0.000155  [166400/209452]\n",
      "loss: 0.000314  [169600/209452]\n",
      "loss: 0.003499  [172800/209452]\n",
      "loss: 0.000400  [176000/209452]\n",
      "loss: 0.000980  [179200/209452]\n",
      "loss: 0.000276  [182400/209452]\n",
      "loss: 0.000976  [185600/209452]\n",
      "loss: 0.000250  [188800/209452]\n",
      "loss: 0.000507  [192000/209452]\n",
      "loss: 0.000155  [195200/209452]\n",
      "loss: 0.000082  [198400/209452]\n",
      "loss: 0.000687  [201600/209452]\n",
      "loss: 0.001090  [204800/209452]\n",
      "loss: 0.000478  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003640 \n",
      "\n",
      "Epoch 31\n",
      "---------------------------\n",
      "loss: 0.000095  [ 3200/209452]\n",
      "loss: 0.000370  [ 6400/209452]\n",
      "loss: 0.000107  [ 9600/209452]\n",
      "loss: 0.000437  [12800/209452]\n",
      "loss: 0.000088  [16000/209452]\n",
      "loss: 0.000072  [19200/209452]\n",
      "loss: 0.000494  [22400/209452]\n",
      "loss: 0.000497  [25600/209452]\n",
      "loss: 0.000108  [28800/209452]\n",
      "loss: 0.000471  [32000/209452]\n",
      "loss: 0.000272  [35200/209452]\n",
      "loss: 0.000670  [38400/209452]\n",
      "loss: 0.001970  [41600/209452]\n",
      "loss: 0.000277  [44800/209452]\n",
      "loss: 0.000344  [48000/209452]\n",
      "loss: 0.000388  [51200/209452]\n",
      "loss: 0.003130  [54400/209452]\n",
      "loss: 0.001295  [57600/209452]\n",
      "loss: 0.000497  [60800/209452]\n",
      "loss: 0.001095  [64000/209452]\n",
      "loss: 0.001076  [67200/209452]\n",
      "loss: 0.000708  [70400/209452]\n",
      "loss: 0.002546  [73600/209452]\n",
      "loss: 0.000314  [76800/209452]\n",
      "loss: 0.000359  [80000/209452]\n",
      "loss: 0.002036  [83200/209452]\n",
      "loss: 0.003520  [86400/209452]\n",
      "loss: 0.000164  [89600/209452]\n",
      "loss: 0.000229  [92800/209452]\n",
      "loss: 0.001093  [96000/209452]\n",
      "loss: 0.006279  [99200/209452]\n",
      "loss: 0.000098  [102400/209452]\n",
      "loss: 0.000286  [105600/209452]\n",
      "loss: 0.000572  [108800/209452]\n",
      "loss: 0.000121  [112000/209452]\n",
      "loss: 0.001439  [115200/209452]\n",
      "loss: 0.001403  [118400/209452]\n",
      "loss: 0.000115  [121600/209452]\n",
      "loss: 0.001286  [124800/209452]\n",
      "loss: 0.000940  [128000/209452]\n",
      "loss: 0.000537  [131200/209452]\n",
      "loss: 0.000227  [134400/209452]\n",
      "loss: 0.000224  [137600/209452]\n",
      "loss: 0.001707  [140800/209452]\n",
      "loss: 0.000032  [144000/209452]\n",
      "loss: 0.000571  [147200/209452]\n",
      "loss: 0.000377  [150400/209452]\n",
      "loss: 0.000448  [153600/209452]\n",
      "loss: 0.000472  [156800/209452]\n",
      "loss: 0.000168  [160000/209452]\n",
      "loss: 0.000567  [163200/209452]\n",
      "loss: 0.000172  [166400/209452]\n",
      "loss: 0.000112  [169600/209452]\n",
      "loss: 0.000409  [172800/209452]\n",
      "loss: 0.000155  [176000/209452]\n",
      "loss: 0.000472  [179200/209452]\n",
      "loss: 0.000198  [182400/209452]\n",
      "loss: 0.001193  [185600/209452]\n",
      "loss: 0.000048  [188800/209452]\n",
      "loss: 0.000337  [192000/209452]\n",
      "loss: 0.000330  [195200/209452]\n",
      "loss: 0.000774  [198400/209452]\n",
      "loss: 0.000241  [201600/209452]\n",
      "loss: 0.000354  [204800/209452]\n",
      "loss: 0.000042  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003755 \n",
      "\n",
      "Epoch 32\n",
      "---------------------------\n",
      "loss: 0.000253  [ 3200/209452]\n",
      "loss: 0.002526  [ 6400/209452]\n",
      "loss: 0.000392  [ 9600/209452]\n",
      "loss: 0.001292  [12800/209452]\n",
      "loss: 0.000355  [16000/209452]\n",
      "loss: 0.000494  [19200/209452]\n",
      "loss: 0.005707  [22400/209452]\n",
      "loss: 0.000298  [25600/209452]\n",
      "loss: 0.001185  [28800/209452]\n",
      "loss: 0.002753  [32000/209452]\n",
      "loss: 0.000122  [35200/209452]\n",
      "loss: 0.001779  [38400/209452]\n",
      "loss: 0.002509  [41600/209452]\n",
      "loss: 0.000290  [44800/209452]\n",
      "loss: 0.000220  [48000/209452]\n",
      "loss: 0.006691  [51200/209452]\n",
      "loss: 0.000364  [54400/209452]\n",
      "loss: 0.000347  [57600/209452]\n",
      "loss: 0.000103  [60800/209452]\n",
      "loss: 0.003200  [64000/209452]\n",
      "loss: 0.000258  [67200/209452]\n",
      "loss: 0.000448  [70400/209452]\n",
      "loss: 0.000369  [73600/209452]\n",
      "loss: 0.000094  [76800/209452]\n",
      "loss: 0.000322  [80000/209452]\n",
      "loss: 0.000123  [83200/209452]\n",
      "loss: 0.000717  [86400/209452]\n",
      "loss: 0.000271  [89600/209452]\n",
      "loss: 0.000897  [92800/209452]\n",
      "loss: 0.001488  [96000/209452]\n",
      "loss: 0.001045  [99200/209452]\n",
      "loss: 0.001866  [102400/209452]\n",
      "loss: 0.000259  [105600/209452]\n",
      "loss: 0.000515  [108800/209452]\n",
      "loss: 0.000934  [112000/209452]\n",
      "loss: 0.000086  [115200/209452]\n",
      "loss: 0.005951  [118400/209452]\n",
      "loss: 0.000157  [121600/209452]\n",
      "loss: 0.002778  [124800/209452]\n",
      "loss: 0.000250  [128000/209452]\n",
      "loss: 0.000127  [131200/209452]\n",
      "loss: 0.000646  [134400/209452]\n",
      "loss: 0.000335  [137600/209452]\n",
      "loss: 0.000490  [140800/209452]\n",
      "loss: 0.000764  [144000/209452]\n",
      "loss: 0.013628  [147200/209452]\n",
      "loss: 0.000292  [150400/209452]\n",
      "loss: 0.000142  [153600/209452]\n",
      "loss: 0.000143  [156800/209452]\n",
      "loss: 0.000080  [160000/209452]\n",
      "loss: 0.003882  [163200/209452]\n",
      "loss: 0.000668  [166400/209452]\n",
      "loss: 0.000605  [169600/209452]\n",
      "loss: 0.000201  [172800/209452]\n",
      "loss: 0.000379  [176000/209452]\n",
      "loss: 0.000430  [179200/209452]\n",
      "loss: 0.011109  [182400/209452]\n",
      "loss: 0.000180  [185600/209452]\n",
      "loss: 0.000552  [188800/209452]\n",
      "loss: 0.000013  [192000/209452]\n",
      "loss: 0.000341  [195200/209452]\n",
      "loss: 0.000138  [198400/209452]\n",
      "loss: 0.000607  [201600/209452]\n",
      "loss: 0.000235  [204800/209452]\n",
      "loss: 0.000156  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003258 \n",
      "\n",
      "Epoch 33\n",
      "---------------------------\n",
      "loss: 0.001035  [ 3200/209452]\n",
      "loss: 0.000470  [ 6400/209452]\n",
      "loss: 0.000042  [ 9600/209452]\n",
      "loss: 0.000180  [12800/209452]\n",
      "loss: 0.000454  [16000/209452]\n",
      "loss: 0.000218  [19200/209452]\n",
      "loss: 0.000158  [22400/209452]\n",
      "loss: 0.000046  [25600/209452]\n",
      "loss: 0.001208  [28800/209452]\n",
      "loss: 0.000134  [32000/209452]\n",
      "loss: 0.002277  [35200/209452]\n",
      "loss: 0.000411  [38400/209452]\n",
      "loss: 0.000432  [41600/209452]\n",
      "loss: 0.000174  [44800/209452]\n",
      "loss: 0.000184  [48000/209452]\n",
      "loss: 0.000085  [51200/209452]\n",
      "loss: 0.003169  [54400/209452]\n",
      "loss: 0.000679  [57600/209452]\n",
      "loss: 0.000206  [60800/209452]\n",
      "loss: 0.000092  [64000/209452]\n",
      "loss: 0.003346  [67200/209452]\n",
      "loss: 0.000352  [70400/209452]\n",
      "loss: 0.001304  [73600/209452]\n",
      "loss: 0.000067  [76800/209452]\n",
      "loss: 0.003418  [80000/209452]\n",
      "loss: 0.000092  [83200/209452]\n",
      "loss: 0.000236  [86400/209452]\n",
      "loss: 0.000088  [89600/209452]\n",
      "loss: 0.000363  [92800/209452]\n",
      "loss: 0.000587  [96000/209452]\n",
      "loss: 0.000128  [99200/209452]\n",
      "loss: 0.001362  [102400/209452]\n",
      "loss: 0.000053  [105600/209452]\n",
      "loss: 0.001237  [108800/209452]\n",
      "loss: 0.000662  [112000/209452]\n",
      "loss: 0.000127  [115200/209452]\n",
      "loss: 0.001005  [118400/209452]\n",
      "loss: 0.000237  [121600/209452]\n",
      "loss: 0.000324  [124800/209452]\n",
      "loss: 0.000426  [128000/209452]\n",
      "loss: 0.000634  [131200/209452]\n",
      "loss: 0.000297  [134400/209452]\n",
      "loss: 0.000138  [137600/209452]\n",
      "loss: 0.000202  [140800/209452]\n",
      "loss: 0.001665  [144000/209452]\n",
      "loss: 0.000118  [147200/209452]\n",
      "loss: 0.000031  [150400/209452]\n",
      "loss: 0.000153  [153600/209452]\n",
      "loss: 0.000020  [156800/209452]\n",
      "loss: 0.000825  [160000/209452]\n",
      "loss: 0.000330  [163200/209452]\n",
      "loss: 0.000217  [166400/209452]\n",
      "loss: 0.000025  [169600/209452]\n",
      "loss: 0.000046  [172800/209452]\n",
      "loss: 0.000899  [176000/209452]\n",
      "loss: 0.000188  [179200/209452]\n",
      "loss: 0.000192  [182400/209452]\n",
      "loss: 0.000387  [185600/209452]\n",
      "loss: 0.001284  [188800/209452]\n",
      "loss: 0.001143  [192000/209452]\n",
      "loss: 0.000296  [195200/209452]\n",
      "loss: 0.000076  [198400/209452]\n",
      "loss: 0.000206  [201600/209452]\n",
      "loss: 0.000313  [204800/209452]\n",
      "loss: 0.000024  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003371 \n",
      "\n",
      "Epoch 34\n",
      "---------------------------\n",
      "loss: 0.000395  [ 3200/209452]\n",
      "loss: 0.000988  [ 6400/209452]\n",
      "loss: 0.007257  [ 9600/209452]\n",
      "loss: 0.001571  [12800/209452]\n",
      "loss: 0.000884  [16000/209452]\n",
      "loss: 0.001092  [19200/209452]\n",
      "loss: 0.000050  [22400/209452]\n",
      "loss: 0.000155  [25600/209452]\n",
      "loss: 0.002521  [28800/209452]\n",
      "loss: 0.000247  [32000/209452]\n",
      "loss: 0.003726  [35200/209452]\n",
      "loss: 0.000153  [38400/209452]\n",
      "loss: 0.000127  [41600/209452]\n",
      "loss: 0.000045  [44800/209452]\n",
      "loss: 0.001835  [48000/209452]\n",
      "loss: 0.000247  [51200/209452]\n",
      "loss: 0.000086  [54400/209452]\n",
      "loss: 0.000113  [57600/209452]\n",
      "loss: 0.000172  [60800/209452]\n",
      "loss: 0.000173  [64000/209452]\n",
      "loss: 0.000557  [67200/209452]\n",
      "loss: 0.002583  [70400/209452]\n",
      "loss: 0.000121  [73600/209452]\n",
      "loss: 0.001788  [76800/209452]\n",
      "loss: 0.000151  [80000/209452]\n",
      "loss: 0.002095  [83200/209452]\n",
      "loss: 0.000415  [86400/209452]\n",
      "loss: 0.004712  [89600/209452]\n",
      "loss: 0.000315  [92800/209452]\n",
      "loss: 0.000132  [96000/209452]\n",
      "loss: 0.000120  [99200/209452]\n",
      "loss: 0.000733  [102400/209452]\n",
      "loss: 0.001289  [105600/209452]\n",
      "loss: 0.000067  [108800/209452]\n",
      "loss: 0.000220  [112000/209452]\n",
      "loss: 0.000370  [115200/209452]\n",
      "loss: 0.000363  [118400/209452]\n",
      "loss: 0.000610  [121600/209452]\n",
      "loss: 0.000603  [124800/209452]\n",
      "loss: 0.000465  [128000/209452]\n",
      "loss: 0.000043  [131200/209452]\n",
      "loss: 0.000294  [134400/209452]\n",
      "loss: 0.000038  [137600/209452]\n",
      "loss: 0.000164  [140800/209452]\n",
      "loss: 0.003209  [144000/209452]\n",
      "loss: 0.000169  [147200/209452]\n",
      "loss: 0.000428  [150400/209452]\n",
      "loss: 0.000386  [153600/209452]\n",
      "loss: 0.000133  [156800/209452]\n",
      "loss: 0.000020  [160000/209452]\n",
      "loss: 0.000293  [163200/209452]\n",
      "loss: 0.000237  [166400/209452]\n",
      "loss: 0.002725  [169600/209452]\n",
      "loss: 0.001033  [172800/209452]\n",
      "loss: 0.002234  [176000/209452]\n",
      "loss: 0.000308  [179200/209452]\n",
      "loss: 0.000093  [182400/209452]\n",
      "loss: 0.000516  [185600/209452]\n",
      "loss: 0.000396  [188800/209452]\n",
      "loss: 0.000608  [192000/209452]\n",
      "loss: 0.000027  [195200/209452]\n",
      "loss: 0.000305  [198400/209452]\n",
      "loss: 0.000058  [201600/209452]\n",
      "loss: 0.010486  [204800/209452]\n",
      "loss: 0.000211  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003270 \n",
      "\n",
      "Epoch 35\n",
      "---------------------------\n",
      "loss: 0.000038  [ 3200/209452]\n",
      "loss: 0.000009  [ 6400/209452]\n",
      "loss: 0.000268  [ 9600/209452]\n",
      "loss: 0.000502  [12800/209452]\n",
      "loss: 0.000760  [16000/209452]\n",
      "loss: 0.003131  [19200/209452]\n",
      "loss: 0.000271  [22400/209452]\n",
      "loss: 0.000078  [25600/209452]\n",
      "loss: 0.000677  [28800/209452]\n",
      "loss: 0.000259  [32000/209452]\n",
      "loss: 0.000713  [35200/209452]\n",
      "loss: 0.002887  [38400/209452]\n",
      "loss: 0.000033  [41600/209452]\n",
      "loss: 0.001013  [44800/209452]\n",
      "loss: 0.000297  [48000/209452]\n",
      "loss: 0.000043  [51200/209452]\n",
      "loss: 0.000058  [54400/209452]\n",
      "loss: 0.000106  [57600/209452]\n",
      "loss: 0.000131  [60800/209452]\n",
      "loss: 0.009813  [64000/209452]\n",
      "loss: 0.000154  [67200/209452]\n",
      "loss: 0.000544  [70400/209452]\n",
      "loss: 0.000462  [73600/209452]\n",
      "loss: 0.000694  [76800/209452]\n",
      "loss: 0.000351  [80000/209452]\n",
      "loss: 0.000099  [83200/209452]\n",
      "loss: 0.001634  [86400/209452]\n",
      "loss: 0.000327  [89600/209452]\n",
      "loss: 0.000360  [92800/209452]\n",
      "loss: 0.000084  [96000/209452]\n",
      "loss: 0.000319  [99200/209452]\n",
      "loss: 0.000057  [102400/209452]\n",
      "loss: 0.000595  [105600/209452]\n",
      "loss: 0.002059  [108800/209452]\n",
      "loss: 0.000554  [112000/209452]\n",
      "loss: 0.001428  [115200/209452]\n",
      "loss: 0.002213  [118400/209452]\n",
      "loss: 0.000172  [121600/209452]\n",
      "loss: 0.001049  [124800/209452]\n",
      "loss: 0.000963  [128000/209452]\n",
      "loss: 0.001062  [131200/209452]\n",
      "loss: 0.000106  [134400/209452]\n",
      "loss: 0.001156  [137600/209452]\n",
      "loss: 0.000333  [140800/209452]\n",
      "loss: 0.000118  [144000/209452]\n",
      "loss: 0.000725  [147200/209452]\n",
      "loss: 0.001089  [150400/209452]\n",
      "loss: 0.002859  [153600/209452]\n",
      "loss: 0.002800  [156800/209452]\n",
      "loss: 0.000221  [160000/209452]\n",
      "loss: 0.000570  [163200/209452]\n",
      "loss: 0.000155  [166400/209452]\n",
      "loss: 0.000105  [169600/209452]\n",
      "loss: 0.000471  [172800/209452]\n",
      "loss: 0.000109  [176000/209452]\n",
      "loss: 0.000433  [179200/209452]\n",
      "loss: 0.000144  [182400/209452]\n",
      "loss: 0.002079  [185600/209452]\n",
      "loss: 0.000338  [188800/209452]\n",
      "loss: 0.000115  [192000/209452]\n",
      "loss: 0.000904  [195200/209452]\n",
      "loss: 0.000353  [198400/209452]\n",
      "loss: 0.000088  [201600/209452]\n",
      "loss: 0.000007  [204800/209452]\n",
      "loss: 0.000135  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003367 \n",
      "\n",
      "Epoch 36\n",
      "---------------------------\n",
      "loss: 0.000207  [ 3200/209452]\n",
      "loss: 0.000136  [ 6400/209452]\n",
      "loss: 0.000143  [ 9600/209452]\n",
      "loss: 0.000061  [12800/209452]\n",
      "loss: 0.000192  [16000/209452]\n",
      "loss: 0.000040  [19200/209452]\n",
      "loss: 0.000184  [22400/209452]\n",
      "loss: 0.000090  [25600/209452]\n",
      "loss: 0.000715  [28800/209452]\n",
      "loss: 0.000110  [32000/209452]\n",
      "loss: 0.000108  [35200/209452]\n",
      "loss: 0.003306  [38400/209452]\n",
      "loss: 0.000221  [41600/209452]\n",
      "loss: 0.000231  [44800/209452]\n",
      "loss: 0.000122  [48000/209452]\n",
      "loss: 0.002614  [51200/209452]\n",
      "loss: 0.000058  [54400/209452]\n",
      "loss: 0.000040  [57600/209452]\n",
      "loss: 0.007981  [60800/209452]\n",
      "loss: 0.002841  [64000/209452]\n",
      "loss: 0.001765  [67200/209452]\n",
      "loss: 0.000186  [70400/209452]\n",
      "loss: 0.000131  [73600/209452]\n",
      "loss: 0.000144  [76800/209452]\n",
      "loss: 0.000340  [80000/209452]\n",
      "loss: 0.000070  [83200/209452]\n",
      "loss: 0.000148  [86400/209452]\n",
      "loss: 0.000539  [89600/209452]\n",
      "loss: 0.000414  [92800/209452]\n",
      "loss: 0.000238  [96000/209452]\n",
      "loss: 0.000070  [99200/209452]\n",
      "loss: 0.001885  [102400/209452]\n",
      "loss: 0.003840  [105600/209452]\n",
      "loss: 0.000871  [108800/209452]\n",
      "loss: 0.000210  [112000/209452]\n",
      "loss: 0.000257  [115200/209452]\n",
      "loss: 0.004267  [118400/209452]\n",
      "loss: 0.000949  [121600/209452]\n",
      "loss: 0.000049  [124800/209452]\n",
      "loss: 0.000524  [128000/209452]\n",
      "loss: 0.002265  [131200/209452]\n",
      "loss: 0.001138  [134400/209452]\n",
      "loss: 0.000957  [137600/209452]\n",
      "loss: 0.005677  [140800/209452]\n",
      "loss: 0.000155  [144000/209452]\n",
      "loss: 0.000110  [147200/209452]\n",
      "loss: 0.000144  [150400/209452]\n",
      "loss: 0.000200  [153600/209452]\n",
      "loss: 0.000087  [156800/209452]\n",
      "loss: 0.000082  [160000/209452]\n",
      "loss: 0.000087  [163200/209452]\n",
      "loss: 0.000219  [166400/209452]\n",
      "loss: 0.000191  [169600/209452]\n",
      "loss: 0.000257  [172800/209452]\n",
      "loss: 0.004918  [176000/209452]\n",
      "loss: 0.000173  [179200/209452]\n",
      "loss: 0.001308  [182400/209452]\n",
      "loss: 0.000050  [185600/209452]\n",
      "loss: 0.000781  [188800/209452]\n",
      "loss: 0.000406  [192000/209452]\n",
      "loss: 0.000656  [195200/209452]\n",
      "loss: 0.000891  [198400/209452]\n",
      "loss: 0.000187  [201600/209452]\n",
      "loss: 0.000645  [204800/209452]\n",
      "loss: 0.000430  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003332 \n",
      "\n",
      "Epoch 37\n",
      "---------------------------\n",
      "loss: 0.001471  [ 3200/209452]\n",
      "loss: 0.000259  [ 6400/209452]\n",
      "loss: 0.000225  [ 9600/209452]\n",
      "loss: 0.000498  [12800/209452]\n",
      "loss: 0.001037  [16000/209452]\n",
      "loss: 0.000161  [19200/209452]\n",
      "loss: 0.000056  [22400/209452]\n",
      "loss: 0.000092  [25600/209452]\n",
      "loss: 0.000049  [28800/209452]\n",
      "loss: 0.000102  [32000/209452]\n",
      "loss: 0.000142  [35200/209452]\n",
      "loss: 0.000461  [38400/209452]\n",
      "loss: 0.000053  [41600/209452]\n",
      "loss: 0.000102  [44800/209452]\n",
      "loss: 0.000122  [48000/209452]\n",
      "loss: 0.001312  [51200/209452]\n",
      "loss: 0.000176  [54400/209452]\n",
      "loss: 0.001005  [57600/209452]\n",
      "loss: 0.000562  [60800/209452]\n",
      "loss: 0.000126  [64000/209452]\n",
      "loss: 0.000083  [67200/209452]\n",
      "loss: 0.001636  [70400/209452]\n",
      "loss: 0.000052  [73600/209452]\n",
      "loss: 0.000591  [76800/209452]\n",
      "loss: 0.000367  [80000/209452]\n",
      "loss: 0.000112  [83200/209452]\n",
      "loss: 0.000205  [86400/209452]\n",
      "loss: 0.000042  [89600/209452]\n",
      "loss: 0.002288  [92800/209452]\n",
      "loss: 0.000464  [96000/209452]\n",
      "loss: 0.000132  [99200/209452]\n",
      "loss: 0.002574  [102400/209452]\n",
      "loss: 0.000348  [105600/209452]\n",
      "loss: 0.000015  [108800/209452]\n",
      "loss: 0.000066  [112000/209452]\n",
      "loss: 0.000141  [115200/209452]\n",
      "loss: 0.000115  [118400/209452]\n",
      "loss: 0.000102  [121600/209452]\n",
      "loss: 0.002628  [124800/209452]\n",
      "loss: 0.001710  [128000/209452]\n",
      "loss: 0.000281  [131200/209452]\n",
      "loss: 0.000132  [134400/209452]\n",
      "loss: 0.000072  [137600/209452]\n",
      "loss: 0.000400  [140800/209452]\n",
      "loss: 0.000401  [144000/209452]\n",
      "loss: 0.000283  [147200/209452]\n",
      "loss: 0.003481  [150400/209452]\n",
      "loss: 0.000898  [153600/209452]\n",
      "loss: 0.000701  [156800/209452]\n",
      "loss: 0.000188  [160000/209452]\n",
      "loss: 0.000085  [163200/209452]\n",
      "loss: 0.000417  [166400/209452]\n",
      "loss: 0.001033  [169600/209452]\n",
      "loss: 0.000057  [172800/209452]\n",
      "loss: 0.000856  [176000/209452]\n",
      "loss: 0.001979  [179200/209452]\n",
      "loss: 0.002257  [182400/209452]\n",
      "loss: 0.004119  [185600/209452]\n",
      "loss: 0.000142  [188800/209452]\n",
      "loss: 0.000061  [192000/209452]\n",
      "loss: 0.000148  [195200/209452]\n",
      "loss: 0.000455  [198400/209452]\n",
      "loss: 0.000750  [201600/209452]\n",
      "loss: 0.000047  [204800/209452]\n",
      "loss: 0.000096  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003230 \n",
      "\n",
      "Epoch 38\n",
      "---------------------------\n",
      "loss: 0.001591  [ 3200/209452]\n",
      "loss: 0.003143  [ 6400/209452]\n",
      "loss: 0.002887  [ 9600/209452]\n",
      "loss: 0.000466  [12800/209452]\n",
      "loss: 0.000093  [16000/209452]\n",
      "loss: 0.000212  [19200/209452]\n",
      "loss: 0.000084  [22400/209452]\n",
      "loss: 0.000525  [25600/209452]\n",
      "loss: 0.000140  [28800/209452]\n",
      "loss: 0.000054  [32000/209452]\n",
      "loss: 0.000531  [35200/209452]\n",
      "loss: 0.000666  [38400/209452]\n",
      "loss: 0.000219  [41600/209452]\n",
      "loss: 0.003331  [44800/209452]\n",
      "loss: 0.000655  [48000/209452]\n",
      "loss: 0.002070  [51200/209452]\n",
      "loss: 0.000344  [54400/209452]\n",
      "loss: 0.000834  [57600/209452]\n",
      "loss: 0.000050  [60800/209452]\n",
      "loss: 0.001214  [64000/209452]\n",
      "loss: 0.000096  [67200/209452]\n",
      "loss: 0.000042  [70400/209452]\n",
      "loss: 0.000081  [73600/209452]\n",
      "loss: 0.000113  [76800/209452]\n",
      "loss: 0.000076  [80000/209452]\n",
      "loss: 0.000310  [83200/209452]\n",
      "loss: 0.000108  [86400/209452]\n",
      "loss: 0.000129  [89600/209452]\n",
      "loss: 0.003226  [92800/209452]\n",
      "loss: 0.000128  [96000/209452]\n",
      "loss: 0.000505  [99200/209452]\n",
      "loss: 0.002136  [102400/209452]\n",
      "loss: 0.000234  [105600/209452]\n",
      "loss: 0.000178  [108800/209452]\n",
      "loss: 0.000377  [112000/209452]\n",
      "loss: 0.000002  [115200/209452]\n",
      "loss: 0.000526  [118400/209452]\n",
      "loss: 0.001055  [121600/209452]\n",
      "loss: 0.000178  [124800/209452]\n",
      "loss: 0.006059  [128000/209452]\n",
      "loss: 0.003670  [131200/209452]\n",
      "loss: 0.000068  [134400/209452]\n",
      "loss: 0.002594  [137600/209452]\n",
      "loss: 0.000096  [140800/209452]\n",
      "loss: 0.000033  [144000/209452]\n",
      "loss: 0.000112  [147200/209452]\n",
      "loss: 0.000079  [150400/209452]\n",
      "loss: 0.000087  [153600/209452]\n",
      "loss: 0.000522  [156800/209452]\n",
      "loss: 0.005951  [160000/209452]\n",
      "loss: 0.000094  [163200/209452]\n",
      "loss: 0.000310  [166400/209452]\n",
      "loss: 0.000154  [169600/209452]\n",
      "loss: 0.002726  [172800/209452]\n",
      "loss: 0.003210  [176000/209452]\n",
      "loss: 0.002778  [179200/209452]\n",
      "loss: 0.001508  [182400/209452]\n",
      "loss: 0.000363  [185600/209452]\n",
      "loss: 0.000466  [188800/209452]\n",
      "loss: 0.002652  [192000/209452]\n",
      "loss: 0.000062  [195200/209452]\n",
      "loss: 0.000040  [198400/209452]\n",
      "loss: 0.000169  [201600/209452]\n",
      "loss: 0.000369  [204800/209452]\n",
      "loss: 0.000058  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003288 \n",
      "\n",
      "Epoch 39\n",
      "---------------------------\n",
      "loss: 0.000082  [ 3200/209452]\n",
      "loss: 0.000301  [ 6400/209452]\n",
      "loss: 0.002233  [ 9600/209452]\n",
      "loss: 0.000813  [12800/209452]\n",
      "loss: 0.000053  [16000/209452]\n",
      "loss: 0.000053  [19200/209452]\n",
      "loss: 0.000160  [22400/209452]\n",
      "loss: 0.000160  [25600/209452]\n",
      "loss: 0.000120  [28800/209452]\n",
      "loss: 0.000008  [32000/209452]\n",
      "loss: 0.000460  [35200/209452]\n",
      "loss: 0.000899  [38400/209452]\n",
      "loss: 0.000394  [41600/209452]\n",
      "loss: 0.000246  [44800/209452]\n",
      "loss: 0.001246  [48000/209452]\n",
      "loss: 0.000135  [51200/209452]\n",
      "loss: 0.000137  [54400/209452]\n",
      "loss: 0.000433  [57600/209452]\n",
      "loss: 0.000345  [60800/209452]\n",
      "loss: 0.000102  [64000/209452]\n",
      "loss: 0.001990  [67200/209452]\n",
      "loss: 0.000230  [70400/209452]\n",
      "loss: 0.016414  [73600/209452]\n",
      "loss: 0.000484  [76800/209452]\n",
      "loss: 0.000407  [80000/209452]\n",
      "loss: 0.000427  [83200/209452]\n",
      "loss: 0.000052  [86400/209452]\n",
      "loss: 0.000038  [89600/209452]\n",
      "loss: 0.000071  [92800/209452]\n",
      "loss: 0.000232  [96000/209452]\n",
      "loss: 0.001215  [99200/209452]\n",
      "loss: 0.000931  [102400/209452]\n",
      "loss: 0.001906  [105600/209452]\n",
      "loss: 0.000438  [108800/209452]\n",
      "loss: 0.000087  [112000/209452]\n",
      "loss: 0.002677  [115200/209452]\n",
      "loss: 0.000156  [118400/209452]\n",
      "loss: 0.000290  [121600/209452]\n",
      "loss: 0.001571  [124800/209452]\n",
      "loss: 0.000027  [128000/209452]\n",
      "loss: 0.005580  [131200/209452]\n",
      "loss: 0.000081  [134400/209452]\n",
      "loss: 0.000028  [137600/209452]\n",
      "loss: 0.000065  [140800/209452]\n",
      "loss: 0.008917  [144000/209452]\n",
      "loss: 0.000178  [147200/209452]\n",
      "loss: 0.000568  [150400/209452]\n",
      "loss: 0.000129  [153600/209452]\n",
      "loss: 0.000096  [156800/209452]\n",
      "loss: 0.000308  [160000/209452]\n",
      "loss: 0.000210  [163200/209452]\n",
      "loss: 0.000222  [166400/209452]\n",
      "loss: 0.000318  [169600/209452]\n",
      "loss: 0.000206  [172800/209452]\n",
      "loss: 0.000117  [176000/209452]\n",
      "loss: 0.000358  [179200/209452]\n",
      "loss: 0.001313  [182400/209452]\n",
      "loss: 0.001062  [185600/209452]\n",
      "loss: 0.000201  [188800/209452]\n",
      "loss: 0.000276  [192000/209452]\n",
      "loss: 0.003779  [195200/209452]\n",
      "loss: 0.000491  [198400/209452]\n",
      "loss: 0.004344  [201600/209452]\n",
      "loss: 0.001507  [204800/209452]\n",
      "loss: 0.000108  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003177 \n",
      "\n",
      "Epoch 40\n",
      "---------------------------\n",
      "loss: 0.003902  [ 3200/209452]\n",
      "loss: 0.000060  [ 6400/209452]\n",
      "loss: 0.000294  [ 9600/209452]\n",
      "loss: 0.000115  [12800/209452]\n",
      "loss: 0.000644  [16000/209452]\n",
      "loss: 0.000220  [19200/209452]\n",
      "loss: 0.000138  [22400/209452]\n",
      "loss: 0.001884  [25600/209452]\n",
      "loss: 0.001266  [28800/209452]\n",
      "loss: 0.000432  [32000/209452]\n",
      "loss: 0.000172  [35200/209452]\n",
      "loss: 0.000356  [38400/209452]\n",
      "loss: 0.002172  [41600/209452]\n",
      "loss: 0.000074  [44800/209452]\n",
      "loss: 0.001844  [48000/209452]\n",
      "loss: 0.001592  [51200/209452]\n",
      "loss: 0.000453  [54400/209452]\n",
      "loss: 0.000129  [57600/209452]\n",
      "loss: 0.003013  [60800/209452]\n",
      "loss: 0.000036  [64000/209452]\n",
      "loss: 0.000068  [67200/209452]\n",
      "loss: 0.000384  [70400/209452]\n",
      "loss: 0.000059  [73600/209452]\n",
      "loss: 0.000186  [76800/209452]\n",
      "loss: 0.000901  [80000/209452]\n",
      "loss: 0.001315  [83200/209452]\n",
      "loss: 0.000032  [86400/209452]\n",
      "loss: 0.000584  [89600/209452]\n",
      "loss: 0.000040  [92800/209452]\n",
      "loss: 0.000154  [96000/209452]\n",
      "loss: 0.000431  [99200/209452]\n",
      "loss: 0.000357  [102400/209452]\n",
      "loss: 0.000437  [105600/209452]\n",
      "loss: 0.000966  [108800/209452]\n",
      "loss: 0.000393  [112000/209452]\n",
      "loss: 0.000136  [115200/209452]\n",
      "loss: 0.000011  [118400/209452]\n",
      "loss: 0.000790  [121600/209452]\n",
      "loss: 0.000258  [124800/209452]\n",
      "loss: 0.000106  [128000/209452]\n",
      "loss: 0.000063  [131200/209452]\n",
      "loss: 0.000376  [134400/209452]\n",
      "loss: 0.000752  [137600/209452]\n",
      "loss: 0.000107  [140800/209452]\n",
      "loss: 0.000045  [144000/209452]\n",
      "loss: 0.000493  [147200/209452]\n",
      "loss: 0.000419  [150400/209452]\n",
      "loss: 0.000079  [153600/209452]\n",
      "loss: 0.000246  [156800/209452]\n",
      "loss: 0.000149  [160000/209452]\n",
      "loss: 0.000771  [163200/209452]\n",
      "loss: 0.000419  [166400/209452]\n",
      "loss: 0.007399  [169600/209452]\n",
      "loss: 0.000682  [172800/209452]\n",
      "loss: 0.000869  [176000/209452]\n",
      "loss: 0.002282  [179200/209452]\n",
      "loss: 0.000016  [182400/209452]\n",
      "loss: 0.000867  [185600/209452]\n",
      "loss: 0.000279  [188800/209452]\n",
      "loss: 0.001460  [192000/209452]\n",
      "loss: 0.000034  [195200/209452]\n",
      "loss: 0.000011  [198400/209452]\n",
      "loss: 0.001834  [201600/209452]\n",
      "loss: 0.000081  [204800/209452]\n",
      "loss: 0.000505  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003318 \n",
      "\n",
      "Epoch 41\n",
      "---------------------------\n",
      "loss: 0.000103  [ 3200/209452]\n",
      "loss: 0.000152  [ 6400/209452]\n",
      "loss: 0.000629  [ 9600/209452]\n",
      "loss: 0.000079  [12800/209452]\n",
      "loss: 0.002485  [16000/209452]\n",
      "loss: 0.000088  [19200/209452]\n",
      "loss: 0.000646  [22400/209452]\n",
      "loss: 0.000401  [25600/209452]\n",
      "loss: 0.001242  [28800/209452]\n",
      "loss: 0.000308  [32000/209452]\n",
      "loss: 0.000084  [35200/209452]\n",
      "loss: 0.000384  [38400/209452]\n",
      "loss: 0.000025  [41600/209452]\n",
      "loss: 0.000689  [44800/209452]\n",
      "loss: 0.000266  [48000/209452]\n",
      "loss: 0.002646  [51200/209452]\n",
      "loss: 0.000414  [54400/209452]\n",
      "loss: 0.000939  [57600/209452]\n",
      "loss: 0.000053  [60800/209452]\n",
      "loss: 0.000108  [64000/209452]\n",
      "loss: 0.000995  [67200/209452]\n",
      "loss: 0.000135  [70400/209452]\n",
      "loss: 0.000132  [73600/209452]\n",
      "loss: 0.000175  [76800/209452]\n",
      "loss: 0.000490  [80000/209452]\n",
      "loss: 0.003675  [83200/209452]\n",
      "loss: 0.000063  [86400/209452]\n",
      "loss: 0.000007  [89600/209452]\n",
      "loss: 0.000101  [92800/209452]\n",
      "loss: 0.000095  [96000/209452]\n",
      "loss: 0.000860  [99200/209452]\n",
      "loss: 0.000137  [102400/209452]\n",
      "loss: 0.000274  [105600/209452]\n",
      "loss: 0.000240  [108800/209452]\n",
      "loss: 0.000070  [112000/209452]\n",
      "loss: 0.000065  [115200/209452]\n",
      "loss: 0.000117  [118400/209452]\n",
      "loss: 0.000333  [121600/209452]\n",
      "loss: 0.000052  [124800/209452]\n",
      "loss: 0.000584  [128000/209452]\n",
      "loss: 0.000328  [131200/209452]\n",
      "loss: 0.000009  [134400/209452]\n",
      "loss: 0.000029  [137600/209452]\n",
      "loss: 0.000056  [140800/209452]\n",
      "loss: 0.000945  [144000/209452]\n",
      "loss: 0.000460  [147200/209452]\n",
      "loss: 0.000021  [150400/209452]\n",
      "loss: 0.000123  [153600/209452]\n",
      "loss: 0.000452  [156800/209452]\n",
      "loss: 0.000023  [160000/209452]\n",
      "loss: 0.000083  [163200/209452]\n",
      "loss: 0.000050  [166400/209452]\n",
      "loss: 0.000151  [169600/209452]\n",
      "loss: 0.000045  [172800/209452]\n",
      "loss: 0.000163  [176000/209452]\n",
      "loss: 0.000443  [179200/209452]\n",
      "loss: 0.000078  [182400/209452]\n",
      "loss: 0.000162  [185600/209452]\n",
      "loss: 0.000512  [188800/209452]\n",
      "loss: 0.000674  [192000/209452]\n",
      "loss: 0.000068  [195200/209452]\n",
      "loss: 0.000729  [198400/209452]\n",
      "loss: 0.000649  [201600/209452]\n",
      "loss: 0.000158  [204800/209452]\n",
      "loss: 0.011032  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003412 \n",
      "\n",
      "Epoch 42\n",
      "---------------------------\n",
      "loss: 0.000094  [ 3200/209452]\n",
      "loss: 0.000474  [ 6400/209452]\n",
      "loss: 0.000151  [ 9600/209452]\n",
      "loss: 0.000099  [12800/209452]\n",
      "loss: 0.000185  [16000/209452]\n",
      "loss: 0.000542  [19200/209452]\n",
      "loss: 0.000193  [22400/209452]\n",
      "loss: 0.000253  [25600/209452]\n",
      "loss: 0.000149  [28800/209452]\n",
      "loss: 0.001669  [32000/209452]\n",
      "loss: 0.000166  [35200/209452]\n",
      "loss: 0.000440  [38400/209452]\n",
      "loss: 0.000058  [41600/209452]\n",
      "loss: 0.000276  [44800/209452]\n",
      "loss: 0.000040  [48000/209452]\n",
      "loss: 0.000188  [51200/209452]\n",
      "loss: 0.000020  [54400/209452]\n",
      "loss: 0.000528  [57600/209452]\n",
      "loss: 0.000130  [60800/209452]\n",
      "loss: 0.000220  [64000/209452]\n",
      "loss: 0.001497  [67200/209452]\n",
      "loss: 0.000206  [70400/209452]\n",
      "loss: 0.000237  [73600/209452]\n",
      "loss: 0.000047  [76800/209452]\n",
      "loss: 0.000447  [80000/209452]\n",
      "loss: 0.000302  [83200/209452]\n",
      "loss: 0.000238  [86400/209452]\n",
      "loss: 0.013978  [89600/209452]\n",
      "loss: 0.000245  [92800/209452]\n",
      "loss: 0.001672  [96000/209452]\n",
      "loss: 0.000214  [99200/209452]\n",
      "loss: 0.000065  [102400/209452]\n",
      "loss: 0.002385  [105600/209452]\n",
      "loss: 0.000968  [108800/209452]\n",
      "loss: 0.000253  [112000/209452]\n",
      "loss: 0.000028  [115200/209452]\n",
      "loss: 0.000170  [118400/209452]\n",
      "loss: 0.000048  [121600/209452]\n",
      "loss: 0.000049  [124800/209452]\n",
      "loss: 0.000214  [128000/209452]\n",
      "loss: 0.000972  [131200/209452]\n",
      "loss: 0.000306  [134400/209452]\n",
      "loss: 0.000077  [137600/209452]\n",
      "loss: 0.000159  [140800/209452]\n",
      "loss: 0.000862  [144000/209452]\n",
      "loss: 0.000147  [147200/209452]\n",
      "loss: 0.000238  [150400/209452]\n",
      "loss: 0.000866  [153600/209452]\n",
      "loss: 0.000274  [156800/209452]\n",
      "loss: 0.000524  [160000/209452]\n",
      "loss: 0.000158  [163200/209452]\n",
      "loss: 0.000105  [166400/209452]\n",
      "loss: 0.000312  [169600/209452]\n",
      "loss: 0.000149  [172800/209452]\n",
      "loss: 0.000465  [176000/209452]\n",
      "loss: 0.000366  [179200/209452]\n",
      "loss: 0.000008  [182400/209452]\n",
      "loss: 0.000095  [185600/209452]\n",
      "loss: 0.000060  [188800/209452]\n",
      "loss: 0.000309  [192000/209452]\n",
      "loss: 0.000047  [195200/209452]\n",
      "loss: 0.000111  [198400/209452]\n",
      "loss: 0.000004  [201600/209452]\n",
      "loss: 0.005624  [204800/209452]\n",
      "loss: 0.000592  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003123 \n",
      "\n",
      "Epoch 43\n",
      "---------------------------\n",
      "loss: 0.000248  [ 3200/209452]\n",
      "loss: 0.001156  [ 6400/209452]\n",
      "loss: 0.000083  [ 9600/209452]\n",
      "loss: 0.000472  [12800/209452]\n",
      "loss: 0.000819  [16000/209452]\n",
      "loss: 0.000270  [19200/209452]\n",
      "loss: 0.005376  [22400/209452]\n",
      "loss: 0.000101  [25600/209452]\n",
      "loss: 0.000057  [28800/209452]\n",
      "loss: 0.001635  [32000/209452]\n",
      "loss: 0.000387  [35200/209452]\n",
      "loss: 0.000075  [38400/209452]\n",
      "loss: 0.000953  [41600/209452]\n",
      "loss: 0.001883  [44800/209452]\n",
      "loss: 0.000011  [48000/209452]\n",
      "loss: 0.000400  [51200/209452]\n",
      "loss: 0.000439  [54400/209452]\n",
      "loss: 0.000155  [57600/209452]\n",
      "loss: 0.000021  [60800/209452]\n",
      "loss: 0.000196  [64000/209452]\n",
      "loss: 0.000013  [67200/209452]\n",
      "loss: 0.000383  [70400/209452]\n",
      "loss: 0.000145  [73600/209452]\n",
      "loss: 0.000333  [76800/209452]\n",
      "loss: 0.000331  [80000/209452]\n",
      "loss: 0.000137  [83200/209452]\n",
      "loss: 0.000216  [86400/209452]\n",
      "loss: 0.000076  [89600/209452]\n",
      "loss: 0.000055  [92800/209452]\n",
      "loss: 0.000111  [96000/209452]\n",
      "loss: 0.000126  [99200/209452]\n",
      "loss: 0.000015  [102400/209452]\n",
      "loss: 0.000292  [105600/209452]\n",
      "loss: 0.000205  [108800/209452]\n",
      "loss: 0.001384  [112000/209452]\n",
      "loss: 0.000086  [115200/209452]\n",
      "loss: 0.000208  [118400/209452]\n",
      "loss: 0.000168  [121600/209452]\n",
      "loss: 0.000079  [124800/209452]\n",
      "loss: 0.000261  [128000/209452]\n",
      "loss: 0.000095  [131200/209452]\n",
      "loss: 0.000066  [134400/209452]\n",
      "loss: 0.000157  [137600/209452]\n",
      "loss: 0.000052  [140800/209452]\n",
      "loss: 0.000128  [144000/209452]\n",
      "loss: 0.000152  [147200/209452]\n",
      "loss: 0.000057  [150400/209452]\n",
      "loss: 0.000254  [153600/209452]\n",
      "loss: 0.000661  [156800/209452]\n",
      "loss: 0.000258  [160000/209452]\n",
      "loss: 0.000760  [163200/209452]\n",
      "loss: 0.000904  [166400/209452]\n",
      "loss: 0.000012  [169600/209452]\n",
      "loss: 0.000286  [172800/209452]\n",
      "loss: 0.000357  [176000/209452]\n",
      "loss: 0.001171  [179200/209452]\n",
      "loss: 0.000152  [182400/209452]\n",
      "loss: 0.000090  [185600/209452]\n",
      "loss: 0.000176  [188800/209452]\n",
      "loss: 0.000072  [192000/209452]\n",
      "loss: 0.000170  [195200/209452]\n",
      "loss: 0.000876  [198400/209452]\n",
      "loss: 0.000036  [201600/209452]\n",
      "loss: 0.000634  [204800/209452]\n",
      "loss: 0.000258  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003060 \n",
      "\n",
      "Epoch 44\n",
      "---------------------------\n",
      "loss: 0.000417  [ 3200/209452]\n",
      "loss: 0.000037  [ 6400/209452]\n",
      "loss: 0.000446  [ 9600/209452]\n",
      "loss: 0.003349  [12800/209452]\n",
      "loss: 0.000725  [16000/209452]\n",
      "loss: 0.000949  [19200/209452]\n",
      "loss: 0.000110  [22400/209452]\n",
      "loss: 0.000140  [25600/209452]\n",
      "loss: 0.000114  [28800/209452]\n",
      "loss: 0.000094  [32000/209452]\n",
      "loss: 0.000479  [35200/209452]\n",
      "loss: 0.000359  [38400/209452]\n",
      "loss: 0.000208  [41600/209452]\n",
      "loss: 0.000183  [44800/209452]\n",
      "loss: 0.000232  [48000/209452]\n",
      "loss: 0.000295  [51200/209452]\n",
      "loss: 0.000056  [54400/209452]\n",
      "loss: 0.000013  [57600/209452]\n",
      "loss: 0.000753  [60800/209452]\n",
      "loss: 0.000157  [64000/209452]\n",
      "loss: 0.000020  [67200/209452]\n",
      "loss: 0.000033  [70400/209452]\n",
      "loss: 0.001068  [73600/209452]\n",
      "loss: 0.000140  [76800/209452]\n",
      "loss: 0.000721  [80000/209452]\n",
      "loss: 0.000108  [83200/209452]\n",
      "loss: 0.001331  [86400/209452]\n",
      "loss: 0.000563  [89600/209452]\n",
      "loss: 0.000008  [92800/209452]\n",
      "loss: 0.000310  [96000/209452]\n",
      "loss: 0.000912  [99200/209452]\n",
      "loss: 0.000042  [102400/209452]\n",
      "loss: 0.000112  [105600/209452]\n",
      "loss: 0.000072  [108800/209452]\n",
      "loss: 0.000150  [112000/209452]\n",
      "loss: 0.000161  [115200/209452]\n",
      "loss: 0.000226  [118400/209452]\n",
      "loss: 0.000049  [121600/209452]\n",
      "loss: 0.000104  [124800/209452]\n",
      "loss: 0.000028  [128000/209452]\n",
      "loss: 0.000070  [131200/209452]\n",
      "loss: 0.000052  [134400/209452]\n",
      "loss: 0.000303  [137600/209452]\n",
      "loss: 0.000666  [140800/209452]\n",
      "loss: 0.000048  [144000/209452]\n",
      "loss: 0.000042  [147200/209452]\n",
      "loss: 0.000468  [150400/209452]\n",
      "loss: 0.000065  [153600/209452]\n",
      "loss: 0.002874  [156800/209452]\n",
      "loss: 0.000100  [160000/209452]\n",
      "loss: 0.001550  [163200/209452]\n",
      "loss: 0.000070  [166400/209452]\n",
      "loss: 0.000109  [169600/209452]\n",
      "loss: 0.006743  [172800/209452]\n",
      "loss: 0.002326  [176000/209452]\n",
      "loss: 0.000310  [179200/209452]\n",
      "loss: 0.000083  [182400/209452]\n",
      "loss: 0.002573  [185600/209452]\n",
      "loss: 0.000186  [188800/209452]\n",
      "loss: 0.000694  [192000/209452]\n",
      "loss: 0.000240  [195200/209452]\n",
      "loss: 0.000884  [198400/209452]\n",
      "loss: 0.000283  [201600/209452]\n",
      "loss: 0.000186  [204800/209452]\n",
      "loss: 0.000351  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 45\n",
      "---------------------------\n",
      "loss: 0.000076  [ 3200/209452]\n",
      "loss: 0.000728  [ 6400/209452]\n",
      "loss: 0.000103  [ 9600/209452]\n",
      "loss: 0.000856  [12800/209452]\n",
      "loss: 0.000475  [16000/209452]\n",
      "loss: 0.000074  [19200/209452]\n",
      "loss: 0.000277  [22400/209452]\n",
      "loss: 0.000584  [25600/209452]\n",
      "loss: 0.001606  [28800/209452]\n",
      "loss: 0.000666  [32000/209452]\n",
      "loss: 0.000077  [35200/209452]\n",
      "loss: 0.000281  [38400/209452]\n",
      "loss: 0.000970  [41600/209452]\n",
      "loss: 0.000227  [44800/209452]\n",
      "loss: 0.000063  [48000/209452]\n",
      "loss: 0.013169  [51200/209452]\n",
      "loss: 0.000027  [54400/209452]\n",
      "loss: 0.000054  [57600/209452]\n",
      "loss: 0.000467  [60800/209452]\n",
      "loss: 0.001955  [64000/209452]\n",
      "loss: 0.000461  [67200/209452]\n",
      "loss: 0.000074  [70400/209452]\n",
      "loss: 0.000056  [73600/209452]\n",
      "loss: 0.000109  [76800/209452]\n",
      "loss: 0.000109  [80000/209452]\n",
      "loss: 0.000103  [83200/209452]\n",
      "loss: 0.001393  [86400/209452]\n",
      "loss: 0.024731  [89600/209452]\n",
      "loss: 0.000359  [92800/209452]\n",
      "loss: 0.000131  [96000/209452]\n",
      "loss: 0.000239  [99200/209452]\n",
      "loss: 0.000003  [102400/209452]\n",
      "loss: 0.000188  [105600/209452]\n",
      "loss: 0.000127  [108800/209452]\n",
      "loss: 0.000094  [112000/209452]\n",
      "loss: 0.000057  [115200/209452]\n",
      "loss: 0.000024  [118400/209452]\n",
      "loss: 0.000223  [121600/209452]\n",
      "loss: 0.000429  [124800/209452]\n",
      "loss: 0.000856  [128000/209452]\n",
      "loss: 0.000045  [131200/209452]\n",
      "loss: 0.000121  [134400/209452]\n",
      "loss: 0.000027  [137600/209452]\n",
      "loss: 0.000013  [140800/209452]\n",
      "loss: 0.000098  [144000/209452]\n",
      "loss: 0.000153  [147200/209452]\n",
      "loss: 0.000052  [150400/209452]\n",
      "loss: 0.001782  [153600/209452]\n",
      "loss: 0.000057  [156800/209452]\n",
      "loss: 0.000220  [160000/209452]\n",
      "loss: 0.000087  [163200/209452]\n",
      "loss: 0.000101  [166400/209452]\n",
      "loss: 0.000335  [169600/209452]\n",
      "loss: 0.000060  [172800/209452]\n",
      "loss: 0.000052  [176000/209452]\n",
      "loss: 0.000228  [179200/209452]\n",
      "loss: 0.000034  [182400/209452]\n",
      "loss: 0.000296  [185600/209452]\n",
      "loss: 0.002498  [188800/209452]\n",
      "loss: 0.005471  [192000/209452]\n",
      "loss: 0.000117  [195200/209452]\n",
      "loss: 0.000260  [198400/209452]\n",
      "loss: 0.001035  [201600/209452]\n",
      "loss: 0.000227  [204800/209452]\n",
      "loss: 0.000307  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003042 \n",
      "\n",
      "Epoch 46\n",
      "---------------------------\n",
      "loss: 0.002046  [ 3200/209452]\n",
      "loss: 0.000242  [ 6400/209452]\n",
      "loss: 0.000077  [ 9600/209452]\n",
      "loss: 0.000500  [12800/209452]\n",
      "loss: 0.000610  [16000/209452]\n",
      "loss: 0.000141  [19200/209452]\n",
      "loss: 0.000119  [22400/209452]\n",
      "loss: 0.000065  [25600/209452]\n",
      "loss: 0.000613  [28800/209452]\n",
      "loss: 0.000819  [32000/209452]\n",
      "loss: 0.000069  [35200/209452]\n",
      "loss: 0.001756  [38400/209452]\n",
      "loss: 0.000352  [41600/209452]\n",
      "loss: 0.000128  [44800/209452]\n",
      "loss: 0.000012  [48000/209452]\n",
      "loss: 0.002819  [51200/209452]\n",
      "loss: 0.000741  [54400/209452]\n",
      "loss: 0.000369  [57600/209452]\n",
      "loss: 0.000226  [60800/209452]\n",
      "loss: 0.001869  [64000/209452]\n",
      "loss: 0.000116  [67200/209452]\n",
      "loss: 0.000176  [70400/209452]\n",
      "loss: 0.000708  [73600/209452]\n",
      "loss: 0.000135  [76800/209452]\n",
      "loss: 0.000115  [80000/209452]\n",
      "loss: 0.000317  [83200/209452]\n",
      "loss: 0.000172  [86400/209452]\n",
      "loss: 0.000896  [89600/209452]\n",
      "loss: 0.002530  [92800/209452]\n",
      "loss: 0.000075  [96000/209452]\n",
      "loss: 0.000030  [99200/209452]\n",
      "loss: 0.000182  [102400/209452]\n",
      "loss: 0.000224  [105600/209452]\n",
      "loss: 0.000143  [108800/209452]\n",
      "loss: 0.000038  [112000/209452]\n",
      "loss: 0.000083  [115200/209452]\n",
      "loss: 0.000572  [118400/209452]\n",
      "loss: 0.006939  [121600/209452]\n",
      "loss: 0.000060  [124800/209452]\n",
      "loss: 0.001019  [128000/209452]\n",
      "loss: 0.000077  [131200/209452]\n",
      "loss: 0.000091  [134400/209452]\n",
      "loss: 0.000096  [137600/209452]\n",
      "loss: 0.000120  [140800/209452]\n",
      "loss: 0.000076  [144000/209452]\n",
      "loss: 0.000407  [147200/209452]\n",
      "loss: 0.000095  [150400/209452]\n",
      "loss: 0.000231  [153600/209452]\n",
      "loss: 0.000372  [156800/209452]\n",
      "loss: 0.000265  [160000/209452]\n",
      "loss: 0.000723  [163200/209452]\n",
      "loss: 0.007864  [166400/209452]\n",
      "loss: 0.000099  [169600/209452]\n",
      "loss: 0.001039  [172800/209452]\n",
      "loss: 0.000087  [176000/209452]\n",
      "loss: 0.000030  [179200/209452]\n",
      "loss: 0.000139  [182400/209452]\n",
      "loss: 0.000008  [185600/209452]\n",
      "loss: 0.000140  [188800/209452]\n",
      "loss: 0.000258  [192000/209452]\n",
      "loss: 0.000188  [195200/209452]\n",
      "loss: 0.000255  [198400/209452]\n",
      "loss: 0.000114  [201600/209452]\n",
      "loss: 0.000030  [204800/209452]\n",
      "loss: 0.000147  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003046 \n",
      "\n",
      "Epoch 47\n",
      "---------------------------\n",
      "loss: 0.000244  [ 3200/209452]\n",
      "loss: 0.000043  [ 6400/209452]\n",
      "loss: 0.000075  [ 9600/209452]\n",
      "loss: 0.000223  [12800/209452]\n",
      "loss: 0.000096  [16000/209452]\n",
      "loss: 0.000089  [19200/209452]\n",
      "loss: 0.000124  [22400/209452]\n",
      "loss: 0.000192  [25600/209452]\n",
      "loss: 0.000031  [28800/209452]\n",
      "loss: 0.000288  [32000/209452]\n",
      "loss: 0.000172  [35200/209452]\n",
      "loss: 0.000278  [38400/209452]\n",
      "loss: 0.001001  [41600/209452]\n",
      "loss: 0.002684  [44800/209452]\n",
      "loss: 0.000137  [48000/209452]\n",
      "loss: 0.000049  [51200/209452]\n",
      "loss: 0.000024  [54400/209452]\n",
      "loss: 0.000112  [57600/209452]\n",
      "loss: 0.000026  [60800/209452]\n",
      "loss: 0.000073  [64000/209452]\n",
      "loss: 0.000421  [67200/209452]\n",
      "loss: 0.000228  [70400/209452]\n",
      "loss: 0.000233  [73600/209452]\n",
      "loss: 0.000389  [76800/209452]\n",
      "loss: 0.000256  [80000/209452]\n",
      "loss: 0.001286  [83200/209452]\n",
      "loss: 0.000115  [86400/209452]\n",
      "loss: 0.000340  [89600/209452]\n",
      "loss: 0.000135  [92800/209452]\n",
      "loss: 0.000041  [96000/209452]\n",
      "loss: 0.000678  [99200/209452]\n",
      "loss: 0.000116  [102400/209452]\n",
      "loss: 0.000157  [105600/209452]\n",
      "loss: 0.000273  [108800/209452]\n",
      "loss: 0.000031  [112000/209452]\n",
      "loss: 0.000031  [115200/209452]\n",
      "loss: 0.000899  [118400/209452]\n",
      "loss: 0.000356  [121600/209452]\n",
      "loss: 0.003064  [124800/209452]\n",
      "loss: 0.000775  [128000/209452]\n",
      "loss: 0.001324  [131200/209452]\n",
      "loss: 0.001207  [134400/209452]\n",
      "loss: 0.000184  [137600/209452]\n",
      "loss: 0.000072  [140800/209452]\n",
      "loss: 0.000027  [144000/209452]\n",
      "loss: 0.000014  [147200/209452]\n",
      "loss: 0.000076  [150400/209452]\n",
      "loss: 0.000253  [153600/209452]\n",
      "loss: 0.000117  [156800/209452]\n",
      "loss: 0.000464  [160000/209452]\n",
      "loss: 0.000151  [163200/209452]\n",
      "loss: 0.000066  [166400/209452]\n",
      "loss: 0.000089  [169600/209452]\n",
      "loss: 0.000890  [172800/209452]\n",
      "loss: 0.000139  [176000/209452]\n",
      "loss: 0.000263  [179200/209452]\n",
      "loss: 0.000135  [182400/209452]\n",
      "loss: 0.000076  [185600/209452]\n",
      "loss: 0.000148  [188800/209452]\n",
      "loss: 0.000129  [192000/209452]\n",
      "loss: 0.007428  [195200/209452]\n",
      "loss: 0.000049  [198400/209452]\n",
      "loss: 0.000294  [201600/209452]\n",
      "loss: 0.000528  [204800/209452]\n",
      "loss: 0.000173  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002928 \n",
      "\n",
      "Epoch 48\n",
      "---------------------------\n",
      "loss: 0.000109  [ 3200/209452]\n",
      "loss: 0.001286  [ 6400/209452]\n",
      "loss: 0.000190  [ 9600/209452]\n",
      "loss: 0.000078  [12800/209452]\n",
      "loss: 0.000371  [16000/209452]\n",
      "loss: 0.001739  [19200/209452]\n",
      "loss: 0.000178  [22400/209452]\n",
      "loss: 0.003139  [25600/209452]\n",
      "loss: 0.000139  [28800/209452]\n",
      "loss: 0.000059  [32000/209452]\n",
      "loss: 0.000671  [35200/209452]\n",
      "loss: 0.001038  [38400/209452]\n",
      "loss: 0.000022  [41600/209452]\n",
      "loss: 0.001046  [44800/209452]\n",
      "loss: 0.001487  [48000/209452]\n",
      "loss: 0.000031  [51200/209452]\n",
      "loss: 0.000065  [54400/209452]\n",
      "loss: 0.000073  [57600/209452]\n",
      "loss: 0.000989  [60800/209452]\n",
      "loss: 0.000214  [64000/209452]\n",
      "loss: 0.000099  [67200/209452]\n",
      "loss: 0.000602  [70400/209452]\n",
      "loss: 0.000225  [73600/209452]\n",
      "loss: 0.000064  [76800/209452]\n",
      "loss: 0.000396  [80000/209452]\n",
      "loss: 0.000403  [83200/209452]\n",
      "loss: 0.001783  [86400/209452]\n",
      "loss: 0.000218  [89600/209452]\n",
      "loss: 0.000463  [92800/209452]\n",
      "loss: 0.001163  [96000/209452]\n",
      "loss: 0.000045  [99200/209452]\n",
      "loss: 0.000008  [102400/209452]\n",
      "loss: 0.000185  [105600/209452]\n",
      "loss: 0.000039  [108800/209452]\n",
      "loss: 0.000032  [112000/209452]\n",
      "loss: 0.001480  [115200/209452]\n",
      "loss: 0.000374  [118400/209452]\n",
      "loss: 0.000887  [121600/209452]\n",
      "loss: 0.000210  [124800/209452]\n",
      "loss: 0.000263  [128000/209452]\n",
      "loss: 0.000099  [131200/209452]\n",
      "loss: 0.000154  [134400/209452]\n",
      "loss: 0.000947  [137600/209452]\n",
      "loss: 0.000131  [140800/209452]\n",
      "loss: 0.000203  [144000/209452]\n",
      "loss: 0.000107  [147200/209452]\n",
      "loss: 0.001094  [150400/209452]\n",
      "loss: 0.000107  [153600/209452]\n",
      "loss: 0.000316  [156800/209452]\n",
      "loss: 0.000081  [160000/209452]\n",
      "loss: 0.000592  [163200/209452]\n",
      "loss: 0.000057  [166400/209452]\n",
      "loss: 0.000192  [169600/209452]\n",
      "loss: 0.000051  [172800/209452]\n",
      "loss: 0.000131  [176000/209452]\n",
      "loss: 0.001523  [179200/209452]\n",
      "loss: 0.000136  [182400/209452]\n",
      "loss: 0.000064  [185600/209452]\n",
      "loss: 0.000209  [188800/209452]\n",
      "loss: 0.000203  [192000/209452]\n",
      "loss: 0.000436  [195200/209452]\n",
      "loss: 0.000085  [198400/209452]\n",
      "loss: 0.000090  [201600/209452]\n",
      "loss: 0.000001  [204800/209452]\n",
      "loss: 0.000092  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003120 \n",
      "\n",
      "Epoch 49\n",
      "---------------------------\n",
      "loss: 0.000070  [ 3200/209452]\n",
      "loss: 0.002960  [ 6400/209452]\n",
      "loss: 0.000331  [ 9600/209452]\n",
      "loss: 0.000117  [12800/209452]\n",
      "loss: 0.000127  [16000/209452]\n",
      "loss: 0.000567  [19200/209452]\n",
      "loss: 0.000149  [22400/209452]\n",
      "loss: 0.000819  [25600/209452]\n",
      "loss: 0.000026  [28800/209452]\n",
      "loss: 0.000057  [32000/209452]\n",
      "loss: 0.000028  [35200/209452]\n",
      "loss: 0.000218  [38400/209452]\n",
      "loss: 0.000065  [41600/209452]\n",
      "loss: 0.000101  [44800/209452]\n",
      "loss: 0.000644  [48000/209452]\n",
      "loss: 0.000451  [51200/209452]\n",
      "loss: 0.005058  [54400/209452]\n",
      "loss: 0.000964  [57600/209452]\n",
      "loss: 0.000180  [60800/209452]\n",
      "loss: 0.000745  [64000/209452]\n",
      "loss: 0.000147  [67200/209452]\n",
      "loss: 0.000037  [70400/209452]\n",
      "loss: 0.000320  [73600/209452]\n",
      "loss: 0.009406  [76800/209452]\n",
      "loss: 0.000087  [80000/209452]\n",
      "loss: 0.000088  [83200/209452]\n",
      "loss: 0.005958  [86400/209452]\n",
      "loss: 0.000251  [89600/209452]\n",
      "loss: 0.000077  [92800/209452]\n",
      "loss: 0.000042  [96000/209452]\n",
      "loss: 0.000346  [99200/209452]\n",
      "loss: 0.000065  [102400/209452]\n",
      "loss: 0.000317  [105600/209452]\n",
      "loss: 0.000109  [108800/209452]\n",
      "loss: 0.000130  [112000/209452]\n",
      "loss: 0.000274  [115200/209452]\n",
      "loss: 0.000018  [118400/209452]\n",
      "loss: 0.000188  [121600/209452]\n",
      "loss: 0.001873  [124800/209452]\n",
      "loss: 0.005339  [128000/209452]\n",
      "loss: 0.000216  [131200/209452]\n",
      "loss: 0.000321  [134400/209452]\n",
      "loss: 0.000129  [137600/209452]\n",
      "loss: 0.000187  [140800/209452]\n",
      "loss: 0.000277  [144000/209452]\n",
      "loss: 0.001460  [147200/209452]\n",
      "loss: 0.001574  [150400/209452]\n",
      "loss: 0.000440  [153600/209452]\n",
      "loss: 0.000098  [156800/209452]\n",
      "loss: 0.000179  [160000/209452]\n",
      "loss: 0.000074  [163200/209452]\n",
      "loss: 0.000625  [166400/209452]\n",
      "loss: 0.002619  [169600/209452]\n",
      "loss: 0.000144  [172800/209452]\n",
      "loss: 0.000200  [176000/209452]\n",
      "loss: 0.000139  [179200/209452]\n",
      "loss: 0.000113  [182400/209452]\n",
      "loss: 0.005277  [185600/209452]\n",
      "loss: 0.000043  [188800/209452]\n",
      "loss: 0.000839  [192000/209452]\n",
      "loss: 0.000124  [195200/209452]\n",
      "loss: 0.000038  [198400/209452]\n",
      "loss: 0.000026  [201600/209452]\n",
      "loss: 0.000388  [204800/209452]\n",
      "loss: 0.000032  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002924 \n",
      "\n",
      "Epoch 50\n",
      "---------------------------\n",
      "loss: 0.000076  [ 3200/209452]\n",
      "loss: 0.000043  [ 6400/209452]\n",
      "loss: 0.000041  [ 9600/209452]\n",
      "loss: 0.000025  [12800/209452]\n",
      "loss: 0.000610  [16000/209452]\n",
      "loss: 0.000065  [19200/209452]\n",
      "loss: 0.000215  [22400/209452]\n",
      "loss: 0.001043  [25600/209452]\n",
      "loss: 0.000091  [28800/209452]\n",
      "loss: 0.000603  [32000/209452]\n",
      "loss: 0.000158  [35200/209452]\n",
      "loss: 0.000661  [38400/209452]\n",
      "loss: 0.000016  [41600/209452]\n",
      "loss: 0.000811  [44800/209452]\n",
      "loss: 0.000836  [48000/209452]\n",
      "loss: 0.000053  [51200/209452]\n",
      "loss: 0.000704  [54400/209452]\n",
      "loss: 0.000047  [57600/209452]\n",
      "loss: 0.000048  [60800/209452]\n",
      "loss: 0.000155  [64000/209452]\n",
      "loss: 0.000075  [67200/209452]\n",
      "loss: 0.000098  [70400/209452]\n",
      "loss: 0.002698  [73600/209452]\n",
      "loss: 0.001392  [76800/209452]\n",
      "loss: 0.000180  [80000/209452]\n",
      "loss: 0.000585  [83200/209452]\n",
      "loss: 0.000596  [86400/209452]\n",
      "loss: 0.001300  [89600/209452]\n",
      "loss: 0.000217  [92800/209452]\n",
      "loss: 0.000235  [96000/209452]\n",
      "loss: 0.000230  [99200/209452]\n",
      "loss: 0.000151  [102400/209452]\n",
      "loss: 0.000046  [105600/209452]\n",
      "loss: 0.001453  [108800/209452]\n",
      "loss: 0.000057  [112000/209452]\n",
      "loss: 0.000322  [115200/209452]\n",
      "loss: 0.000273  [118400/209452]\n",
      "loss: 0.000086  [121600/209452]\n",
      "loss: 0.002438  [124800/209452]\n",
      "loss: 0.000117  [128000/209452]\n",
      "loss: 0.001335  [131200/209452]\n",
      "loss: 0.002749  [134400/209452]\n",
      "loss: 0.000332  [137600/209452]\n",
      "loss: 0.001797  [140800/209452]\n",
      "loss: 0.000447  [144000/209452]\n",
      "loss: 0.000097  [147200/209452]\n",
      "loss: 0.016127  [150400/209452]\n",
      "loss: 0.000107  [153600/209452]\n",
      "loss: 0.002493  [156800/209452]\n",
      "loss: 0.000097  [160000/209452]\n",
      "loss: 0.000784  [163200/209452]\n",
      "loss: 0.002196  [166400/209452]\n",
      "loss: 0.000066  [169600/209452]\n",
      "loss: 0.000174  [172800/209452]\n",
      "loss: 0.000026  [176000/209452]\n",
      "loss: 0.000083  [179200/209452]\n",
      "loss: 0.000155  [182400/209452]\n",
      "loss: 0.000116  [185600/209452]\n",
      "loss: 0.000076  [188800/209452]\n",
      "loss: 0.001075  [192000/209452]\n",
      "loss: 0.000023  [195200/209452]\n",
      "loss: 0.000196  [198400/209452]\n",
      "loss: 0.000122  [201600/209452]\n",
      "loss: 0.003535  [204800/209452]\n",
      "loss: 0.000229  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 51\n",
      "---------------------------\n",
      "loss: 0.000054  [ 3200/209452]\n",
      "loss: 0.000032  [ 6400/209452]\n",
      "loss: 0.000087  [ 9600/209452]\n",
      "loss: 0.002271  [12800/209452]\n",
      "loss: 0.000367  [16000/209452]\n",
      "loss: 0.000009  [19200/209452]\n",
      "loss: 0.000163  [22400/209452]\n",
      "loss: 0.000493  [25600/209452]\n",
      "loss: 0.003328  [28800/209452]\n",
      "loss: 0.001014  [32000/209452]\n",
      "loss: 0.000077  [35200/209452]\n",
      "loss: 0.000336  [38400/209452]\n",
      "loss: 0.000124  [41600/209452]\n",
      "loss: 0.004391  [44800/209452]\n",
      "loss: 0.000093  [48000/209452]\n",
      "loss: 0.000096  [51200/209452]\n",
      "loss: 0.000367  [54400/209452]\n",
      "loss: 0.000101  [57600/209452]\n",
      "loss: 0.000017  [60800/209452]\n",
      "loss: 0.000240  [64000/209452]\n",
      "loss: 0.000380  [67200/209452]\n",
      "loss: 0.005577  [70400/209452]\n",
      "loss: 0.000020  [73600/209452]\n",
      "loss: 0.000252  [76800/209452]\n",
      "loss: 0.000235  [80000/209452]\n",
      "loss: 0.000068  [83200/209452]\n",
      "loss: 0.000085  [86400/209452]\n",
      "loss: 0.000483  [89600/209452]\n",
      "loss: 0.000031  [92800/209452]\n",
      "loss: 0.000194  [96000/209452]\n",
      "loss: 0.000057  [99200/209452]\n",
      "loss: 0.000080  [102400/209452]\n",
      "loss: 0.004433  [105600/209452]\n",
      "loss: 0.000103  [108800/209452]\n",
      "loss: 0.000109  [112000/209452]\n",
      "loss: 0.009297  [115200/209452]\n",
      "loss: 0.000171  [118400/209452]\n",
      "loss: 0.000050  [121600/209452]\n",
      "loss: 0.000182  [124800/209452]\n",
      "loss: 0.000144  [128000/209452]\n",
      "loss: 0.000102  [131200/209452]\n",
      "loss: 0.000300  [134400/209452]\n",
      "loss: 0.000323  [137600/209452]\n",
      "loss: 0.136125  [140800/209452]\n",
      "loss: 0.000043  [144000/209452]\n",
      "loss: 0.000028  [147200/209452]\n",
      "loss: 0.000423  [150400/209452]\n",
      "loss: 0.001775  [153600/209452]\n",
      "loss: 0.000518  [156800/209452]\n",
      "loss: 0.000737  [160000/209452]\n",
      "loss: 0.000149  [163200/209452]\n",
      "loss: 0.000266  [166400/209452]\n",
      "loss: 0.000134  [169600/209452]\n",
      "loss: 0.000051  [172800/209452]\n",
      "loss: 0.000368  [176000/209452]\n",
      "loss: 0.000133  [179200/209452]\n",
      "loss: 0.000239  [182400/209452]\n",
      "loss: 0.000028  [185600/209452]\n",
      "loss: 0.001427  [188800/209452]\n",
      "loss: 0.000102  [192000/209452]\n",
      "loss: 0.000057  [195200/209452]\n",
      "loss: 0.000047  [198400/209452]\n",
      "loss: 0.000395  [201600/209452]\n",
      "loss: 0.000667  [204800/209452]\n",
      "loss: 0.000107  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003081 \n",
      "\n",
      "Epoch 52\n",
      "---------------------------\n",
      "loss: 0.000159  [ 3200/209452]\n",
      "loss: 0.004073  [ 6400/209452]\n",
      "loss: 0.000264  [ 9600/209452]\n",
      "loss: 0.000219  [12800/209452]\n",
      "loss: 0.000061  [16000/209452]\n",
      "loss: 0.000192  [19200/209452]\n",
      "loss: 0.005079  [22400/209452]\n",
      "loss: 0.000092  [25600/209452]\n",
      "loss: 0.000122  [28800/209452]\n",
      "loss: 0.000921  [32000/209452]\n",
      "loss: 0.000051  [35200/209452]\n",
      "loss: 0.000171  [38400/209452]\n",
      "loss: 0.000006  [41600/209452]\n",
      "loss: 0.000407  [44800/209452]\n",
      "loss: 0.002429  [48000/209452]\n",
      "loss: 0.000904  [51200/209452]\n",
      "loss: 0.000189  [54400/209452]\n",
      "loss: 0.001771  [57600/209452]\n",
      "loss: 0.000235  [60800/209452]\n",
      "loss: 0.001123  [64000/209452]\n",
      "loss: 0.000219  [67200/209452]\n",
      "loss: 0.000446  [70400/209452]\n",
      "loss: 0.000071  [73600/209452]\n",
      "loss: 0.000644  [76800/209452]\n",
      "loss: 0.000085  [80000/209452]\n",
      "loss: 0.000131  [83200/209452]\n",
      "loss: 0.000265  [86400/209452]\n",
      "loss: 0.000064  [89600/209452]\n",
      "loss: 0.000272  [92800/209452]\n",
      "loss: 0.000247  [96000/209452]\n",
      "loss: 0.000447  [99200/209452]\n",
      "loss: 0.000304  [102400/209452]\n",
      "loss: 0.000096  [105600/209452]\n",
      "loss: 0.001934  [108800/209452]\n",
      "loss: 0.000076  [112000/209452]\n",
      "loss: 0.004053  [115200/209452]\n",
      "loss: 0.000415  [118400/209452]\n",
      "loss: 0.002261  [121600/209452]\n",
      "loss: 0.000221  [124800/209452]\n",
      "loss: 0.000441  [128000/209452]\n",
      "loss: 0.000377  [131200/209452]\n",
      "loss: 0.000013  [134400/209452]\n",
      "loss: 0.000731  [137600/209452]\n",
      "loss: 0.000256  [140800/209452]\n",
      "loss: 0.000054  [144000/209452]\n",
      "loss: 0.002000  [147200/209452]\n",
      "loss: 0.001259  [150400/209452]\n",
      "loss: 0.000008  [153600/209452]\n",
      "loss: 0.000114  [156800/209452]\n",
      "loss: 0.000762  [160000/209452]\n",
      "loss: 0.000069  [163200/209452]\n",
      "loss: 0.000016  [166400/209452]\n",
      "loss: 0.000144  [169600/209452]\n",
      "loss: 0.000077  [172800/209452]\n",
      "loss: 0.000219  [176000/209452]\n",
      "loss: 0.002075  [179200/209452]\n",
      "loss: 0.001026  [182400/209452]\n",
      "loss: 0.000035  [185600/209452]\n",
      "loss: 0.000368  [188800/209452]\n",
      "loss: 0.000336  [192000/209452]\n",
      "loss: 0.000114  [195200/209452]\n",
      "loss: 0.000420  [198400/209452]\n",
      "loss: 0.000030  [201600/209452]\n",
      "loss: 0.000089  [204800/209452]\n",
      "loss: 0.000357  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 53\n",
      "---------------------------\n",
      "loss: 0.000075  [ 3200/209452]\n",
      "loss: 0.001101  [ 6400/209452]\n",
      "loss: 0.000050  [ 9600/209452]\n",
      "loss: 0.000158  [12800/209452]\n",
      "loss: 0.002225  [16000/209452]\n",
      "loss: 0.000071  [19200/209452]\n",
      "loss: 0.000078  [22400/209452]\n",
      "loss: 0.000055  [25600/209452]\n",
      "loss: 0.001540  [28800/209452]\n",
      "loss: 0.000114  [32000/209452]\n",
      "loss: 0.000327  [35200/209452]\n",
      "loss: 0.000065  [38400/209452]\n",
      "loss: 0.000283  [41600/209452]\n",
      "loss: 0.000222  [44800/209452]\n",
      "loss: 0.001655  [48000/209452]\n",
      "loss: 0.000891  [51200/209452]\n",
      "loss: 0.001226  [54400/209452]\n",
      "loss: 0.000022  [57600/209452]\n",
      "loss: 0.000016  [60800/209452]\n",
      "loss: 0.000157  [64000/209452]\n",
      "loss: 0.000082  [67200/209452]\n",
      "loss: 0.000049  [70400/209452]\n",
      "loss: 0.001808  [73600/209452]\n",
      "loss: 0.000295  [76800/209452]\n",
      "loss: 0.000082  [80000/209452]\n",
      "loss: 0.001166  [83200/209452]\n",
      "loss: 0.000031  [86400/209452]\n",
      "loss: 0.000094  [89600/209452]\n",
      "loss: 0.000281  [92800/209452]\n",
      "loss: 0.000219  [96000/209452]\n",
      "loss: 0.000123  [99200/209452]\n",
      "loss: 0.000183  [102400/209452]\n",
      "loss: 0.000390  [105600/209452]\n",
      "loss: 0.000171  [108800/209452]\n",
      "loss: 0.000166  [112000/209452]\n",
      "loss: 0.000144  [115200/209452]\n",
      "loss: 0.000106  [118400/209452]\n",
      "loss: 0.006347  [121600/209452]\n",
      "loss: 0.000044  [124800/209452]\n",
      "loss: 0.000169  [128000/209452]\n",
      "loss: 0.000056  [131200/209452]\n",
      "loss: 0.000109  [134400/209452]\n",
      "loss: 0.000116  [137600/209452]\n",
      "loss: 0.000200  [140800/209452]\n",
      "loss: 0.000511  [144000/209452]\n",
      "loss: 0.000087  [147200/209452]\n",
      "loss: 0.000038  [150400/209452]\n",
      "loss: 0.000206  [153600/209452]\n",
      "loss: 0.000191  [156800/209452]\n",
      "loss: 0.000031  [160000/209452]\n",
      "loss: 0.000055  [163200/209452]\n",
      "loss: 0.000040  [166400/209452]\n",
      "loss: 0.001614  [169600/209452]\n",
      "loss: 0.014604  [172800/209452]\n",
      "loss: 0.000223  [176000/209452]\n",
      "loss: 0.000088  [179200/209452]\n",
      "loss: 0.000051  [182400/209452]\n",
      "loss: 0.000085  [185600/209452]\n",
      "loss: 0.000052  [188800/209452]\n",
      "loss: 0.000090  [192000/209452]\n",
      "loss: 0.000026  [195200/209452]\n",
      "loss: 0.000100  [198400/209452]\n",
      "loss: 0.000135  [201600/209452]\n",
      "loss: 0.001114  [204800/209452]\n",
      "loss: 0.000156  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 54\n",
      "---------------------------\n",
      "loss: 0.000803  [ 3200/209452]\n",
      "loss: 0.001064  [ 6400/209452]\n",
      "loss: 0.001207  [ 9600/209452]\n",
      "loss: 0.001641  [12800/209452]\n",
      "loss: 0.000172  [16000/209452]\n",
      "loss: 0.000039  [19200/209452]\n",
      "loss: 0.010361  [22400/209452]\n",
      "loss: 0.000107  [25600/209452]\n",
      "loss: 0.000343  [28800/209452]\n",
      "loss: 0.000037  [32000/209452]\n",
      "loss: 0.001788  [35200/209452]\n",
      "loss: 0.000094  [38400/209452]\n",
      "loss: 0.000168  [41600/209452]\n",
      "loss: 0.000073  [44800/209452]\n",
      "loss: 0.000028  [48000/209452]\n",
      "loss: 0.000045  [51200/209452]\n",
      "loss: 0.000433  [54400/209452]\n",
      "loss: 0.000041  [57600/209452]\n",
      "loss: 0.000082  [60800/209452]\n",
      "loss: 0.000037  [64000/209452]\n",
      "loss: 0.000125  [67200/209452]\n",
      "loss: 0.000081  [70400/209452]\n",
      "loss: 0.000124  [73600/209452]\n",
      "loss: 0.000055  [76800/209452]\n",
      "loss: 0.000152  [80000/209452]\n",
      "loss: 0.000065  [83200/209452]\n",
      "loss: 0.001689  [86400/209452]\n",
      "loss: 0.000520  [89600/209452]\n",
      "loss: 0.000046  [92800/209452]\n",
      "loss: 0.000039  [96000/209452]\n",
      "loss: 0.000098  [99200/209452]\n",
      "loss: 0.000098  [102400/209452]\n",
      "loss: 0.000077  [105600/209452]\n",
      "loss: 0.000073  [108800/209452]\n",
      "loss: 0.000238  [112000/209452]\n",
      "loss: 0.000028  [115200/209452]\n",
      "loss: 0.000072  [118400/209452]\n",
      "loss: 0.000040  [121600/209452]\n",
      "loss: 0.000030  [124800/209452]\n",
      "loss: 0.000277  [128000/209452]\n",
      "loss: 0.000104  [131200/209452]\n",
      "loss: 0.000144  [134400/209452]\n",
      "loss: 0.000317  [137600/209452]\n",
      "loss: 0.000581  [140800/209452]\n",
      "loss: 0.000121  [144000/209452]\n",
      "loss: 0.000091  [147200/209452]\n",
      "loss: 0.000102  [150400/209452]\n",
      "loss: 0.000843  [153600/209452]\n",
      "loss: 0.000099  [156800/209452]\n",
      "loss: 0.000033  [160000/209452]\n",
      "loss: 0.000090  [163200/209452]\n",
      "loss: 0.002128  [166400/209452]\n",
      "loss: 0.000126  [169600/209452]\n",
      "loss: 0.000761  [172800/209452]\n",
      "loss: 0.000141  [176000/209452]\n",
      "loss: 0.000936  [179200/209452]\n",
      "loss: 0.000330  [182400/209452]\n",
      "loss: 0.000042  [185600/209452]\n",
      "loss: 0.000718  [188800/209452]\n",
      "loss: 0.000351  [192000/209452]\n",
      "loss: 0.000388  [195200/209452]\n",
      "loss: 0.000037  [198400/209452]\n",
      "loss: 0.000056  [201600/209452]\n",
      "loss: 0.000016  [204800/209452]\n",
      "loss: 0.000398  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002992 \n",
      "\n",
      "Epoch 55\n",
      "---------------------------\n",
      "loss: 0.000915  [ 3200/209452]\n",
      "loss: 0.000151  [ 6400/209452]\n",
      "loss: 0.000051  [ 9600/209452]\n",
      "loss: 0.000055  [12800/209452]\n",
      "loss: 0.000512  [16000/209452]\n",
      "loss: 0.000116  [19200/209452]\n",
      "loss: 0.000133  [22400/209452]\n",
      "loss: 0.000067  [25600/209452]\n",
      "loss: 0.000162  [28800/209452]\n",
      "loss: 0.000923  [32000/209452]\n",
      "loss: 0.000091  [35200/209452]\n",
      "loss: 0.000111  [38400/209452]\n",
      "loss: 0.000052  [41600/209452]\n",
      "loss: 0.000206  [44800/209452]\n",
      "loss: 0.000083  [48000/209452]\n",
      "loss: 0.000038  [51200/209452]\n",
      "loss: 0.002552  [54400/209452]\n",
      "loss: 0.000190  [57600/209452]\n",
      "loss: 0.000031  [60800/209452]\n",
      "loss: 0.001002  [64000/209452]\n",
      "loss: 0.000052  [67200/209452]\n",
      "loss: 0.000134  [70400/209452]\n",
      "loss: 0.000180  [73600/209452]\n",
      "loss: 0.000008  [76800/209452]\n",
      "loss: 0.000749  [80000/209452]\n",
      "loss: 0.000368  [83200/209452]\n",
      "loss: 0.000212  [86400/209452]\n",
      "loss: 0.000174  [89600/209452]\n",
      "loss: 0.000065  [92800/209452]\n",
      "loss: 0.000460  [96000/209452]\n",
      "loss: 0.000064  [99200/209452]\n",
      "loss: 0.001859  [102400/209452]\n",
      "loss: 0.000231  [105600/209452]\n",
      "loss: 0.000909  [108800/209452]\n",
      "loss: 0.000028  [112000/209452]\n",
      "loss: 0.002250  [115200/209452]\n",
      "loss: 0.000175  [118400/209452]\n",
      "loss: 0.000219  [121600/209452]\n",
      "loss: 0.000285  [124800/209452]\n",
      "loss: 0.000097  [128000/209452]\n",
      "loss: 0.001151  [131200/209452]\n",
      "loss: 0.000071  [134400/209452]\n",
      "loss: 0.000116  [137600/209452]\n",
      "loss: 0.000002  [140800/209452]\n",
      "loss: 0.000055  [144000/209452]\n",
      "loss: 0.000632  [147200/209452]\n",
      "loss: 0.000045  [150400/209452]\n",
      "loss: 0.000131  [153600/209452]\n",
      "loss: 0.000041  [156800/209452]\n",
      "loss: 0.000055  [160000/209452]\n",
      "loss: 0.000365  [163200/209452]\n",
      "loss: 0.000142  [166400/209452]\n",
      "loss: 0.000038  [169600/209452]\n",
      "loss: 0.001026  [172800/209452]\n",
      "loss: 0.000365  [176000/209452]\n",
      "loss: 0.000328  [179200/209452]\n",
      "loss: 0.000094  [182400/209452]\n",
      "loss: 0.000077  [185600/209452]\n",
      "loss: 0.000057  [188800/209452]\n",
      "loss: 0.000045  [192000/209452]\n",
      "loss: 0.001474  [195200/209452]\n",
      "loss: 0.000079  [198400/209452]\n",
      "loss: 0.000824  [201600/209452]\n",
      "loss: 0.000383  [204800/209452]\n",
      "loss: 0.000430  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003017 \n",
      "\n",
      "Epoch 56\n",
      "---------------------------\n",
      "loss: 0.002761  [ 3200/209452]\n",
      "loss: 0.000426  [ 6400/209452]\n",
      "loss: 0.000344  [ 9600/209452]\n",
      "loss: 0.000628  [12800/209452]\n",
      "loss: 0.000103  [16000/209452]\n",
      "loss: 0.000187  [19200/209452]\n",
      "loss: 0.000304  [22400/209452]\n",
      "loss: 0.000043  [25600/209452]\n",
      "loss: 0.000017  [28800/209452]\n",
      "loss: 0.000109  [32000/209452]\n",
      "loss: 0.000224  [35200/209452]\n",
      "loss: 0.000281  [38400/209452]\n",
      "loss: 0.000149  [41600/209452]\n",
      "loss: 0.001071  [44800/209452]\n",
      "loss: 0.000055  [48000/209452]\n",
      "loss: 0.000438  [51200/209452]\n",
      "loss: 0.000205  [54400/209452]\n",
      "loss: 0.000099  [57600/209452]\n",
      "loss: 0.000723  [60800/209452]\n",
      "loss: 0.000246  [64000/209452]\n",
      "loss: 0.000165  [67200/209452]\n",
      "loss: 0.000036  [70400/209452]\n",
      "loss: 0.000057  [73600/209452]\n",
      "loss: 0.000401  [76800/209452]\n",
      "loss: 0.000300  [80000/209452]\n",
      "loss: 0.000440  [83200/209452]\n",
      "loss: 0.000055  [86400/209452]\n",
      "loss: 0.000073  [89600/209452]\n",
      "loss: 0.000084  [92800/209452]\n",
      "loss: 0.000071  [96000/209452]\n",
      "loss: 0.000011  [99200/209452]\n",
      "loss: 0.001080  [102400/209452]\n",
      "loss: 0.000398  [105600/209452]\n",
      "loss: 0.000074  [108800/209452]\n",
      "loss: 0.000165  [112000/209452]\n",
      "loss: 0.005575  [115200/209452]\n",
      "loss: 0.000198  [118400/209452]\n",
      "loss: 0.000085  [121600/209452]\n",
      "loss: 0.000124  [124800/209452]\n",
      "loss: 0.000098  [128000/209452]\n",
      "loss: 0.002348  [131200/209452]\n",
      "loss: 0.000082  [134400/209452]\n",
      "loss: 0.000283  [137600/209452]\n",
      "loss: 0.000099  [140800/209452]\n",
      "loss: 0.000061  [144000/209452]\n",
      "loss: 0.001324  [147200/209452]\n",
      "loss: 0.000004  [150400/209452]\n",
      "loss: 0.000202  [153600/209452]\n",
      "loss: 0.000012  [156800/209452]\n",
      "loss: 0.003540  [160000/209452]\n",
      "loss: 0.000465  [163200/209452]\n",
      "loss: 0.000071  [166400/209452]\n",
      "loss: 0.000060  [169600/209452]\n",
      "loss: 0.000172  [172800/209452]\n",
      "loss: 0.000257  [176000/209452]\n",
      "loss: 0.000124  [179200/209452]\n",
      "loss: 0.000484  [182400/209452]\n",
      "loss: 0.000088  [185600/209452]\n",
      "loss: 0.000094  [188800/209452]\n",
      "loss: 0.000018  [192000/209452]\n",
      "loss: 0.000931  [195200/209452]\n",
      "loss: 0.000038  [198400/209452]\n",
      "loss: 0.000380  [201600/209452]\n",
      "loss: 0.000557  [204800/209452]\n",
      "loss: 0.000024  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 57\n",
      "---------------------------\n",
      "loss: 0.000095  [ 3200/209452]\n",
      "loss: 0.000148  [ 6400/209452]\n",
      "loss: 0.002414  [ 9600/209452]\n",
      "loss: 0.000043  [12800/209452]\n",
      "loss: 0.000169  [16000/209452]\n",
      "loss: 0.001427  [19200/209452]\n",
      "loss: 0.000013  [22400/209452]\n",
      "loss: 0.000303  [25600/209452]\n",
      "loss: 0.000258  [28800/209452]\n",
      "loss: 0.007070  [32000/209452]\n",
      "loss: 0.002834  [35200/209452]\n",
      "loss: 0.000617  [38400/209452]\n",
      "loss: 0.000170  [41600/209452]\n",
      "loss: 0.000167  [44800/209452]\n",
      "loss: 0.000046  [48000/209452]\n",
      "loss: 0.001094  [51200/209452]\n",
      "loss: 0.000006  [54400/209452]\n",
      "loss: 0.000018  [57600/209452]\n",
      "loss: 0.000331  [60800/209452]\n",
      "loss: 0.000104  [64000/209452]\n",
      "loss: 0.000005  [67200/209452]\n",
      "loss: 0.000076  [70400/209452]\n",
      "loss: 0.001903  [73600/209452]\n",
      "loss: 0.000021  [76800/209452]\n",
      "loss: 0.000127  [80000/209452]\n",
      "loss: 0.000252  [83200/209452]\n",
      "loss: 0.000087  [86400/209452]\n",
      "loss: 0.000047  [89600/209452]\n",
      "loss: 0.000050  [92800/209452]\n",
      "loss: 0.000108  [96000/209452]\n",
      "loss: 0.000150  [99200/209452]\n",
      "loss: 0.000417  [102400/209452]\n",
      "loss: 0.000011  [105600/209452]\n",
      "loss: 0.000059  [108800/209452]\n",
      "loss: 0.000024  [112000/209452]\n",
      "loss: 0.000839  [115200/209452]\n",
      "loss: 0.000084  [118400/209452]\n",
      "loss: 0.000091  [121600/209452]\n",
      "loss: 0.000195  [124800/209452]\n",
      "loss: 0.000975  [128000/209452]\n",
      "loss: 0.000123  [131200/209452]\n",
      "loss: 0.001831  [134400/209452]\n",
      "loss: 0.002162  [137600/209452]\n",
      "loss: 0.000092  [140800/209452]\n",
      "loss: 0.000117  [144000/209452]\n",
      "loss: 0.000337  [147200/209452]\n",
      "loss: 0.000014  [150400/209452]\n",
      "loss: 0.000086  [153600/209452]\n",
      "loss: 0.000217  [156800/209452]\n",
      "loss: 0.001481  [160000/209452]\n",
      "loss: 0.000560  [163200/209452]\n",
      "loss: 0.000069  [166400/209452]\n",
      "loss: 0.000249  [169600/209452]\n",
      "loss: 0.000156  [172800/209452]\n",
      "loss: 0.004575  [176000/209452]\n",
      "loss: 0.000339  [179200/209452]\n",
      "loss: 0.000852  [182400/209452]\n",
      "loss: 0.000133  [185600/209452]\n",
      "loss: 0.000041  [188800/209452]\n",
      "loss: 0.000071  [192000/209452]\n",
      "loss: 0.000259  [195200/209452]\n",
      "loss: 0.000015  [198400/209452]\n",
      "loss: 0.001287  [201600/209452]\n",
      "loss: 0.000202  [204800/209452]\n",
      "loss: 0.000111  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 58\n",
      "---------------------------\n",
      "loss: 0.000071  [ 3200/209452]\n",
      "loss: 0.000111  [ 6400/209452]\n",
      "loss: 0.000216  [ 9600/209452]\n",
      "loss: 0.002260  [12800/209452]\n",
      "loss: 0.000198  [16000/209452]\n",
      "loss: 0.000284  [19200/209452]\n",
      "loss: 0.000099  [22400/209452]\n",
      "loss: 0.000495  [25600/209452]\n",
      "loss: 0.000077  [28800/209452]\n",
      "loss: 0.000020  [32000/209452]\n",
      "loss: 0.000074  [35200/209452]\n",
      "loss: 0.000019  [38400/209452]\n",
      "loss: 0.000035  [41600/209452]\n",
      "loss: 0.000053  [44800/209452]\n",
      "loss: 0.000032  [48000/209452]\n",
      "loss: 0.000044  [51200/209452]\n",
      "loss: 0.002817  [54400/209452]\n",
      "loss: 0.000049  [57600/209452]\n",
      "loss: 0.000027  [60800/209452]\n",
      "loss: 0.000234  [64000/209452]\n",
      "loss: 0.000074  [67200/209452]\n",
      "loss: 0.000092  [70400/209452]\n",
      "loss: 0.000022  [73600/209452]\n",
      "loss: 0.000131  [76800/209452]\n",
      "loss: 0.000034  [80000/209452]\n",
      "loss: 0.000374  [83200/209452]\n",
      "loss: 0.002110  [86400/209452]\n",
      "loss: 0.000310  [89600/209452]\n",
      "loss: 0.000058  [92800/209452]\n",
      "loss: 0.000460  [96000/209452]\n",
      "loss: 0.000165  [99200/209452]\n",
      "loss: 0.000375  [102400/209452]\n",
      "loss: 0.000250  [105600/209452]\n",
      "loss: 0.005029  [108800/209452]\n",
      "loss: 0.000038  [112000/209452]\n",
      "loss: 0.000369  [115200/209452]\n",
      "loss: 0.000162  [118400/209452]\n",
      "loss: 0.000495  [121600/209452]\n",
      "loss: 0.000197  [124800/209452]\n",
      "loss: 0.000408  [128000/209452]\n",
      "loss: 0.000084  [131200/209452]\n",
      "loss: 0.000251  [134400/209452]\n",
      "loss: 0.000313  [137600/209452]\n",
      "loss: 0.000071  [140800/209452]\n",
      "loss: 0.000473  [144000/209452]\n",
      "loss: 0.000108  [147200/209452]\n",
      "loss: 0.000111  [150400/209452]\n",
      "loss: 0.000051  [153600/209452]\n",
      "loss: 0.000131  [156800/209452]\n",
      "loss: 0.000017  [160000/209452]\n",
      "loss: 0.000101  [163200/209452]\n",
      "loss: 0.000029  [166400/209452]\n",
      "loss: 0.000137  [169600/209452]\n",
      "loss: 0.000432  [172800/209452]\n",
      "loss: 0.000249  [176000/209452]\n",
      "loss: 0.000348  [179200/209452]\n",
      "loss: 0.000007  [182400/209452]\n",
      "loss: 0.000184  [185600/209452]\n",
      "loss: 0.000883  [188800/209452]\n",
      "loss: 0.000098  [192000/209452]\n",
      "loss: 0.000032  [195200/209452]\n",
      "loss: 0.000057  [198400/209452]\n",
      "loss: 0.000064  [201600/209452]\n",
      "loss: 0.000189  [204800/209452]\n",
      "loss: 0.000020  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 59\n",
      "---------------------------\n",
      "loss: 0.000882  [ 3200/209452]\n",
      "loss: 0.000773  [ 6400/209452]\n",
      "loss: 0.000041  [ 9600/209452]\n",
      "loss: 0.000057  [12800/209452]\n",
      "loss: 0.000078  [16000/209452]\n",
      "loss: 0.000082  [19200/209452]\n",
      "loss: 0.000103  [22400/209452]\n",
      "loss: 0.000243  [25600/209452]\n",
      "loss: 0.000189  [28800/209452]\n",
      "loss: 0.000427  [32000/209452]\n",
      "loss: 0.000881  [35200/209452]\n",
      "loss: 0.000056  [38400/209452]\n",
      "loss: 0.000084  [41600/209452]\n",
      "loss: 0.000102  [44800/209452]\n",
      "loss: 0.000010  [48000/209452]\n",
      "loss: 0.000164  [51200/209452]\n",
      "loss: 0.000067  [54400/209452]\n",
      "loss: 0.000014  [57600/209452]\n",
      "loss: 0.000742  [60800/209452]\n",
      "loss: 0.000048  [64000/209452]\n",
      "loss: 0.000867  [67200/209452]\n",
      "loss: 0.000099  [70400/209452]\n",
      "loss: 0.000012  [73600/209452]\n",
      "loss: 0.000030  [76800/209452]\n",
      "loss: 0.000102  [80000/209452]\n",
      "loss: 0.000056  [83200/209452]\n",
      "loss: 0.000080  [86400/209452]\n",
      "loss: 0.000211  [89600/209452]\n",
      "loss: 0.000123  [92800/209452]\n",
      "loss: 0.000210  [96000/209452]\n",
      "loss: 0.000255  [99200/209452]\n",
      "loss: 0.000027  [102400/209452]\n",
      "loss: 0.000196  [105600/209452]\n",
      "loss: 0.000805  [108800/209452]\n",
      "loss: 0.000180  [112000/209452]\n",
      "loss: 0.000037  [115200/209452]\n",
      "loss: 0.000064  [118400/209452]\n",
      "loss: 0.000200  [121600/209452]\n",
      "loss: 0.000063  [124800/209452]\n",
      "loss: 0.000022  [128000/209452]\n",
      "loss: 0.000037  [131200/209452]\n",
      "loss: 0.000274  [134400/209452]\n",
      "loss: 0.001828  [137600/209452]\n",
      "loss: 0.000888  [140800/209452]\n",
      "loss: 0.000030  [144000/209452]\n",
      "loss: 0.000083  [147200/209452]\n",
      "loss: 0.000060  [150400/209452]\n",
      "loss: 0.000613  [153600/209452]\n",
      "loss: 0.000017  [156800/209452]\n",
      "loss: 0.000037  [160000/209452]\n",
      "loss: 0.000216  [163200/209452]\n",
      "loss: 0.000246  [166400/209452]\n",
      "loss: 0.000085  [169600/209452]\n",
      "loss: 0.000215  [172800/209452]\n",
      "loss: 0.000043  [176000/209452]\n",
      "loss: 0.000061  [179200/209452]\n",
      "loss: 0.000690  [182400/209452]\n",
      "loss: 0.000041  [185600/209452]\n",
      "loss: 0.000061  [188800/209452]\n",
      "loss: 0.000101  [192000/209452]\n",
      "loss: 0.000173  [195200/209452]\n",
      "loss: 0.000130  [198400/209452]\n",
      "loss: 0.000058  [201600/209452]\n",
      "loss: 0.000043  [204800/209452]\n",
      "loss: 0.000349  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002877 \n",
      "\n",
      "Epoch 60\n",
      "---------------------------\n",
      "loss: 0.000060  [ 3200/209452]\n",
      "loss: 0.000063  [ 6400/209452]\n",
      "loss: 0.000833  [ 9600/209452]\n",
      "loss: 0.000105  [12800/209452]\n",
      "loss: 0.000378  [16000/209452]\n",
      "loss: 0.002560  [19200/209452]\n",
      "loss: 0.000027  [22400/209452]\n",
      "loss: 0.000497  [25600/209452]\n",
      "loss: 0.000140  [28800/209452]\n",
      "loss: 0.000134  [32000/209452]\n",
      "loss: 0.000041  [35200/209452]\n",
      "loss: 0.000348  [38400/209452]\n",
      "loss: 0.000098  [41600/209452]\n",
      "loss: 0.001069  [44800/209452]\n",
      "loss: 0.000076  [48000/209452]\n",
      "loss: 0.000355  [51200/209452]\n",
      "loss: 0.000092  [54400/209452]\n",
      "loss: 0.000173  [57600/209452]\n",
      "loss: 0.000576  [60800/209452]\n",
      "loss: 0.000023  [64000/209452]\n",
      "loss: 0.000239  [67200/209452]\n",
      "loss: 0.000003  [70400/209452]\n",
      "loss: 0.000170  [73600/209452]\n",
      "loss: 0.000089  [76800/209452]\n",
      "loss: 0.001679  [80000/209452]\n",
      "loss: 0.000061  [83200/209452]\n",
      "loss: 0.000026  [86400/209452]\n",
      "loss: 0.000923  [89600/209452]\n",
      "loss: 0.000087  [92800/209452]\n",
      "loss: 0.000207  [96000/209452]\n",
      "loss: 0.000288  [99200/209452]\n",
      "loss: 0.000208  [102400/209452]\n",
      "loss: 0.000854  [105600/209452]\n",
      "loss: 0.000150  [108800/209452]\n",
      "loss: 0.000061  [112000/209452]\n",
      "loss: 0.000113  [115200/209452]\n",
      "loss: 0.001062  [118400/209452]\n",
      "loss: 0.000153  [121600/209452]\n",
      "loss: 0.000151  [124800/209452]\n",
      "loss: 0.000070  [128000/209452]\n",
      "loss: 0.000005  [131200/209452]\n",
      "loss: 0.000151  [134400/209452]\n",
      "loss: 0.000034  [137600/209452]\n",
      "loss: 0.000057  [140800/209452]\n",
      "loss: 0.000009  [144000/209452]\n",
      "loss: 0.000597  [147200/209452]\n",
      "loss: 0.000296  [150400/209452]\n",
      "loss: 0.000076  [153600/209452]\n",
      "loss: 0.000084  [156800/209452]\n",
      "loss: 0.000184  [160000/209452]\n",
      "loss: 0.000111  [163200/209452]\n",
      "loss: 0.000058  [166400/209452]\n",
      "loss: 0.001088  [169600/209452]\n",
      "loss: 0.000120  [172800/209452]\n",
      "loss: 0.003786  [176000/209452]\n",
      "loss: 0.000260  [179200/209452]\n",
      "loss: 0.000078  [182400/209452]\n",
      "loss: 0.000543  [185600/209452]\n",
      "loss: 0.000237  [188800/209452]\n",
      "loss: 0.000184  [192000/209452]\n",
      "loss: 0.000143  [195200/209452]\n",
      "loss: 0.000213  [198400/209452]\n",
      "loss: 0.000231  [201600/209452]\n",
      "loss: 0.000934  [204800/209452]\n",
      "loss: 0.000013  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 61\n",
      "---------------------------\n",
      "loss: 0.000021  [ 3200/209452]\n",
      "loss: 0.000027  [ 6400/209452]\n",
      "loss: 0.000218  [ 9600/209452]\n",
      "loss: 0.000010  [12800/209452]\n",
      "loss: 0.000629  [16000/209452]\n",
      "loss: 0.000022  [19200/209452]\n",
      "loss: 0.000030  [22400/209452]\n",
      "loss: 0.000046  [25600/209452]\n",
      "loss: 0.000264  [28800/209452]\n",
      "loss: 0.000221  [32000/209452]\n",
      "loss: 0.001261  [35200/209452]\n",
      "loss: 0.000268  [38400/209452]\n",
      "loss: 0.000190  [41600/209452]\n",
      "loss: 0.000168  [44800/209452]\n",
      "loss: 0.000103  [48000/209452]\n",
      "loss: 0.001489  [51200/209452]\n",
      "loss: 0.000076  [54400/209452]\n",
      "loss: 0.000144  [57600/209452]\n",
      "loss: 0.000235  [60800/209452]\n",
      "loss: 0.000206  [64000/209452]\n",
      "loss: 0.000042  [67200/209452]\n",
      "loss: 0.000021  [70400/209452]\n",
      "loss: 0.000100  [73600/209452]\n",
      "loss: 0.000650  [76800/209452]\n",
      "loss: 0.000027  [80000/209452]\n",
      "loss: 0.000138  [83200/209452]\n",
      "loss: 0.000903  [86400/209452]\n",
      "loss: 0.000160  [89600/209452]\n",
      "loss: 0.000009  [92800/209452]\n",
      "loss: 0.000212  [96000/209452]\n",
      "loss: 0.000246  [99200/209452]\n",
      "loss: 0.000084  [102400/209452]\n",
      "loss: 0.000102  [105600/209452]\n",
      "loss: 0.000105  [108800/209452]\n",
      "loss: 0.000100  [112000/209452]\n",
      "loss: 0.000074  [115200/209452]\n",
      "loss: 0.000024  [118400/209452]\n",
      "loss: 0.000051  [121600/209452]\n",
      "loss: 0.000266  [124800/209452]\n",
      "loss: 0.002902  [128000/209452]\n",
      "loss: 0.000061  [131200/209452]\n",
      "loss: 0.000105  [134400/209452]\n",
      "loss: 0.000050  [137600/209452]\n",
      "loss: 0.000065  [140800/209452]\n",
      "loss: 0.000226  [144000/209452]\n",
      "loss: 0.000035  [147200/209452]\n",
      "loss: 0.000017  [150400/209452]\n",
      "loss: 0.000108  [153600/209452]\n",
      "loss: 0.000319  [156800/209452]\n",
      "loss: 0.000168  [160000/209452]\n",
      "loss: 0.000039  [163200/209452]\n",
      "loss: 0.000178  [166400/209452]\n",
      "loss: 0.000105  [169600/209452]\n",
      "loss: 0.000039  [172800/209452]\n",
      "loss: 0.000276  [176000/209452]\n",
      "loss: 0.000186  [179200/209452]\n",
      "loss: 0.000035  [182400/209452]\n",
      "loss: 0.001476  [185600/209452]\n",
      "loss: 0.000381  [188800/209452]\n",
      "loss: 0.000172  [192000/209452]\n",
      "loss: 0.000030  [195200/209452]\n",
      "loss: 0.001143  [198400/209452]\n",
      "loss: 0.000015  [201600/209452]\n",
      "loss: 0.000542  [204800/209452]\n",
      "loss: 0.000151  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003036 \n",
      "\n",
      "Epoch 62\n",
      "---------------------------\n",
      "loss: 0.000065  [ 3200/209452]\n",
      "loss: 0.000027  [ 6400/209452]\n",
      "loss: 0.000423  [ 9600/209452]\n",
      "loss: 0.000192  [12800/209452]\n",
      "loss: 0.001516  [16000/209452]\n",
      "loss: 0.000033  [19200/209452]\n",
      "loss: 0.000044  [22400/209452]\n",
      "loss: 0.000015  [25600/209452]\n",
      "loss: 0.000094  [28800/209452]\n",
      "loss: 0.000227  [32000/209452]\n",
      "loss: 0.000062  [35200/209452]\n",
      "loss: 0.000055  [38400/209452]\n",
      "loss: 0.000663  [41600/209452]\n",
      "loss: 0.000083  [44800/209452]\n",
      "loss: 0.000247  [48000/209452]\n",
      "loss: 0.000110  [51200/209452]\n",
      "loss: 0.000056  [54400/209452]\n",
      "loss: 0.000031  [57600/209452]\n",
      "loss: 0.000019  [60800/209452]\n",
      "loss: 0.000171  [64000/209452]\n",
      "loss: 0.000050  [67200/209452]\n",
      "loss: 0.000021  [70400/209452]\n",
      "loss: 0.000041  [73600/209452]\n",
      "loss: 0.000037  [76800/209452]\n",
      "loss: 0.001022  [80000/209452]\n",
      "loss: 0.002371  [83200/209452]\n",
      "loss: 0.001732  [86400/209452]\n",
      "loss: 0.000063  [89600/209452]\n",
      "loss: 0.000034  [92800/209452]\n",
      "loss: 0.000318  [96000/209452]\n",
      "loss: 0.000043  [99200/209452]\n",
      "loss: 0.000685  [102400/209452]\n",
      "loss: 0.000194  [105600/209452]\n",
      "loss: 0.000186  [108800/209452]\n",
      "loss: 0.000013  [112000/209452]\n",
      "loss: 0.000059  [115200/209452]\n",
      "loss: 0.000187  [118400/209452]\n",
      "loss: 0.000233  [121600/209452]\n",
      "loss: 0.000101  [124800/209452]\n",
      "loss: 0.000041  [128000/209452]\n",
      "loss: 0.000026  [131200/209452]\n",
      "loss: 0.000044  [134400/209452]\n",
      "loss: 0.000053  [137600/209452]\n",
      "loss: 0.000017  [140800/209452]\n",
      "loss: 0.000087  [144000/209452]\n",
      "loss: 0.000241  [147200/209452]\n",
      "loss: 0.000007  [150400/209452]\n",
      "loss: 0.000011  [153600/209452]\n",
      "loss: 0.003139  [156800/209452]\n",
      "loss: 0.000087  [160000/209452]\n",
      "loss: 0.000060  [163200/209452]\n",
      "loss: 0.000029  [166400/209452]\n",
      "loss: 0.000011  [169600/209452]\n",
      "loss: 0.000190  [172800/209452]\n",
      "loss: 0.000150  [176000/209452]\n",
      "loss: 0.000000  [179200/209452]\n",
      "loss: 0.000027  [182400/209452]\n",
      "loss: 0.000063  [185600/209452]\n",
      "loss: 0.000046  [188800/209452]\n",
      "loss: 0.000055  [192000/209452]\n",
      "loss: 0.000241  [195200/209452]\n",
      "loss: 0.000114  [198400/209452]\n",
      "loss: 0.000047  [201600/209452]\n",
      "loss: 0.000099  [204800/209452]\n",
      "loss: 0.000051  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 63\n",
      "---------------------------\n",
      "loss: 0.000034  [ 3200/209452]\n",
      "loss: 0.000161  [ 6400/209452]\n",
      "loss: 0.000444  [ 9600/209452]\n",
      "loss: 0.000019  [12800/209452]\n",
      "loss: 0.000653  [16000/209452]\n",
      "loss: 0.000050  [19200/209452]\n",
      "loss: 0.000238  [22400/209452]\n",
      "loss: 0.000234  [25600/209452]\n",
      "loss: 0.000011  [28800/209452]\n",
      "loss: 0.000028  [32000/209452]\n",
      "loss: 0.000013  [35200/209452]\n",
      "loss: 0.000367  [38400/209452]\n",
      "loss: 0.000081  [41600/209452]\n",
      "loss: 0.000056  [44800/209452]\n",
      "loss: 0.000014  [48000/209452]\n",
      "loss: 0.000068  [51200/209452]\n",
      "loss: 0.000462  [54400/209452]\n",
      "loss: 0.000099  [57600/209452]\n",
      "loss: 0.000064  [60800/209452]\n",
      "loss: 0.000069  [64000/209452]\n",
      "loss: 0.000066  [67200/209452]\n",
      "loss: 0.001108  [70400/209452]\n",
      "loss: 0.000381  [73600/209452]\n",
      "loss: 0.000142  [76800/209452]\n",
      "loss: 0.000169  [80000/209452]\n",
      "loss: 0.000115  [83200/209452]\n",
      "loss: 0.000782  [86400/209452]\n",
      "loss: 0.002546  [89600/209452]\n",
      "loss: 0.000245  [92800/209452]\n",
      "loss: 0.000224  [96000/209452]\n",
      "loss: 0.000052  [99200/209452]\n",
      "loss: 0.004022  [102400/209452]\n",
      "loss: 0.000025  [105600/209452]\n",
      "loss: 0.000040  [108800/209452]\n",
      "loss: 0.000124  [112000/209452]\n",
      "loss: 0.000014  [115200/209452]\n",
      "loss: 0.000065  [118400/209452]\n",
      "loss: 0.000010  [121600/209452]\n",
      "loss: 0.000072  [124800/209452]\n",
      "loss: 0.001263  [128000/209452]\n",
      "loss: 0.000370  [131200/209452]\n",
      "loss: 0.000429  [134400/209452]\n",
      "loss: 0.000051  [137600/209452]\n",
      "loss: 0.000037  [140800/209452]\n",
      "loss: 0.000035  [144000/209452]\n",
      "loss: 0.000324  [147200/209452]\n",
      "loss: 0.000234  [150400/209452]\n",
      "loss: 0.000133  [153600/209452]\n",
      "loss: 0.000693  [156800/209452]\n",
      "loss: 0.000134  [160000/209452]\n",
      "loss: 0.000410  [163200/209452]\n",
      "loss: 0.000064  [166400/209452]\n",
      "loss: 0.001302  [169600/209452]\n",
      "loss: 0.000202  [172800/209452]\n",
      "loss: 0.000088  [176000/209452]\n",
      "loss: 0.000236  [179200/209452]\n",
      "loss: 0.000033  [182400/209452]\n",
      "loss: 0.000075  [185600/209452]\n",
      "loss: 0.000209  [188800/209452]\n",
      "loss: 0.000557  [192000/209452]\n",
      "loss: 0.000216  [195200/209452]\n",
      "loss: 0.000049  [198400/209452]\n",
      "loss: 0.000282  [201600/209452]\n",
      "loss: 0.000621  [204800/209452]\n",
      "loss: 0.000015  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.003035 \n",
      "\n",
      "Epoch 64\n",
      "---------------------------\n",
      "loss: 0.000073  [ 3200/209452]\n",
      "loss: 0.001821  [ 6400/209452]\n",
      "loss: 0.000069  [ 9600/209452]\n",
      "loss: 0.000040  [12800/209452]\n",
      "loss: 0.000146  [16000/209452]\n",
      "loss: 0.000074  [19200/209452]\n",
      "loss: 0.000041  [22400/209452]\n",
      "loss: 0.003920  [25600/209452]\n",
      "loss: 0.000358  [28800/209452]\n",
      "loss: 0.000015  [32000/209452]\n",
      "loss: 0.005823  [35200/209452]\n",
      "loss: 0.000076  [38400/209452]\n",
      "loss: 0.000024  [41600/209452]\n",
      "loss: 0.000023  [44800/209452]\n",
      "loss: 0.000493  [48000/209452]\n",
      "loss: 0.000151  [51200/209452]\n",
      "loss: 0.000062  [54400/209452]\n",
      "loss: 0.000079  [57600/209452]\n",
      "loss: 0.000033  [60800/209452]\n",
      "loss: 0.000476  [64000/209452]\n",
      "loss: 0.000005  [67200/209452]\n",
      "loss: 0.000040  [70400/209452]\n",
      "loss: 0.000190  [73600/209452]\n",
      "loss: 0.000007  [76800/209452]\n",
      "loss: 0.000013  [80000/209452]\n",
      "loss: 0.000703  [83200/209452]\n",
      "loss: 0.000036  [86400/209452]\n",
      "loss: 0.000253  [89600/209452]\n",
      "loss: 0.000029  [92800/209452]\n",
      "loss: 0.000308  [96000/209452]\n",
      "loss: 0.000550  [99200/209452]\n",
      "loss: 0.000325  [102400/209452]\n",
      "loss: 0.000189  [105600/209452]\n",
      "loss: 0.000245  [108800/209452]\n",
      "loss: 0.000725  [112000/209452]\n",
      "loss: 0.000222  [115200/209452]\n",
      "loss: 0.000029  [118400/209452]\n",
      "loss: 0.000024  [121600/209452]\n",
      "loss: 0.000010  [124800/209452]\n",
      "loss: 0.000055  [128000/209452]\n",
      "loss: 0.000061  [131200/209452]\n",
      "loss: 0.000379  [134400/209452]\n",
      "loss: 0.001514  [137600/209452]\n",
      "loss: 0.000029  [140800/209452]\n",
      "loss: 0.000122  [144000/209452]\n",
      "loss: 0.000093  [147200/209452]\n",
      "loss: 0.000031  [150400/209452]\n",
      "loss: 0.000017  [153600/209452]\n",
      "loss: 0.002237  [156800/209452]\n",
      "loss: 0.000055  [160000/209452]\n",
      "loss: 0.000460  [163200/209452]\n",
      "loss: 0.000125  [166400/209452]\n",
      "loss: 0.000691  [169600/209452]\n",
      "loss: 0.000033  [172800/209452]\n",
      "loss: 0.000078  [176000/209452]\n",
      "loss: 0.000155  [179200/209452]\n",
      "loss: 0.000213  [182400/209452]\n",
      "loss: 0.000741  [185600/209452]\n",
      "loss: 0.000012  [188800/209452]\n",
      "loss: 0.000380  [192000/209452]\n",
      "loss: 0.000113  [195200/209452]\n",
      "loss: 0.000020  [198400/209452]\n",
      "loss: 0.000214  [201600/209452]\n",
      "loss: 0.000035  [204800/209452]\n",
      "loss: 0.000164  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 65\n",
      "---------------------------\n",
      "loss: 0.000093  [ 3200/209452]\n",
      "loss: 0.000011  [ 6400/209452]\n",
      "loss: 0.000115  [ 9600/209452]\n",
      "loss: 0.000101  [12800/209452]\n",
      "loss: 0.000248  [16000/209452]\n",
      "loss: 0.000023  [19200/209452]\n",
      "loss: 0.000147  [22400/209452]\n",
      "loss: 0.000155  [25600/209452]\n",
      "loss: 0.000110  [28800/209452]\n",
      "loss: 0.000955  [32000/209452]\n",
      "loss: 0.000104  [35200/209452]\n",
      "loss: 0.000065  [38400/209452]\n",
      "loss: 0.000435  [41600/209452]\n",
      "loss: 0.000075  [44800/209452]\n",
      "loss: 0.000055  [48000/209452]\n",
      "loss: 0.000580  [51200/209452]\n",
      "loss: 0.000276  [54400/209452]\n",
      "loss: 0.000881  [57600/209452]\n",
      "loss: 0.000245  [60800/209452]\n",
      "loss: 0.000018  [64000/209452]\n",
      "loss: 0.000039  [67200/209452]\n",
      "loss: 0.000228  [70400/209452]\n",
      "loss: 0.000015  [73600/209452]\n",
      "loss: 0.000321  [76800/209452]\n",
      "loss: 0.000091  [80000/209452]\n",
      "loss: 0.000684  [83200/209452]\n",
      "loss: 0.000071  [86400/209452]\n",
      "loss: 0.000266  [89600/209452]\n",
      "loss: 0.000093  [92800/209452]\n",
      "loss: 0.000044  [96000/209452]\n",
      "loss: 0.000668  [99200/209452]\n",
      "loss: 0.000183  [102400/209452]\n",
      "loss: 0.000077  [105600/209452]\n",
      "loss: 0.000034  [108800/209452]\n",
      "loss: 0.006861  [112000/209452]\n",
      "loss: 0.000162  [115200/209452]\n",
      "loss: 0.001503  [118400/209452]\n",
      "loss: 0.000174  [121600/209452]\n",
      "loss: 0.000043  [124800/209452]\n",
      "loss: 0.000163  [128000/209452]\n",
      "loss: 0.000012  [131200/209452]\n",
      "loss: 0.000218  [134400/209452]\n",
      "loss: 0.000008  [137600/209452]\n",
      "loss: 0.000363  [140800/209452]\n",
      "loss: 0.000023  [144000/209452]\n",
      "loss: 0.000088  [147200/209452]\n",
      "loss: 0.000010  [150400/209452]\n",
      "loss: 0.000115  [153600/209452]\n",
      "loss: 0.000127  [156800/209452]\n",
      "loss: 0.000001  [160000/209452]\n",
      "loss: 0.000046  [163200/209452]\n",
      "loss: 0.000223  [166400/209452]\n",
      "loss: 0.000288  [169600/209452]\n",
      "loss: 0.000123  [172800/209452]\n",
      "loss: 0.000140  [176000/209452]\n",
      "loss: 0.000065  [179200/209452]\n",
      "loss: 0.000485  [182400/209452]\n",
      "loss: 0.000011  [185600/209452]\n",
      "loss: 0.000054  [188800/209452]\n",
      "loss: 0.000035  [192000/209452]\n",
      "loss: 0.000016  [195200/209452]\n",
      "loss: 0.000259  [198400/209452]\n",
      "loss: 0.000004  [201600/209452]\n",
      "loss: 0.000423  [204800/209452]\n",
      "loss: 0.000066  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 66\n",
      "---------------------------\n",
      "loss: 0.000045  [ 3200/209452]\n",
      "loss: 0.001407  [ 6400/209452]\n",
      "loss: 0.000047  [ 9600/209452]\n",
      "loss: 0.000965  [12800/209452]\n",
      "loss: 0.000087  [16000/209452]\n",
      "loss: 0.000036  [19200/209452]\n",
      "loss: 0.000247  [22400/209452]\n",
      "loss: 0.000111  [25600/209452]\n",
      "loss: 0.000080  [28800/209452]\n",
      "loss: 0.000033  [32000/209452]\n",
      "loss: 0.001063  [35200/209452]\n",
      "loss: 0.000080  [38400/209452]\n",
      "loss: 0.000015  [41600/209452]\n",
      "loss: 0.000063  [44800/209452]\n",
      "loss: 0.000249  [48000/209452]\n",
      "loss: 0.000500  [51200/209452]\n",
      "loss: 0.000475  [54400/209452]\n",
      "loss: 0.000083  [57600/209452]\n",
      "loss: 0.000107  [60800/209452]\n",
      "loss: 0.000110  [64000/209452]\n",
      "loss: 0.000227  [67200/209452]\n",
      "loss: 0.000048  [70400/209452]\n",
      "loss: 0.000499  [73600/209452]\n",
      "loss: 0.000136  [76800/209452]\n",
      "loss: 0.000523  [80000/209452]\n",
      "loss: 0.000128  [83200/209452]\n",
      "loss: 0.000370  [86400/209452]\n",
      "loss: 0.000046  [89600/209452]\n",
      "loss: 0.000944  [92800/209452]\n",
      "loss: 0.000009  [96000/209452]\n",
      "loss: 0.000084  [99200/209452]\n",
      "loss: 0.000305  [102400/209452]\n",
      "loss: 0.000277  [105600/209452]\n",
      "loss: 0.000054  [108800/209452]\n",
      "loss: 0.000034  [112000/209452]\n",
      "loss: 0.000031  [115200/209452]\n",
      "loss: 0.000343  [118400/209452]\n",
      "loss: 0.000234  [121600/209452]\n",
      "loss: 0.000037  [124800/209452]\n",
      "loss: 0.000097  [128000/209452]\n",
      "loss: 0.000362  [131200/209452]\n",
      "loss: 0.000050  [134400/209452]\n",
      "loss: 0.000082  [137600/209452]\n",
      "loss: 0.000141  [140800/209452]\n",
      "loss: 0.000034  [144000/209452]\n",
      "loss: 0.000030  [147200/209452]\n",
      "loss: 0.000066  [150400/209452]\n",
      "loss: 0.000080  [153600/209452]\n",
      "loss: 0.000419  [156800/209452]\n",
      "loss: 0.001232  [160000/209452]\n",
      "loss: 0.000072  [163200/209452]\n",
      "loss: 0.000773  [166400/209452]\n",
      "loss: 0.001818  [169600/209452]\n",
      "loss: 0.000283  [172800/209452]\n",
      "loss: 0.000151  [176000/209452]\n",
      "loss: 0.000067  [179200/209452]\n",
      "loss: 0.000055  [182400/209452]\n",
      "loss: 0.000308  [185600/209452]\n",
      "loss: 0.000160  [188800/209452]\n",
      "loss: 0.000168  [192000/209452]\n",
      "loss: 0.000085  [195200/209452]\n",
      "loss: 0.000021  [198400/209452]\n",
      "loss: 0.000249  [201600/209452]\n",
      "loss: 0.000087  [204800/209452]\n",
      "loss: 0.000550  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 67\n",
      "---------------------------\n",
      "loss: 0.000120  [ 3200/209452]\n",
      "loss: 0.001320  [ 6400/209452]\n",
      "loss: 0.000037  [ 9600/209452]\n",
      "loss: 0.000037  [12800/209452]\n",
      "loss: 0.000118  [16000/209452]\n",
      "loss: 0.000055  [19200/209452]\n",
      "loss: 0.000069  [22400/209452]\n",
      "loss: 0.000072  [25600/209452]\n",
      "loss: 0.000021  [28800/209452]\n",
      "loss: 0.000104  [32000/209452]\n",
      "loss: 0.000936  [35200/209452]\n",
      "loss: 0.001987  [38400/209452]\n",
      "loss: 0.000012  [41600/209452]\n",
      "loss: 0.000055  [44800/209452]\n",
      "loss: 0.000015  [48000/209452]\n",
      "loss: 0.000255  [51200/209452]\n",
      "loss: 0.000036  [54400/209452]\n",
      "loss: 0.000109  [57600/209452]\n",
      "loss: 0.000654  [60800/209452]\n",
      "loss: 0.000393  [64000/209452]\n",
      "loss: 0.000859  [67200/209452]\n",
      "loss: 0.000051  [70400/209452]\n",
      "loss: 0.004829  [73600/209452]\n",
      "loss: 0.000441  [76800/209452]\n",
      "loss: 0.000023  [80000/209452]\n",
      "loss: 0.000136  [83200/209452]\n",
      "loss: 0.000388  [86400/209452]\n",
      "loss: 0.000060  [89600/209452]\n",
      "loss: 0.000356  [92800/209452]\n",
      "loss: 0.000036  [96000/209452]\n",
      "loss: 0.000276  [99200/209452]\n",
      "loss: 0.000074  [102400/209452]\n",
      "loss: 0.000647  [105600/209452]\n",
      "loss: 0.000091  [108800/209452]\n",
      "loss: 0.000130  [112000/209452]\n",
      "loss: 0.000120  [115200/209452]\n",
      "loss: 0.000138  [118400/209452]\n",
      "loss: 0.000481  [121600/209452]\n",
      "loss: 0.000121  [124800/209452]\n",
      "loss: 0.000167  [128000/209452]\n",
      "loss: 0.000042  [131200/209452]\n",
      "loss: 0.000054  [134400/209452]\n",
      "loss: 0.000087  [137600/209452]\n",
      "loss: 0.003089  [140800/209452]\n",
      "loss: 0.000099  [144000/209452]\n",
      "loss: 0.000031  [147200/209452]\n",
      "loss: 0.000041  [150400/209452]\n",
      "loss: 0.000059  [153600/209452]\n",
      "loss: 0.001441  [156800/209452]\n",
      "loss: 0.004136  [160000/209452]\n",
      "loss: 0.000058  [163200/209452]\n",
      "loss: 0.000041  [166400/209452]\n",
      "loss: 0.000027  [169600/209452]\n",
      "loss: 0.000021  [172800/209452]\n",
      "loss: 0.000227  [176000/209452]\n",
      "loss: 0.001632  [179200/209452]\n",
      "loss: 0.000967  [182400/209452]\n",
      "loss: 0.000067  [185600/209452]\n",
      "loss: 0.000077  [188800/209452]\n",
      "loss: 0.000161  [192000/209452]\n",
      "loss: 0.000337  [195200/209452]\n",
      "loss: 0.000045  [198400/209452]\n",
      "loss: 0.000115  [201600/209452]\n",
      "loss: 0.000116  [204800/209452]\n",
      "loss: 0.000174  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002861 \n",
      "\n",
      "Epoch 68\n",
      "---------------------------\n",
      "loss: 0.006228  [ 3200/209452]\n",
      "loss: 0.000061  [ 6400/209452]\n",
      "loss: 0.000319  [ 9600/209452]\n",
      "loss: 0.000231  [12800/209452]\n",
      "loss: 0.001739  [16000/209452]\n",
      "loss: 0.000831  [19200/209452]\n",
      "loss: 0.000057  [22400/209452]\n",
      "loss: 0.000076  [25600/209452]\n",
      "loss: 0.000260  [28800/209452]\n",
      "loss: 0.000000  [32000/209452]\n",
      "loss: 0.000006  [35200/209452]\n",
      "loss: 0.000062  [38400/209452]\n",
      "loss: 0.000035  [41600/209452]\n",
      "loss: 0.000024  [44800/209452]\n",
      "loss: 0.000306  [48000/209452]\n",
      "loss: 0.000074  [51200/209452]\n",
      "loss: 0.000070  [54400/209452]\n",
      "loss: 0.000291  [57600/209452]\n",
      "loss: 0.000053  [60800/209452]\n",
      "loss: 0.000077  [64000/209452]\n",
      "loss: 0.000050  [67200/209452]\n",
      "loss: 0.000550  [70400/209452]\n",
      "loss: 0.000423  [73600/209452]\n",
      "loss: 0.000105  [76800/209452]\n",
      "loss: 0.000265  [80000/209452]\n",
      "loss: 0.000854  [83200/209452]\n",
      "loss: 0.000037  [86400/209452]\n",
      "loss: 0.001057  [89600/209452]\n",
      "loss: 0.000266  [92800/209452]\n",
      "loss: 0.000101  [96000/209452]\n",
      "loss: 0.000627  [99200/209452]\n",
      "loss: 0.000608  [102400/209452]\n",
      "loss: 0.000095  [105600/209452]\n",
      "loss: 0.000021  [108800/209452]\n",
      "loss: 0.000083  [112000/209452]\n",
      "loss: 0.000499  [115200/209452]\n",
      "loss: 0.000122  [118400/209452]\n",
      "loss: 0.000101  [121600/209452]\n",
      "loss: 0.000038  [124800/209452]\n",
      "loss: 0.000086  [128000/209452]\n",
      "loss: 0.000080  [131200/209452]\n",
      "loss: 0.000108  [134400/209452]\n",
      "loss: 0.000026  [137600/209452]\n",
      "loss: 0.000216  [140800/209452]\n",
      "loss: 0.000005  [144000/209452]\n",
      "loss: 0.000081  [147200/209452]\n",
      "loss: 0.000023  [150400/209452]\n",
      "loss: 0.002203  [153600/209452]\n",
      "loss: 0.003827  [156800/209452]\n",
      "loss: 0.000010  [160000/209452]\n",
      "loss: 0.000044  [163200/209452]\n",
      "loss: 0.001501  [166400/209452]\n",
      "loss: 0.000034  [169600/209452]\n",
      "loss: 0.000205  [172800/209452]\n",
      "loss: 0.000115  [176000/209452]\n",
      "loss: 0.000949  [179200/209452]\n",
      "loss: 0.000104  [182400/209452]\n",
      "loss: 0.000074  [185600/209452]\n",
      "loss: 0.000214  [188800/209452]\n",
      "loss: 0.001123  [192000/209452]\n",
      "loss: 0.000836  [195200/209452]\n",
      "loss: 0.000200  [198400/209452]\n",
      "loss: 0.000283  [201600/209452]\n",
      "loss: 0.000033  [204800/209452]\n",
      "loss: 0.000052  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 69\n",
      "---------------------------\n",
      "loss: 0.000049  [ 3200/209452]\n",
      "loss: 0.000610  [ 6400/209452]\n",
      "loss: 0.000108  [ 9600/209452]\n",
      "loss: 0.000065  [12800/209452]\n",
      "loss: 0.000003  [16000/209452]\n",
      "loss: 0.000154  [19200/209452]\n",
      "loss: 0.000076  [22400/209452]\n",
      "loss: 0.000039  [25600/209452]\n",
      "loss: 0.000030  [28800/209452]\n",
      "loss: 0.000035  [32000/209452]\n",
      "loss: 0.000105  [35200/209452]\n",
      "loss: 0.000111  [38400/209452]\n",
      "loss: 0.000153  [41600/209452]\n",
      "loss: 0.000378  [44800/209452]\n",
      "loss: 0.000034  [48000/209452]\n",
      "loss: 0.000001  [51200/209452]\n",
      "loss: 0.000153  [54400/209452]\n",
      "loss: 0.000320  [57600/209452]\n",
      "loss: 0.000072  [60800/209452]\n",
      "loss: 0.000015  [64000/209452]\n",
      "loss: 0.000098  [67200/209452]\n",
      "loss: 0.000281  [70400/209452]\n",
      "loss: 0.000050  [73600/209452]\n",
      "loss: 0.000026  [76800/209452]\n",
      "loss: 0.000192  [80000/209452]\n",
      "loss: 0.000019  [83200/209452]\n",
      "loss: 0.000242  [86400/209452]\n",
      "loss: 0.000016  [89600/209452]\n",
      "loss: 0.000158  [92800/209452]\n",
      "loss: 0.000209  [96000/209452]\n",
      "loss: 0.000168  [99200/209452]\n",
      "loss: 0.000209  [102400/209452]\n",
      "loss: 0.000034  [105600/209452]\n",
      "loss: 0.000011  [108800/209452]\n",
      "loss: 0.000720  [112000/209452]\n",
      "loss: 0.000057  [115200/209452]\n",
      "loss: 0.000178  [118400/209452]\n",
      "loss: 0.000045  [121600/209452]\n",
      "loss: 0.000958  [124800/209452]\n",
      "loss: 0.000039  [128000/209452]\n",
      "loss: 0.000061  [131200/209452]\n",
      "loss: 0.000447  [134400/209452]\n",
      "loss: 0.000045  [137600/209452]\n",
      "loss: 0.000031  [140800/209452]\n",
      "loss: 0.000014  [144000/209452]\n",
      "loss: 0.000012  [147200/209452]\n",
      "loss: 0.000051  [150400/209452]\n",
      "loss: 0.000113  [153600/209452]\n",
      "loss: 0.000820  [156800/209452]\n",
      "loss: 0.000005  [160000/209452]\n",
      "loss: 0.000060  [163200/209452]\n",
      "loss: 0.000101  [166400/209452]\n",
      "loss: 0.000095  [169600/209452]\n",
      "loss: 0.000025  [172800/209452]\n",
      "loss: 0.000176  [176000/209452]\n",
      "loss: 0.000005  [179200/209452]\n",
      "loss: 0.000092  [182400/209452]\n",
      "loss: 0.000115  [185600/209452]\n",
      "loss: 0.000382  [188800/209452]\n",
      "loss: 0.000171  [192000/209452]\n",
      "loss: 0.003141  [195200/209452]\n",
      "loss: 0.000277  [198400/209452]\n",
      "loss: 0.000305  [201600/209452]\n",
      "loss: 0.000375  [204800/209452]\n",
      "loss: 0.000063  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002867 \n",
      "\n",
      "Epoch 70\n",
      "---------------------------\n",
      "loss: 0.000037  [ 3200/209452]\n",
      "loss: 0.000025  [ 6400/209452]\n",
      "loss: 0.000071  [ 9600/209452]\n",
      "loss: 0.000881  [12800/209452]\n",
      "loss: 0.000033  [16000/209452]\n",
      "loss: 0.000066  [19200/209452]\n",
      "loss: 0.000839  [22400/209452]\n",
      "loss: 0.000036  [25600/209452]\n",
      "loss: 0.000183  [28800/209452]\n",
      "loss: 0.000447  [32000/209452]\n",
      "loss: 0.000058  [35200/209452]\n",
      "loss: 0.000534  [38400/209452]\n",
      "loss: 0.000123  [41600/209452]\n",
      "loss: 0.000221  [44800/209452]\n",
      "loss: 0.000018  [48000/209452]\n",
      "loss: 0.000430  [51200/209452]\n",
      "loss: 0.000030  [54400/209452]\n",
      "loss: 0.000261  [57600/209452]\n",
      "loss: 0.000067  [60800/209452]\n",
      "loss: 0.000030  [64000/209452]\n",
      "loss: 0.000117  [67200/209452]\n",
      "loss: 0.000328  [70400/209452]\n",
      "loss: 0.000008  [73600/209452]\n",
      "loss: 0.000001  [76800/209452]\n",
      "loss: 0.000191  [80000/209452]\n",
      "loss: 0.000109  [83200/209452]\n",
      "loss: 0.000148  [86400/209452]\n",
      "loss: 0.000024  [89600/209452]\n",
      "loss: 0.000081  [92800/209452]\n",
      "loss: 0.000024  [96000/209452]\n",
      "loss: 0.000043  [99200/209452]\n",
      "loss: 0.000094  [102400/209452]\n",
      "loss: 0.000425  [105600/209452]\n",
      "loss: 0.000065  [108800/209452]\n",
      "loss: 0.000034  [112000/209452]\n",
      "loss: 0.000022  [115200/209452]\n",
      "loss: 0.000058  [118400/209452]\n",
      "loss: 0.000806  [121600/209452]\n",
      "loss: 0.000050  [124800/209452]\n",
      "loss: 0.000061  [128000/209452]\n",
      "loss: 0.000051  [131200/209452]\n",
      "loss: 0.000170  [134400/209452]\n",
      "loss: 0.001291  [137600/209452]\n",
      "loss: 0.003122  [140800/209452]\n",
      "loss: 0.000654  [144000/209452]\n",
      "loss: 0.000043  [147200/209452]\n",
      "loss: 0.001234  [150400/209452]\n",
      "loss: 0.000278  [153600/209452]\n",
      "loss: 0.000016  [156800/209452]\n",
      "loss: 0.000052  [160000/209452]\n",
      "loss: 0.000054  [163200/209452]\n",
      "loss: 0.000201  [166400/209452]\n",
      "loss: 0.000045  [169600/209452]\n",
      "loss: 0.000084  [172800/209452]\n",
      "loss: 0.000009  [176000/209452]\n",
      "loss: 0.000625  [179200/209452]\n",
      "loss: 0.000016  [182400/209452]\n",
      "loss: 0.000008  [185600/209452]\n",
      "loss: 0.000441  [188800/209452]\n",
      "loss: 0.000090  [192000/209452]\n",
      "loss: 0.000182  [195200/209452]\n",
      "loss: 0.000035  [198400/209452]\n",
      "loss: 0.000336  [201600/209452]\n",
      "loss: 0.000061  [204800/209452]\n",
      "loss: 0.000203  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002871 \n",
      "\n",
      "Epoch 71\n",
      "---------------------------\n",
      "loss: 0.000245  [ 3200/209452]\n",
      "loss: 0.000165  [ 6400/209452]\n",
      "loss: 0.000054  [ 9600/209452]\n",
      "loss: 0.000044  [12800/209452]\n",
      "loss: 0.000963  [16000/209452]\n",
      "loss: 0.000051  [19200/209452]\n",
      "loss: 0.000064  [22400/209452]\n",
      "loss: 0.000032  [25600/209452]\n",
      "loss: 0.000129  [28800/209452]\n",
      "loss: 0.000106  [32000/209452]\n",
      "loss: 0.000674  [35200/209452]\n",
      "loss: 0.000106  [38400/209452]\n",
      "loss: 0.000085  [41600/209452]\n",
      "loss: 0.001138  [44800/209452]\n",
      "loss: 0.000094  [48000/209452]\n",
      "loss: 0.000097  [51200/209452]\n",
      "loss: 0.000042  [54400/209452]\n",
      "loss: 0.000140  [57600/209452]\n",
      "loss: 0.000280  [60800/209452]\n",
      "loss: 0.000043  [64000/209452]\n",
      "loss: 0.001464  [67200/209452]\n",
      "loss: 0.002993  [70400/209452]\n",
      "loss: 0.000035  [73600/209452]\n",
      "loss: 0.000073  [76800/209452]\n",
      "loss: 0.000066  [80000/209452]\n",
      "loss: 0.000068  [83200/209452]\n",
      "loss: 0.000050  [86400/209452]\n",
      "loss: 0.000676  [89600/209452]\n",
      "loss: 0.000005  [92800/209452]\n",
      "loss: 0.000137  [96000/209452]\n",
      "loss: 0.000092  [99200/209452]\n",
      "loss: 0.000781  [102400/209452]\n",
      "loss: 0.000669  [105600/209452]\n",
      "loss: 0.000013  [108800/209452]\n",
      "loss: 0.000134  [112000/209452]\n",
      "loss: 0.000007  [115200/209452]\n",
      "loss: 0.000116  [118400/209452]\n",
      "loss: 0.000756  [121600/209452]\n",
      "loss: 0.000043  [124800/209452]\n",
      "loss: 0.000196  [128000/209452]\n",
      "loss: 0.000034  [131200/209452]\n",
      "loss: 0.000042  [134400/209452]\n",
      "loss: 0.000044  [137600/209452]\n",
      "loss: 0.000056  [140800/209452]\n",
      "loss: 0.000077  [144000/209452]\n",
      "loss: 0.000095  [147200/209452]\n",
      "loss: 0.000068  [150400/209452]\n",
      "loss: 0.000046  [153600/209452]\n",
      "loss: 0.000096  [156800/209452]\n",
      "loss: 0.000017  [160000/209452]\n",
      "loss: 0.000021  [163200/209452]\n",
      "loss: 0.000497  [166400/209452]\n",
      "loss: 0.000056  [169600/209452]\n",
      "loss: 0.000182  [172800/209452]\n",
      "loss: 0.000349  [176000/209452]\n",
      "loss: 0.000066  [179200/209452]\n",
      "loss: 0.000005  [182400/209452]\n",
      "loss: 0.002298  [185600/209452]\n",
      "loss: 0.000053  [188800/209452]\n",
      "loss: 0.000041  [192000/209452]\n",
      "loss: 0.000069  [195200/209452]\n",
      "loss: 0.000020  [198400/209452]\n",
      "loss: 0.001161  [201600/209452]\n",
      "loss: 0.000017  [204800/209452]\n",
      "loss: 0.000235  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 72\n",
      "---------------------------\n",
      "loss: 0.000037  [ 3200/209452]\n",
      "loss: 0.000067  [ 6400/209452]\n",
      "loss: 0.006529  [ 9600/209452]\n",
      "loss: 0.000684  [12800/209452]\n",
      "loss: 0.000252  [16000/209452]\n",
      "loss: 0.000072  [19200/209452]\n",
      "loss: 0.000125  [22400/209452]\n",
      "loss: 0.000161  [25600/209452]\n",
      "loss: 0.000014  [28800/209452]\n",
      "loss: 0.000038  [32000/209452]\n",
      "loss: 0.000130  [35200/209452]\n",
      "loss: 0.000070  [38400/209452]\n",
      "loss: 0.002230  [41600/209452]\n",
      "loss: 0.000087  [44800/209452]\n",
      "loss: 0.000064  [48000/209452]\n",
      "loss: 0.000018  [51200/209452]\n",
      "loss: 0.000106  [54400/209452]\n",
      "loss: 0.000070  [57600/209452]\n",
      "loss: 0.000102  [60800/209452]\n",
      "loss: 0.002149  [64000/209452]\n",
      "loss: 0.000034  [67200/209452]\n",
      "loss: 0.000432  [70400/209452]\n",
      "loss: 0.000127  [73600/209452]\n",
      "loss: 0.000078  [76800/209452]\n",
      "loss: 0.000062  [80000/209452]\n",
      "loss: 0.000048  [83200/209452]\n",
      "loss: 0.000025  [86400/209452]\n",
      "loss: 0.000115  [89600/209452]\n",
      "loss: 0.000240  [92800/209452]\n",
      "loss: 0.000082  [96000/209452]\n",
      "loss: 0.000308  [99200/209452]\n",
      "loss: 0.001100  [102400/209452]\n",
      "loss: 0.005451  [105600/209452]\n",
      "loss: 0.000237  [108800/209452]\n",
      "loss: 0.000252  [112000/209452]\n",
      "loss: 0.000014  [115200/209452]\n",
      "loss: 0.000055  [118400/209452]\n",
      "loss: 0.000041  [121600/209452]\n",
      "loss: 0.000095  [124800/209452]\n",
      "loss: 0.000120  [128000/209452]\n",
      "loss: 0.000169  [131200/209452]\n",
      "loss: 0.000178  [134400/209452]\n",
      "loss: 0.000025  [137600/209452]\n",
      "loss: 0.000102  [140800/209452]\n",
      "loss: 0.000016  [144000/209452]\n",
      "loss: 0.000041  [147200/209452]\n",
      "loss: 0.000036  [150400/209452]\n",
      "loss: 0.000335  [153600/209452]\n",
      "loss: 0.002601  [156800/209452]\n",
      "loss: 0.000005  [160000/209452]\n",
      "loss: 0.000282  [163200/209452]\n",
      "loss: 0.000080  [166400/209452]\n",
      "loss: 0.000136  [169600/209452]\n",
      "loss: 0.000109  [172800/209452]\n",
      "loss: 0.000042  [176000/209452]\n",
      "loss: 0.000091  [179200/209452]\n",
      "loss: 0.000071  [182400/209452]\n",
      "loss: 0.000109  [185600/209452]\n",
      "loss: 0.000035  [188800/209452]\n",
      "loss: 0.000013  [192000/209452]\n",
      "loss: 0.000288  [195200/209452]\n",
      "loss: 0.000025  [198400/209452]\n",
      "loss: 0.000196  [201600/209452]\n",
      "loss: 0.000102  [204800/209452]\n",
      "loss: 0.000047  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002657 \n",
      "\n",
      "Epoch 73\n",
      "---------------------------\n",
      "loss: 0.000345  [ 3200/209452]\n",
      "loss: 0.000047  [ 6400/209452]\n",
      "loss: 0.000071  [ 9600/209452]\n",
      "loss: 0.000125  [12800/209452]\n",
      "loss: 0.000016  [16000/209452]\n",
      "loss: 0.000070  [19200/209452]\n",
      "loss: 0.001185  [22400/209452]\n",
      "loss: 0.000017  [25600/209452]\n",
      "loss: 0.001198  [28800/209452]\n",
      "loss: 0.000010  [32000/209452]\n",
      "loss: 0.000032  [35200/209452]\n",
      "loss: 0.000109  [38400/209452]\n",
      "loss: 0.000014  [41600/209452]\n",
      "loss: 0.000488  [44800/209452]\n",
      "loss: 0.000861  [48000/209452]\n",
      "loss: 0.000956  [51200/209452]\n",
      "loss: 0.000072  [54400/209452]\n",
      "loss: 0.001876  [57600/209452]\n",
      "loss: 0.000008  [60800/209452]\n",
      "loss: 0.000129  [64000/209452]\n",
      "loss: 0.001349  [67200/209452]\n",
      "loss: 0.000042  [70400/209452]\n",
      "loss: 0.000019  [73600/209452]\n",
      "loss: 0.000105  [76800/209452]\n",
      "loss: 0.000119  [80000/209452]\n",
      "loss: 0.000029  [83200/209452]\n",
      "loss: 0.000462  [86400/209452]\n",
      "loss: 0.000065  [89600/209452]\n",
      "loss: 0.000252  [92800/209452]\n",
      "loss: 0.000061  [96000/209452]\n",
      "loss: 0.000021  [99200/209452]\n",
      "loss: 0.000073  [102400/209452]\n",
      "loss: 0.000181  [105600/209452]\n",
      "loss: 0.000059  [108800/209452]\n",
      "loss: 0.000182  [112000/209452]\n",
      "loss: 0.000042  [115200/209452]\n",
      "loss: 0.000054  [118400/209452]\n",
      "loss: 0.000389  [121600/209452]\n",
      "loss: 0.000591  [124800/209452]\n",
      "loss: 0.000225  [128000/209452]\n",
      "loss: 0.000022  [131200/209452]\n",
      "loss: 0.000107  [134400/209452]\n",
      "loss: 0.000099  [137600/209452]\n",
      "loss: 0.000033  [140800/209452]\n",
      "loss: 0.000081  [144000/209452]\n",
      "loss: 0.000016  [147200/209452]\n",
      "loss: 0.000151  [150400/209452]\n",
      "loss: 0.001084  [153600/209452]\n",
      "loss: 0.000023  [156800/209452]\n",
      "loss: 0.000141  [160000/209452]\n",
      "loss: 0.000003  [163200/209452]\n",
      "loss: 0.000032  [166400/209452]\n",
      "loss: 0.000352  [169600/209452]\n",
      "loss: 0.000066  [172800/209452]\n",
      "loss: 0.000059  [176000/209452]\n",
      "loss: 0.000104  [179200/209452]\n",
      "loss: 0.000056  [182400/209452]\n",
      "loss: 0.000041  [185600/209452]\n",
      "loss: 0.000314  [188800/209452]\n",
      "loss: 0.000037  [192000/209452]\n",
      "loss: 0.000426  [195200/209452]\n",
      "loss: 0.000035  [198400/209452]\n",
      "loss: 0.000037  [201600/209452]\n",
      "loss: 0.000014  [204800/209452]\n",
      "loss: 0.000314  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002679 \n",
      "\n",
      "Epoch 74\n",
      "---------------------------\n",
      "loss: 0.000156  [ 3200/209452]\n",
      "loss: 0.000177  [ 6400/209452]\n",
      "loss: 0.000059  [ 9600/209452]\n",
      "loss: 0.000055  [12800/209452]\n",
      "loss: 0.000110  [16000/209452]\n",
      "loss: 0.000534  [19200/209452]\n",
      "loss: 0.000023  [22400/209452]\n",
      "loss: 0.000130  [25600/209452]\n",
      "loss: 0.000069  [28800/209452]\n",
      "loss: 0.000017  [32000/209452]\n",
      "loss: 0.000189  [35200/209452]\n",
      "loss: 0.000142  [38400/209452]\n",
      "loss: 0.000231  [41600/209452]\n",
      "loss: 0.000095  [44800/209452]\n",
      "loss: 0.000047  [48000/209452]\n",
      "loss: 0.000042  [51200/209452]\n",
      "loss: 0.000051  [54400/209452]\n",
      "loss: 0.000645  [57600/209452]\n",
      "loss: 0.000037  [60800/209452]\n",
      "loss: 0.000014  [64000/209452]\n",
      "loss: 0.000344  [67200/209452]\n",
      "loss: 0.000335  [70400/209452]\n",
      "loss: 0.000211  [73600/209452]\n",
      "loss: 0.000006  [76800/209452]\n",
      "loss: 0.000006  [80000/209452]\n",
      "loss: 0.000110  [83200/209452]\n",
      "loss: 0.000179  [86400/209452]\n",
      "loss: 0.000197  [89600/209452]\n",
      "loss: 0.000181  [92800/209452]\n",
      "loss: 0.001941  [96000/209452]\n",
      "loss: 0.000032  [99200/209452]\n",
      "loss: 0.000060  [102400/209452]\n",
      "loss: 0.000063  [105600/209452]\n",
      "loss: 0.000036  [108800/209452]\n",
      "loss: 0.000006  [112000/209452]\n",
      "loss: 0.000031  [115200/209452]\n",
      "loss: 0.001740  [118400/209452]\n",
      "loss: 0.000429  [121600/209452]\n",
      "loss: 0.000019  [124800/209452]\n",
      "loss: 0.001695  [128000/209452]\n",
      "loss: 0.000154  [131200/209452]\n",
      "loss: 0.000281  [134400/209452]\n",
      "loss: 0.000051  [137600/209452]\n",
      "loss: 0.000038  [140800/209452]\n",
      "loss: 0.000159  [144000/209452]\n",
      "loss: 0.000188  [147200/209452]\n",
      "loss: 0.000092  [150400/209452]\n",
      "loss: 0.000528  [153600/209452]\n",
      "loss: 0.000057  [156800/209452]\n",
      "loss: 0.000012  [160000/209452]\n",
      "loss: 0.000170  [163200/209452]\n",
      "loss: 0.000021  [166400/209452]\n",
      "loss: 0.000052  [169600/209452]\n",
      "loss: 0.000062  [172800/209452]\n",
      "loss: 0.000010  [176000/209452]\n",
      "loss: 0.000042  [179200/209452]\n",
      "loss: 0.000047  [182400/209452]\n",
      "loss: 0.000129  [185600/209452]\n",
      "loss: 0.000024  [188800/209452]\n",
      "loss: 0.000012  [192000/209452]\n",
      "loss: 0.000100  [195200/209452]\n",
      "loss: 0.000195  [198400/209452]\n",
      "loss: 0.000039  [201600/209452]\n",
      "loss: 0.000059  [204800/209452]\n",
      "loss: 0.000011  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002704 \n",
      "\n",
      "Epoch 75\n",
      "---------------------------\n",
      "loss: 0.000051  [ 3200/209452]\n",
      "loss: 0.000515  [ 6400/209452]\n",
      "loss: 0.000153  [ 9600/209452]\n",
      "loss: 0.000178  [12800/209452]\n",
      "loss: 0.000135  [16000/209452]\n",
      "loss: 0.000459  [19200/209452]\n",
      "loss: 0.000169  [22400/209452]\n",
      "loss: 0.000084  [25600/209452]\n",
      "loss: 0.000290  [28800/209452]\n",
      "loss: 0.001155  [32000/209452]\n",
      "loss: 0.000182  [35200/209452]\n",
      "loss: 0.000024  [38400/209452]\n",
      "loss: 0.002644  [41600/209452]\n",
      "loss: 0.000197  [44800/209452]\n",
      "loss: 0.000113  [48000/209452]\n",
      "loss: 0.000076  [51200/209452]\n",
      "loss: 0.000269  [54400/209452]\n",
      "loss: 0.000007  [57600/209452]\n",
      "loss: 0.000050  [60800/209452]\n",
      "loss: 0.000070  [64000/209452]\n",
      "loss: 0.000069  [67200/209452]\n",
      "loss: 0.000286  [70400/209452]\n",
      "loss: 0.000021  [73600/209452]\n",
      "loss: 0.000118  [76800/209452]\n",
      "loss: 0.000007  [80000/209452]\n",
      "loss: 0.000099  [83200/209452]\n",
      "loss: 0.000033  [86400/209452]\n",
      "loss: 0.000070  [89600/209452]\n",
      "loss: 0.000015  [92800/209452]\n",
      "loss: 0.000086  [96000/209452]\n",
      "loss: 0.000027  [99200/209452]\n",
      "loss: 0.000201  [102400/209452]\n",
      "loss: 0.000026  [105600/209452]\n",
      "loss: 0.000014  [108800/209452]\n",
      "loss: 0.000040  [112000/209452]\n",
      "loss: 0.000081  [115200/209452]\n",
      "loss: 0.000034  [118400/209452]\n",
      "loss: 0.000119  [121600/209452]\n",
      "loss: 0.000199  [124800/209452]\n",
      "loss: 0.000149  [128000/209452]\n",
      "loss: 0.000046  [131200/209452]\n",
      "loss: 0.000084  [134400/209452]\n",
      "loss: 0.000005  [137600/209452]\n",
      "loss: 0.000116  [140800/209452]\n",
      "loss: 0.000298  [144000/209452]\n",
      "loss: 0.000149  [147200/209452]\n",
      "loss: 0.000027  [150400/209452]\n",
      "loss: 0.000032  [153600/209452]\n",
      "loss: 0.000012  [156800/209452]\n",
      "loss: 0.000861  [160000/209452]\n",
      "loss: 0.000124  [163200/209452]\n",
      "loss: 0.000198  [166400/209452]\n",
      "loss: 0.000111  [169600/209452]\n",
      "loss: 0.000020  [172800/209452]\n",
      "loss: 0.000297  [176000/209452]\n",
      "loss: 0.000116  [179200/209452]\n",
      "loss: 0.000192  [182400/209452]\n",
      "loss: 0.000031  [185600/209452]\n",
      "loss: 0.000134  [188800/209452]\n",
      "loss: 0.000214  [192000/209452]\n",
      "loss: 0.000286  [195200/209452]\n",
      "loss: 0.000057  [198400/209452]\n",
      "loss: 0.000657  [201600/209452]\n",
      "loss: 0.000021  [204800/209452]\n",
      "loss: 0.000013  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 76\n",
      "---------------------------\n",
      "loss: 0.000013  [ 3200/209452]\n",
      "loss: 0.000008  [ 6400/209452]\n",
      "loss: 0.000289  [ 9600/209452]\n",
      "loss: 0.000087  [12800/209452]\n",
      "loss: 0.000026  [16000/209452]\n",
      "loss: 0.000028  [19200/209452]\n",
      "loss: 0.000039  [22400/209452]\n",
      "loss: 0.000061  [25600/209452]\n",
      "loss: 0.000258  [28800/209452]\n",
      "loss: 0.000033  [32000/209452]\n",
      "loss: 0.000214  [35200/209452]\n",
      "loss: 0.000035  [38400/209452]\n",
      "loss: 0.000064  [41600/209452]\n",
      "loss: 0.000034  [44800/209452]\n",
      "loss: 0.002093  [48000/209452]\n",
      "loss: 0.000240  [51200/209452]\n",
      "loss: 0.000051  [54400/209452]\n",
      "loss: 0.000134  [57600/209452]\n",
      "loss: 0.000031  [60800/209452]\n",
      "loss: 0.000057  [64000/209452]\n",
      "loss: 0.000048  [67200/209452]\n",
      "loss: 0.001913  [70400/209452]\n",
      "loss: 0.000012  [73600/209452]\n",
      "loss: 0.000020  [76800/209452]\n",
      "loss: 0.000110  [80000/209452]\n",
      "loss: 0.000125  [83200/209452]\n",
      "loss: 0.000078  [86400/209452]\n",
      "loss: 0.000042  [89600/209452]\n",
      "loss: 0.000023  [92800/209452]\n",
      "loss: 0.000039  [96000/209452]\n",
      "loss: 0.000878  [99200/209452]\n",
      "loss: 0.000019  [102400/209452]\n",
      "loss: 0.000515  [105600/209452]\n",
      "loss: 0.002887  [108800/209452]\n",
      "loss: 0.000054  [112000/209452]\n",
      "loss: 0.000448  [115200/209452]\n",
      "loss: 0.000096  [118400/209452]\n",
      "loss: 0.000014  [121600/209452]\n",
      "loss: 0.000032  [124800/209452]\n",
      "loss: 0.000024  [128000/209452]\n",
      "loss: 0.000282  [131200/209452]\n",
      "loss: 0.000117  [134400/209452]\n",
      "loss: 0.000173  [137600/209452]\n",
      "loss: 0.000234  [140800/209452]\n",
      "loss: 0.000042  [144000/209452]\n",
      "loss: 0.000151  [147200/209452]\n",
      "loss: 0.000035  [150400/209452]\n",
      "loss: 0.000012  [153600/209452]\n",
      "loss: 0.000028  [156800/209452]\n",
      "loss: 0.002387  [160000/209452]\n",
      "loss: 0.000016  [163200/209452]\n",
      "loss: 0.000117  [166400/209452]\n",
      "loss: 0.000020  [169600/209452]\n",
      "loss: 0.000038  [172800/209452]\n",
      "loss: 0.000091  [176000/209452]\n",
      "loss: 0.000343  [179200/209452]\n",
      "loss: 0.000033  [182400/209452]\n",
      "loss: 0.000795  [185600/209452]\n",
      "loss: 0.000464  [188800/209452]\n",
      "loss: 0.000136  [192000/209452]\n",
      "loss: 0.000029  [195200/209452]\n",
      "loss: 0.000026  [198400/209452]\n",
      "loss: 0.000136  [201600/209452]\n",
      "loss: 0.001286  [204800/209452]\n",
      "loss: 0.000017  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 77\n",
      "---------------------------\n",
      "loss: 0.000049  [ 3200/209452]\n",
      "loss: 0.000576  [ 6400/209452]\n",
      "loss: 0.000004  [ 9600/209452]\n",
      "loss: 0.000021  [12800/209452]\n",
      "loss: 0.000241  [16000/209452]\n",
      "loss: 0.000093  [19200/209452]\n",
      "loss: 0.000101  [22400/209452]\n",
      "loss: 0.000044  [25600/209452]\n",
      "loss: 0.000096  [28800/209452]\n",
      "loss: 0.000556  [32000/209452]\n",
      "loss: 0.000035  [35200/209452]\n",
      "loss: 0.000022  [38400/209452]\n",
      "loss: 0.000112  [41600/209452]\n",
      "loss: 0.000052  [44800/209452]\n",
      "loss: 0.000023  [48000/209452]\n",
      "loss: 0.000053  [51200/209452]\n",
      "loss: 0.000009  [54400/209452]\n",
      "loss: 0.000040  [57600/209452]\n",
      "loss: 0.000052  [60800/209452]\n",
      "loss: 0.000402  [64000/209452]\n",
      "loss: 0.000044  [67200/209452]\n",
      "loss: 0.000012  [70400/209452]\n",
      "loss: 0.000241  [73600/209452]\n",
      "loss: 0.000036  [76800/209452]\n",
      "loss: 0.000649  [80000/209452]\n",
      "loss: 0.000152  [83200/209452]\n",
      "loss: 0.000097  [86400/209452]\n",
      "loss: 0.000708  [89600/209452]\n",
      "loss: 0.000051  [92800/209452]\n",
      "loss: 0.000034  [96000/209452]\n",
      "loss: 0.000053  [99200/209452]\n",
      "loss: 0.000346  [102400/209452]\n",
      "loss: 0.000114  [105600/209452]\n",
      "loss: 0.000019  [108800/209452]\n",
      "loss: 0.000062  [112000/209452]\n",
      "loss: 0.000056  [115200/209452]\n",
      "loss: 0.000103  [118400/209452]\n",
      "loss: 0.000029  [121600/209452]\n",
      "loss: 0.000049  [124800/209452]\n",
      "loss: 0.000013  [128000/209452]\n",
      "loss: 0.000096  [131200/209452]\n",
      "loss: 0.000079  [134400/209452]\n",
      "loss: 0.000141  [137600/209452]\n",
      "loss: 0.000034  [140800/209452]\n",
      "loss: 0.000416  [144000/209452]\n",
      "loss: 0.000058  [147200/209452]\n",
      "loss: 0.000021  [150400/209452]\n",
      "loss: 0.000062  [153600/209452]\n",
      "loss: 0.000068  [156800/209452]\n",
      "loss: 0.000082  [160000/209452]\n",
      "loss: 0.002598  [163200/209452]\n",
      "loss: 0.000173  [166400/209452]\n",
      "loss: 0.000076  [169600/209452]\n",
      "loss: 0.000105  [172800/209452]\n",
      "loss: 0.000426  [176000/209452]\n",
      "loss: 0.000418  [179200/209452]\n",
      "loss: 0.000027  [182400/209452]\n",
      "loss: 0.000019  [185600/209452]\n",
      "loss: 0.000063  [188800/209452]\n",
      "loss: 0.000080  [192000/209452]\n",
      "loss: 0.000001  [195200/209452]\n",
      "loss: 0.000023  [198400/209452]\n",
      "loss: 0.000064  [201600/209452]\n",
      "loss: 0.000022  [204800/209452]\n",
      "loss: 0.000535  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 78\n",
      "---------------------------\n",
      "loss: 0.000258  [ 3200/209452]\n",
      "loss: 0.000068  [ 6400/209452]\n",
      "loss: 0.000990  [ 9600/209452]\n",
      "loss: 0.000046  [12800/209452]\n",
      "loss: 0.000062  [16000/209452]\n",
      "loss: 0.000062  [19200/209452]\n",
      "loss: 0.000150  [22400/209452]\n",
      "loss: 0.000072  [25600/209452]\n",
      "loss: 0.000647  [28800/209452]\n",
      "loss: 0.001288  [32000/209452]\n",
      "loss: 0.000308  [35200/209452]\n",
      "loss: 0.000028  [38400/209452]\n",
      "loss: 0.000028  [41600/209452]\n",
      "loss: 0.000128  [44800/209452]\n",
      "loss: 0.000061  [48000/209452]\n",
      "loss: 0.000052  [51200/209452]\n",
      "loss: 0.000675  [54400/209452]\n",
      "loss: 0.000079  [57600/209452]\n",
      "loss: 0.000053  [60800/209452]\n",
      "loss: 0.000017  [64000/209452]\n",
      "loss: 0.000030  [67200/209452]\n",
      "loss: 0.000140  [70400/209452]\n",
      "loss: 0.000058  [73600/209452]\n",
      "loss: 0.000051  [76800/209452]\n",
      "loss: 0.002020  [80000/209452]\n",
      "loss: 0.000045  [83200/209452]\n",
      "loss: 0.000062  [86400/209452]\n",
      "loss: 0.000026  [89600/209452]\n",
      "loss: 0.000059  [92800/209452]\n",
      "loss: 0.000077  [96000/209452]\n",
      "loss: 0.000045  [99200/209452]\n",
      "loss: 0.000069  [102400/209452]\n",
      "loss: 0.000230  [105600/209452]\n",
      "loss: 0.000878  [108800/209452]\n",
      "loss: 0.000224  [112000/209452]\n",
      "loss: 0.000373  [115200/209452]\n",
      "loss: 0.000022  [118400/209452]\n",
      "loss: 0.000064  [121600/209452]\n",
      "loss: 0.000324  [124800/209452]\n",
      "loss: 0.000085  [128000/209452]\n",
      "loss: 0.000042  [131200/209452]\n",
      "loss: 0.000027  [134400/209452]\n",
      "loss: 0.000334  [137600/209452]\n",
      "loss: 0.000085  [140800/209452]\n",
      "loss: 0.000022  [144000/209452]\n",
      "loss: 0.000148  [147200/209452]\n",
      "loss: 0.002376  [150400/209452]\n",
      "loss: 0.000082  [153600/209452]\n",
      "loss: 0.000201  [156800/209452]\n",
      "loss: 0.000034  [160000/209452]\n",
      "loss: 0.000166  [163200/209452]\n",
      "loss: 0.000442  [166400/209452]\n",
      "loss: 0.000273  [169600/209452]\n",
      "loss: 0.000018  [172800/209452]\n",
      "loss: 0.000019  [176000/209452]\n",
      "loss: 0.002835  [179200/209452]\n",
      "loss: 0.000101  [182400/209452]\n",
      "loss: 0.000036  [185600/209452]\n",
      "loss: 0.000203  [188800/209452]\n",
      "loss: 0.000052  [192000/209452]\n",
      "loss: 0.000048  [195200/209452]\n",
      "loss: 0.000057  [198400/209452]\n",
      "loss: 0.001234  [201600/209452]\n",
      "loss: 0.000203  [204800/209452]\n",
      "loss: 0.000061  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002724 \n",
      "\n",
      "Epoch 79\n",
      "---------------------------\n",
      "loss: 0.000004  [ 3200/209452]\n",
      "loss: 0.000003  [ 6400/209452]\n",
      "loss: 0.000059  [ 9600/209452]\n",
      "loss: 0.000180  [12800/209452]\n",
      "loss: 0.000128  [16000/209452]\n",
      "loss: 0.000019  [19200/209452]\n",
      "loss: 0.000161  [22400/209452]\n",
      "loss: 0.000216  [25600/209452]\n",
      "loss: 0.000042  [28800/209452]\n",
      "loss: 0.000177  [32000/209452]\n",
      "loss: 0.000042  [35200/209452]\n",
      "loss: 0.000084  [38400/209452]\n",
      "loss: 0.000013  [41600/209452]\n",
      "loss: 0.000031  [44800/209452]\n",
      "loss: 0.000029  [48000/209452]\n",
      "loss: 0.000014  [51200/209452]\n",
      "loss: 0.000031  [54400/209452]\n",
      "loss: 0.000177  [57600/209452]\n",
      "loss: 0.000046  [60800/209452]\n",
      "loss: 0.000022  [64000/209452]\n",
      "loss: 0.000171  [67200/209452]\n",
      "loss: 0.000640  [70400/209452]\n",
      "loss: 0.000205  [73600/209452]\n",
      "loss: 0.000296  [76800/209452]\n",
      "loss: 0.000106  [80000/209452]\n",
      "loss: 0.000019  [83200/209452]\n",
      "loss: 0.000074  [86400/209452]\n",
      "loss: 0.000163  [89600/209452]\n",
      "loss: 0.001247  [92800/209452]\n",
      "loss: 0.000932  [96000/209452]\n",
      "loss: 0.000048  [99200/209452]\n",
      "loss: 0.000017  [102400/209452]\n",
      "loss: 0.000021  [105600/209452]\n",
      "loss: 0.000265  [108800/209452]\n",
      "loss: 0.000240  [112000/209452]\n",
      "loss: 0.000038  [115200/209452]\n",
      "loss: 0.000050  [118400/209452]\n",
      "loss: 0.000009  [121600/209452]\n",
      "loss: 0.000051  [124800/209452]\n",
      "loss: 0.010238  [128000/209452]\n",
      "loss: 0.001133  [131200/209452]\n",
      "loss: 0.000116  [134400/209452]\n",
      "loss: 0.000056  [137600/209452]\n",
      "loss: 0.000233  [140800/209452]\n",
      "loss: 0.000352  [144000/209452]\n",
      "loss: 0.000098  [147200/209452]\n",
      "loss: 0.000019  [150400/209452]\n",
      "loss: 0.000228  [153600/209452]\n",
      "loss: 0.000399  [156800/209452]\n",
      "loss: 0.000010  [160000/209452]\n",
      "loss: 0.000079  [163200/209452]\n",
      "loss: 0.000755  [166400/209452]\n",
      "loss: 0.000166  [169600/209452]\n",
      "loss: 0.000087  [172800/209452]\n",
      "loss: 0.000482  [176000/209452]\n",
      "loss: 0.000039  [179200/209452]\n",
      "loss: 0.000652  [182400/209452]\n",
      "loss: 0.000034  [185600/209452]\n",
      "loss: 0.000167  [188800/209452]\n",
      "loss: 0.000300  [192000/209452]\n",
      "loss: 0.000012  [195200/209452]\n",
      "loss: 0.000015  [198400/209452]\n",
      "loss: 0.000092  [201600/209452]\n",
      "loss: 0.000066  [204800/209452]\n",
      "loss: 0.000005  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002707 \n",
      "\n",
      "Epoch 80\n",
      "---------------------------\n",
      "loss: 0.000081  [ 3200/209452]\n",
      "loss: 0.000325  [ 6400/209452]\n",
      "loss: 0.000067  [ 9600/209452]\n",
      "loss: 0.002178  [12800/209452]\n",
      "loss: 0.000001  [16000/209452]\n",
      "loss: 0.000309  [19200/209452]\n",
      "loss: 0.000047  [22400/209452]\n",
      "loss: 0.000012  [25600/209452]\n",
      "loss: 0.000220  [28800/209452]\n",
      "loss: 0.000871  [32000/209452]\n",
      "loss: 0.000072  [35200/209452]\n",
      "loss: 0.000033  [38400/209452]\n",
      "loss: 0.000171  [41600/209452]\n",
      "loss: 0.000052  [44800/209452]\n",
      "loss: 0.004852  [48000/209452]\n",
      "loss: 0.000185  [51200/209452]\n",
      "loss: 0.000200  [54400/209452]\n",
      "loss: 0.000007  [57600/209452]\n",
      "loss: 0.000094  [60800/209452]\n",
      "loss: 0.000018  [64000/209452]\n",
      "loss: 0.000019  [67200/209452]\n",
      "loss: 0.000062  [70400/209452]\n",
      "loss: 0.001039  [73600/209452]\n",
      "loss: 0.000049  [76800/209452]\n",
      "loss: 0.000016  [80000/209452]\n",
      "loss: 0.000038  [83200/209452]\n",
      "loss: 0.000082  [86400/209452]\n",
      "loss: 0.000074  [89600/209452]\n",
      "loss: 0.000028  [92800/209452]\n",
      "loss: 0.000448  [96000/209452]\n",
      "loss: 0.000048  [99200/209452]\n",
      "loss: 0.000076  [102400/209452]\n",
      "loss: 0.000692  [105600/209452]\n",
      "loss: 0.000027  [108800/209452]\n",
      "loss: 0.000037  [112000/209452]\n",
      "loss: 0.000660  [115200/209452]\n",
      "loss: 0.000271  [118400/209452]\n",
      "loss: 0.000052  [121600/209452]\n",
      "loss: 0.000034  [124800/209452]\n",
      "loss: 0.000035  [128000/209452]\n",
      "loss: 0.000083  [131200/209452]\n",
      "loss: 0.000191  [134400/209452]\n",
      "loss: 0.000051  [137600/209452]\n",
      "loss: 0.000455  [140800/209452]\n",
      "loss: 0.000077  [144000/209452]\n",
      "loss: 0.000253  [147200/209452]\n",
      "loss: 0.000005  [150400/209452]\n",
      "loss: 0.000116  [153600/209452]\n",
      "loss: 0.000151  [156800/209452]\n",
      "loss: 0.000057  [160000/209452]\n",
      "loss: 0.000024  [163200/209452]\n",
      "loss: 0.000352  [166400/209452]\n",
      "loss: 0.000061  [169600/209452]\n",
      "loss: 0.000108  [172800/209452]\n",
      "loss: 0.000049  [176000/209452]\n",
      "loss: 0.004933  [179200/209452]\n",
      "loss: 0.002910  [182400/209452]\n",
      "loss: 0.000059  [185600/209452]\n",
      "loss: 0.000078  [188800/209452]\n",
      "loss: 0.000009  [192000/209452]\n",
      "loss: 0.000031  [195200/209452]\n",
      "loss: 0.000070  [198400/209452]\n",
      "loss: 0.000473  [201600/209452]\n",
      "loss: 0.000032  [204800/209452]\n",
      "loss: 0.000088  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 81\n",
      "---------------------------\n",
      "loss: 0.000064  [ 3200/209452]\n",
      "loss: 0.000045  [ 6400/209452]\n",
      "loss: 0.000568  [ 9600/209452]\n",
      "loss: 0.000604  [12800/209452]\n",
      "loss: 0.000179  [16000/209452]\n",
      "loss: 0.000042  [19200/209452]\n",
      "loss: 0.000018  [22400/209452]\n",
      "loss: 0.001011  [25600/209452]\n",
      "loss: 0.000002  [28800/209452]\n",
      "loss: 0.000232  [32000/209452]\n",
      "loss: 0.000066  [35200/209452]\n",
      "loss: 0.000058  [38400/209452]\n",
      "loss: 0.000002  [41600/209452]\n",
      "loss: 0.000057  [44800/209452]\n",
      "loss: 0.000015  [48000/209452]\n",
      "loss: 0.000042  [51200/209452]\n",
      "loss: 0.000025  [54400/209452]\n",
      "loss: 0.000032  [57600/209452]\n",
      "loss: 0.001266  [60800/209452]\n",
      "loss: 0.000017  [64000/209452]\n",
      "loss: 0.000026  [67200/209452]\n",
      "loss: 0.000128  [70400/209452]\n",
      "loss: 0.000137  [73600/209452]\n",
      "loss: 0.000017  [76800/209452]\n",
      "loss: 0.000066  [80000/209452]\n",
      "loss: 0.000131  [83200/209452]\n",
      "loss: 0.000090  [86400/209452]\n",
      "loss: 0.000199  [89600/209452]\n",
      "loss: 0.000097  [92800/209452]\n",
      "loss: 0.000104  [96000/209452]\n",
      "loss: 0.000784  [99200/209452]\n",
      "loss: 0.000038  [102400/209452]\n",
      "loss: 0.000103  [105600/209452]\n",
      "loss: 0.000019  [108800/209452]\n",
      "loss: 0.000036  [112000/209452]\n",
      "loss: 0.000058  [115200/209452]\n",
      "loss: 0.000053  [118400/209452]\n",
      "loss: 0.000021  [121600/209452]\n",
      "loss: 0.000014  [124800/209452]\n",
      "loss: 0.000017  [128000/209452]\n",
      "loss: 0.000474  [131200/209452]\n",
      "loss: 0.000912  [134400/209452]\n",
      "loss: 0.000053  [137600/209452]\n",
      "loss: 0.000020  [140800/209452]\n",
      "loss: 0.000094  [144000/209452]\n",
      "loss: 0.000052  [147200/209452]\n",
      "loss: 0.000023  [150400/209452]\n",
      "loss: 0.000024  [153600/209452]\n",
      "loss: 0.000270  [156800/209452]\n",
      "loss: 0.000024  [160000/209452]\n",
      "loss: 0.000124  [163200/209452]\n",
      "loss: 0.000071  [166400/209452]\n",
      "loss: 0.000011  [169600/209452]\n",
      "loss: 0.000139  [172800/209452]\n",
      "loss: 0.000052  [176000/209452]\n",
      "loss: 0.000152  [179200/209452]\n",
      "loss: 0.000490  [182400/209452]\n",
      "loss: 0.005182  [185600/209452]\n",
      "loss: 0.000012  [188800/209452]\n",
      "loss: 0.000014  [192000/209452]\n",
      "loss: 0.000007  [195200/209452]\n",
      "loss: 0.000326  [198400/209452]\n",
      "loss: 0.000063  [201600/209452]\n",
      "loss: 0.000013  [204800/209452]\n",
      "loss: 0.000047  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 82\n",
      "---------------------------\n",
      "loss: 0.000205  [ 3200/209452]\n",
      "loss: 0.000046  [ 6400/209452]\n",
      "loss: 0.000044  [ 9600/209452]\n",
      "loss: 0.000095  [12800/209452]\n",
      "loss: 0.000052  [16000/209452]\n",
      "loss: 0.000163  [19200/209452]\n",
      "loss: 0.000189  [22400/209452]\n",
      "loss: 0.000001  [25600/209452]\n",
      "loss: 0.000040  [28800/209452]\n",
      "loss: 0.000005  [32000/209452]\n",
      "loss: 0.000017  [35200/209452]\n",
      "loss: 0.000054  [38400/209452]\n",
      "loss: 0.000043  [41600/209452]\n",
      "loss: 0.000466  [44800/209452]\n",
      "loss: 0.000029  [48000/209452]\n",
      "loss: 0.000029  [51200/209452]\n",
      "loss: 0.000018  [54400/209452]\n",
      "loss: 0.000237  [57600/209452]\n",
      "loss: 0.000095  [60800/209452]\n",
      "loss: 0.000105  [64000/209452]\n",
      "loss: 0.000168  [67200/209452]\n",
      "loss: 0.000065  [70400/209452]\n",
      "loss: 0.000566  [73600/209452]\n",
      "loss: 0.000103  [76800/209452]\n",
      "loss: 0.000071  [80000/209452]\n",
      "loss: 0.000095  [83200/209452]\n",
      "loss: 0.000068  [86400/209452]\n",
      "loss: 0.000956  [89600/209452]\n",
      "loss: 0.000013  [92800/209452]\n",
      "loss: 0.000057  [96000/209452]\n",
      "loss: 0.000456  [99200/209452]\n",
      "loss: 0.000541  [102400/209452]\n",
      "loss: 0.000095  [105600/209452]\n",
      "loss: 0.000004  [108800/209452]\n",
      "loss: 0.000002  [112000/209452]\n",
      "loss: 0.000112  [115200/209452]\n",
      "loss: 0.000099  [118400/209452]\n",
      "loss: 0.000374  [121600/209452]\n",
      "loss: 0.000477  [124800/209452]\n",
      "loss: 0.000030  [128000/209452]\n",
      "loss: 0.000023  [131200/209452]\n",
      "loss: 0.000064  [134400/209452]\n",
      "loss: 0.000025  [137600/209452]\n",
      "loss: 0.000011  [140800/209452]\n",
      "loss: 0.000066  [144000/209452]\n",
      "loss: 0.000114  [147200/209452]\n",
      "loss: 0.000083  [150400/209452]\n",
      "loss: 0.000058  [153600/209452]\n",
      "loss: 0.000027  [156800/209452]\n",
      "loss: 0.000044  [160000/209452]\n",
      "loss: 0.000195  [163200/209452]\n",
      "loss: 0.000027  [166400/209452]\n",
      "loss: 0.000002  [169600/209452]\n",
      "loss: 0.000001  [172800/209452]\n",
      "loss: 0.000567  [176000/209452]\n",
      "loss: 0.000114  [179200/209452]\n",
      "loss: 0.000002  [182400/209452]\n",
      "loss: 0.000056  [185600/209452]\n",
      "loss: 0.000009  [188800/209452]\n",
      "loss: 0.000093  [192000/209452]\n",
      "loss: 0.000546  [195200/209452]\n",
      "loss: 0.000101  [198400/209452]\n",
      "loss: 0.000025  [201600/209452]\n",
      "loss: 0.000597  [204800/209452]\n",
      "loss: 0.000023  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002764 \n",
      "\n",
      "Epoch 83\n",
      "---------------------------\n",
      "loss: 0.000070  [ 3200/209452]\n",
      "loss: 0.000093  [ 6400/209452]\n",
      "loss: 0.000212  [ 9600/209452]\n",
      "loss: 0.000205  [12800/209452]\n",
      "loss: 0.002687  [16000/209452]\n",
      "loss: 0.000049  [19200/209452]\n",
      "loss: 0.000281  [22400/209452]\n",
      "loss: 0.000165  [25600/209452]\n",
      "loss: 0.000032  [28800/209452]\n",
      "loss: 0.000122  [32000/209452]\n",
      "loss: 0.000024  [35200/209452]\n",
      "loss: 0.000149  [38400/209452]\n",
      "loss: 0.000081  [41600/209452]\n",
      "loss: 0.000018  [44800/209452]\n",
      "loss: 0.000056  [48000/209452]\n",
      "loss: 0.000072  [51200/209452]\n",
      "loss: 0.000045  [54400/209452]\n",
      "loss: 0.000352  [57600/209452]\n",
      "loss: 0.000034  [60800/209452]\n",
      "loss: 0.000327  [64000/209452]\n",
      "loss: 0.000197  [67200/209452]\n",
      "loss: 0.000017  [70400/209452]\n",
      "loss: 0.001755  [73600/209452]\n",
      "loss: 0.000172  [76800/209452]\n",
      "loss: 0.000133  [80000/209452]\n",
      "loss: 0.000036  [83200/209452]\n",
      "loss: 0.000021  [86400/209452]\n",
      "loss: 0.000037  [89600/209452]\n",
      "loss: 0.000180  [92800/209452]\n",
      "loss: 0.000581  [96000/209452]\n",
      "loss: 0.000044  [99200/209452]\n",
      "loss: 0.003131  [102400/209452]\n",
      "loss: 0.000058  [105600/209452]\n",
      "loss: 0.000131  [108800/209452]\n",
      "loss: 0.000220  [112000/209452]\n",
      "loss: 0.000004  [115200/209452]\n",
      "loss: 0.003495  [118400/209452]\n",
      "loss: 0.001344  [121600/209452]\n",
      "loss: 0.000450  [124800/209452]\n",
      "loss: 0.000121  [128000/209452]\n",
      "loss: 0.000053  [131200/209452]\n",
      "loss: 0.000058  [134400/209452]\n",
      "loss: 0.000103  [137600/209452]\n",
      "loss: 0.000081  [140800/209452]\n",
      "loss: 0.000091  [144000/209452]\n",
      "loss: 0.000301  [147200/209452]\n",
      "loss: 0.002533  [150400/209452]\n",
      "loss: 0.000119  [153600/209452]\n",
      "loss: 0.000026  [156800/209452]\n",
      "loss: 0.000265  [160000/209452]\n",
      "loss: 0.000123  [163200/209452]\n",
      "loss: 0.000022  [166400/209452]\n",
      "loss: 0.000272  [169600/209452]\n",
      "loss: 0.000063  [172800/209452]\n",
      "loss: 0.000009  [176000/209452]\n",
      "loss: 0.000067  [179200/209452]\n",
      "loss: 0.000032  [182400/209452]\n",
      "loss: 0.000108  [185600/209452]\n",
      "loss: 0.000065  [188800/209452]\n",
      "loss: 0.000268  [192000/209452]\n",
      "loss: 0.000049  [195200/209452]\n",
      "loss: 0.000056  [198400/209452]\n",
      "loss: 0.000015  [201600/209452]\n",
      "loss: 0.000072  [204800/209452]\n",
      "loss: 0.000019  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002712 \n",
      "\n",
      "Epoch 84\n",
      "---------------------------\n",
      "loss: 0.000091  [ 3200/209452]\n",
      "loss: 0.000078  [ 6400/209452]\n",
      "loss: 0.000015  [ 9600/209452]\n",
      "loss: 0.000232  [12800/209452]\n",
      "loss: 0.000071  [16000/209452]\n",
      "loss: 0.000004  [19200/209452]\n",
      "loss: 0.000508  [22400/209452]\n",
      "loss: 0.000139  [25600/209452]\n",
      "loss: 0.000064  [28800/209452]\n",
      "loss: 0.000024  [32000/209452]\n",
      "loss: 0.002353  [35200/209452]\n",
      "loss: 0.000496  [38400/209452]\n",
      "loss: 0.000364  [41600/209452]\n",
      "loss: 0.000063  [44800/209452]\n",
      "loss: 0.000203  [48000/209452]\n",
      "loss: 0.000069  [51200/209452]\n",
      "loss: 0.000093  [54400/209452]\n",
      "loss: 0.000118  [57600/209452]\n",
      "loss: 0.000039  [60800/209452]\n",
      "loss: 0.000136  [64000/209452]\n",
      "loss: 0.000226  [67200/209452]\n",
      "loss: 0.000007  [70400/209452]\n",
      "loss: 0.000326  [73600/209452]\n",
      "loss: 0.000020  [76800/209452]\n",
      "loss: 0.000075  [80000/209452]\n",
      "loss: 0.000041  [83200/209452]\n",
      "loss: 0.000031  [86400/209452]\n",
      "loss: 0.000036  [89600/209452]\n",
      "loss: 0.000758  [92800/209452]\n",
      "loss: 0.000119  [96000/209452]\n",
      "loss: 0.000035  [99200/209452]\n",
      "loss: 0.000036  [102400/209452]\n",
      "loss: 0.000107  [105600/209452]\n",
      "loss: 0.000011  [108800/209452]\n",
      "loss: 0.000617  [112000/209452]\n",
      "loss: 0.000005  [115200/209452]\n",
      "loss: 0.000045  [118400/209452]\n",
      "loss: 0.000018  [121600/209452]\n",
      "loss: 0.000015  [124800/209452]\n",
      "loss: 0.000205  [128000/209452]\n",
      "loss: 0.000015  [131200/209452]\n",
      "loss: 0.000143  [134400/209452]\n",
      "loss: 0.000102  [137600/209452]\n",
      "loss: 0.000132  [140800/209452]\n",
      "loss: 0.000010  [144000/209452]\n",
      "loss: 0.001281  [147200/209452]\n",
      "loss: 0.000058  [150400/209452]\n",
      "loss: 0.000158  [153600/209452]\n",
      "loss: 0.000504  [156800/209452]\n",
      "loss: 0.000147  [160000/209452]\n",
      "loss: 0.000597  [163200/209452]\n",
      "loss: 0.000058  [166400/209452]\n",
      "loss: 0.000064  [169600/209452]\n",
      "loss: 0.001212  [172800/209452]\n",
      "loss: 0.000021  [176000/209452]\n",
      "loss: 0.000049  [179200/209452]\n",
      "loss: 0.000122  [182400/209452]\n",
      "loss: 0.000052  [185600/209452]\n",
      "loss: 0.000178  [188800/209452]\n",
      "loss: 0.000019  [192000/209452]\n",
      "loss: 0.000011  [195200/209452]\n",
      "loss: 0.000044  [198400/209452]\n",
      "loss: 0.000025  [201600/209452]\n",
      "loss: 0.000010  [204800/209452]\n",
      "loss: 0.003331  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 85\n",
      "---------------------------\n",
      "loss: 0.000092  [ 3200/209452]\n",
      "loss: 0.000187  [ 6400/209452]\n",
      "loss: 0.000346  [ 9600/209452]\n",
      "loss: 0.000315  [12800/209452]\n",
      "loss: 0.000043  [16000/209452]\n",
      "loss: 0.000024  [19200/209452]\n",
      "loss: 0.000046  [22400/209452]\n",
      "loss: 0.001070  [25600/209452]\n",
      "loss: 0.000125  [28800/209452]\n",
      "loss: 0.000014  [32000/209452]\n",
      "loss: 0.000056  [35200/209452]\n",
      "loss: 0.000095  [38400/209452]\n",
      "loss: 0.000157  [41600/209452]\n",
      "loss: 0.000038  [44800/209452]\n",
      "loss: 0.000042  [48000/209452]\n",
      "loss: 0.000058  [51200/209452]\n",
      "loss: 0.000034  [54400/209452]\n",
      "loss: 0.000109  [57600/209452]\n",
      "loss: 0.000149  [60800/209452]\n",
      "loss: 0.000139  [64000/209452]\n",
      "loss: 0.000076  [67200/209452]\n",
      "loss: 0.000052  [70400/209452]\n",
      "loss: 0.000042  [73600/209452]\n",
      "loss: 0.000053  [76800/209452]\n",
      "loss: 0.001244  [80000/209452]\n",
      "loss: 0.000386  [83200/209452]\n",
      "loss: 0.000095  [86400/209452]\n",
      "loss: 0.000082  [89600/209452]\n",
      "loss: 0.000018  [92800/209452]\n",
      "loss: 0.000059  [96000/209452]\n",
      "loss: 0.000103  [99200/209452]\n",
      "loss: 0.000090  [102400/209452]\n",
      "loss: 0.000074  [105600/209452]\n",
      "loss: 0.000130  [108800/209452]\n",
      "loss: 0.000102  [112000/209452]\n",
      "loss: 0.000238  [115200/209452]\n",
      "loss: 0.000166  [118400/209452]\n",
      "loss: 0.000064  [121600/209452]\n",
      "loss: 0.000044  [124800/209452]\n",
      "loss: 0.000024  [128000/209452]\n",
      "loss: 0.000115  [131200/209452]\n",
      "loss: 0.000153  [134400/209452]\n",
      "loss: 0.000023  [137600/209452]\n",
      "loss: 0.000018  [140800/209452]\n",
      "loss: 0.000062  [144000/209452]\n",
      "loss: 0.000195  [147200/209452]\n",
      "loss: 0.000084  [150400/209452]\n",
      "loss: 0.000022  [153600/209452]\n",
      "loss: 0.000004  [156800/209452]\n",
      "loss: 0.000074  [160000/209452]\n",
      "loss: 0.000277  [163200/209452]\n",
      "loss: 0.000076  [166400/209452]\n",
      "loss: 0.000038  [169600/209452]\n",
      "loss: 0.000137  [172800/209452]\n",
      "loss: 0.000182  [176000/209452]\n",
      "loss: 0.000024  [179200/209452]\n",
      "loss: 0.000091  [182400/209452]\n",
      "loss: 0.000053  [185600/209452]\n",
      "loss: 0.000006  [188800/209452]\n",
      "loss: 0.000121  [192000/209452]\n",
      "loss: 0.000027  [195200/209452]\n",
      "loss: 0.000010  [198400/209452]\n",
      "loss: 0.000146  [201600/209452]\n",
      "loss: 0.000122  [204800/209452]\n",
      "loss: 0.000039  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002712 \n",
      "\n",
      "Epoch 86\n",
      "---------------------------\n",
      "loss: 0.000056  [ 3200/209452]\n",
      "loss: 0.000136  [ 6400/209452]\n",
      "loss: 0.000055  [ 9600/209452]\n",
      "loss: 0.000175  [12800/209452]\n",
      "loss: 0.000219  [16000/209452]\n",
      "loss: 0.000016  [19200/209452]\n",
      "loss: 0.000024  [22400/209452]\n",
      "loss: 0.000194  [25600/209452]\n",
      "loss: 0.000040  [28800/209452]\n",
      "loss: 0.000036  [32000/209452]\n",
      "loss: 0.000297  [35200/209452]\n",
      "loss: 0.000122  [38400/209452]\n",
      "loss: 0.000043  [41600/209452]\n",
      "loss: 0.002218  [44800/209452]\n",
      "loss: 0.000018  [48000/209452]\n",
      "loss: 0.000049  [51200/209452]\n",
      "loss: 0.000322  [54400/209452]\n",
      "loss: 0.000028  [57600/209452]\n",
      "loss: 0.000013  [60800/209452]\n",
      "loss: 0.000126  [64000/209452]\n",
      "loss: 0.000039  [67200/209452]\n",
      "loss: 0.000007  [70400/209452]\n",
      "loss: 0.000018  [73600/209452]\n",
      "loss: 0.000033  [76800/209452]\n",
      "loss: 0.000018  [80000/209452]\n",
      "loss: 0.000022  [83200/209452]\n",
      "loss: 0.000042  [86400/209452]\n",
      "loss: 0.000200  [89600/209452]\n",
      "loss: 0.000392  [92800/209452]\n",
      "loss: 0.000083  [96000/209452]\n",
      "loss: 0.000028  [99200/209452]\n",
      "loss: 0.000021  [102400/209452]\n",
      "loss: 0.000068  [105600/209452]\n",
      "loss: 0.000025  [108800/209452]\n",
      "loss: 0.000192  [112000/209452]\n",
      "loss: 0.000034  [115200/209452]\n",
      "loss: 0.000041  [118400/209452]\n",
      "loss: 0.000071  [121600/209452]\n",
      "loss: 0.000232  [124800/209452]\n",
      "loss: 0.000187  [128000/209452]\n",
      "loss: 0.000040  [131200/209452]\n",
      "loss: 0.000065  [134400/209452]\n",
      "loss: 0.000008  [137600/209452]\n",
      "loss: 0.000015  [140800/209452]\n",
      "loss: 0.000085  [144000/209452]\n",
      "loss: 0.000060  [147200/209452]\n",
      "loss: 0.000085  [150400/209452]\n",
      "loss: 0.000164  [153600/209452]\n",
      "loss: 0.000045  [156800/209452]\n",
      "loss: 0.000118  [160000/209452]\n",
      "loss: 0.000024  [163200/209452]\n",
      "loss: 0.000020  [166400/209452]\n",
      "loss: 0.000123  [169600/209452]\n",
      "loss: 0.001313  [172800/209452]\n",
      "loss: 0.000036  [176000/209452]\n",
      "loss: 0.000022  [179200/209452]\n",
      "loss: 0.000071  [182400/209452]\n",
      "loss: 0.000087  [185600/209452]\n",
      "loss: 0.000172  [188800/209452]\n",
      "loss: 0.000041  [192000/209452]\n",
      "loss: 0.022298  [195200/209452]\n",
      "loss: 0.000832  [198400/209452]\n",
      "loss: 0.000019  [201600/209452]\n",
      "loss: 0.000181  [204800/209452]\n",
      "loss: 0.000037  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002679 \n",
      "\n",
      "Epoch 87\n",
      "---------------------------\n",
      "loss: 0.000068  [ 3200/209452]\n",
      "loss: 0.001174  [ 6400/209452]\n",
      "loss: 0.000017  [ 9600/209452]\n",
      "loss: 0.000058  [12800/209452]\n",
      "loss: 0.000060  [16000/209452]\n",
      "loss: 0.000020  [19200/209452]\n",
      "loss: 0.000024  [22400/209452]\n",
      "loss: 0.000016  [25600/209452]\n",
      "loss: 0.000312  [28800/209452]\n",
      "loss: 0.000099  [32000/209452]\n",
      "loss: 0.000038  [35200/209452]\n",
      "loss: 0.000011  [38400/209452]\n",
      "loss: 0.001036  [41600/209452]\n",
      "loss: 0.000243  [44800/209452]\n",
      "loss: 0.000015  [48000/209452]\n",
      "loss: 0.000043  [51200/209452]\n",
      "loss: 0.000104  [54400/209452]\n",
      "loss: 0.000095  [57600/209452]\n",
      "loss: 0.001252  [60800/209452]\n",
      "loss: 0.000344  [64000/209452]\n",
      "loss: 0.000023  [67200/209452]\n",
      "loss: 0.000137  [70400/209452]\n",
      "loss: 0.000021  [73600/209452]\n",
      "loss: 0.000056  [76800/209452]\n",
      "loss: 0.000166  [80000/209452]\n",
      "loss: 0.000047  [83200/209452]\n",
      "loss: 0.000086  [86400/209452]\n",
      "loss: 0.000011  [89600/209452]\n",
      "loss: 0.000038  [92800/209452]\n",
      "loss: 0.000213  [96000/209452]\n",
      "loss: 0.000064  [99200/209452]\n",
      "loss: 0.000028  [102400/209452]\n",
      "loss: 0.001531  [105600/209452]\n",
      "loss: 0.000020  [108800/209452]\n",
      "loss: 0.000048  [112000/209452]\n",
      "loss: 0.000044  [115200/209452]\n",
      "loss: 0.000016  [118400/209452]\n",
      "loss: 0.000053  [121600/209452]\n",
      "loss: 0.000294  [124800/209452]\n",
      "loss: 0.000109  [128000/209452]\n",
      "loss: 0.000015  [131200/209452]\n",
      "loss: 0.000046  [134400/209452]\n",
      "loss: 0.000076  [137600/209452]\n",
      "loss: 0.000055  [140800/209452]\n",
      "loss: 0.000173  [144000/209452]\n",
      "loss: 0.000079  [147200/209452]\n",
      "loss: 0.000053  [150400/209452]\n",
      "loss: 0.000241  [153600/209452]\n",
      "loss: 0.000274  [156800/209452]\n",
      "loss: 0.000124  [160000/209452]\n",
      "loss: 0.000040  [163200/209452]\n",
      "loss: 0.000228  [166400/209452]\n",
      "loss: 0.000021  [169600/209452]\n",
      "loss: 0.000044  [172800/209452]\n",
      "loss: 0.000132  [176000/209452]\n",
      "loss: 0.000046  [179200/209452]\n",
      "loss: 0.000218  [182400/209452]\n",
      "loss: 0.000035  [185600/209452]\n",
      "loss: 0.000201  [188800/209452]\n",
      "loss: 0.000056  [192000/209452]\n",
      "loss: 0.000175  [195200/209452]\n",
      "loss: 0.000038  [198400/209452]\n",
      "loss: 0.000021  [201600/209452]\n",
      "loss: 0.000044  [204800/209452]\n",
      "loss: 0.000023  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002674 \n",
      "\n",
      "Epoch 88\n",
      "---------------------------\n",
      "loss: 0.000729  [ 3200/209452]\n",
      "loss: 0.000044  [ 6400/209452]\n",
      "loss: 0.000009  [ 9600/209452]\n",
      "loss: 0.000120  [12800/209452]\n",
      "loss: 0.000503  [16000/209452]\n",
      "loss: 0.000187  [19200/209452]\n",
      "loss: 0.003325  [22400/209452]\n",
      "loss: 0.000378  [25600/209452]\n",
      "loss: 0.000069  [28800/209452]\n",
      "loss: 0.000029  [32000/209452]\n",
      "loss: 0.000024  [35200/209452]\n",
      "loss: 0.000092  [38400/209452]\n",
      "loss: 0.000718  [41600/209452]\n",
      "loss: 0.000025  [44800/209452]\n",
      "loss: 0.000030  [48000/209452]\n",
      "loss: 0.000031  [51200/209452]\n",
      "loss: 0.000055  [54400/209452]\n",
      "loss: 0.000024  [57600/209452]\n",
      "loss: 0.000039  [60800/209452]\n",
      "loss: 0.000027  [64000/209452]\n",
      "loss: 0.000355  [67200/209452]\n",
      "loss: 0.000018  [70400/209452]\n",
      "loss: 0.000019  [73600/209452]\n",
      "loss: 0.000669  [76800/209452]\n",
      "loss: 0.000056  [80000/209452]\n",
      "loss: 0.000166  [83200/209452]\n",
      "loss: 0.000066  [86400/209452]\n",
      "loss: 0.000249  [89600/209452]\n",
      "loss: 0.000226  [92800/209452]\n",
      "loss: 0.000016  [96000/209452]\n",
      "loss: 0.000023  [99200/209452]\n",
      "loss: 0.000817  [102400/209452]\n",
      "loss: 0.000057  [105600/209452]\n",
      "loss: 0.000316  [108800/209452]\n",
      "loss: 0.000151  [112000/209452]\n",
      "loss: 0.000179  [115200/209452]\n",
      "loss: 0.000015  [118400/209452]\n",
      "loss: 0.000106  [121600/209452]\n",
      "loss: 0.000137  [124800/209452]\n",
      "loss: 0.000169  [128000/209452]\n",
      "loss: 0.002221  [131200/209452]\n",
      "loss: 0.000564  [134400/209452]\n",
      "loss: 0.000156  [137600/209452]\n",
      "loss: 0.000185  [140800/209452]\n",
      "loss: 0.000072  [144000/209452]\n",
      "loss: 0.000227  [147200/209452]\n",
      "loss: 0.000022  [150400/209452]\n",
      "loss: 0.000092  [153600/209452]\n",
      "loss: 0.000034  [156800/209452]\n",
      "loss: 0.000100  [160000/209452]\n",
      "loss: 0.000219  [163200/209452]\n",
      "loss: 0.000036  [166400/209452]\n",
      "loss: 0.000026  [169600/209452]\n",
      "loss: 0.000006  [172800/209452]\n",
      "loss: 0.000019  [176000/209452]\n",
      "loss: 0.001301  [179200/209452]\n",
      "loss: 0.000003  [182400/209452]\n",
      "loss: 0.000037  [185600/209452]\n",
      "loss: 0.000162  [188800/209452]\n",
      "loss: 0.000018  [192000/209452]\n",
      "loss: 0.000084  [195200/209452]\n",
      "loss: 0.000109  [198400/209452]\n",
      "loss: 0.000107  [201600/209452]\n",
      "loss: 0.000053  [204800/209452]\n",
      "loss: 0.000019  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 89\n",
      "---------------------------\n",
      "loss: 0.000017  [ 3200/209452]\n",
      "loss: 0.000058  [ 6400/209452]\n",
      "loss: 0.000150  [ 9600/209452]\n",
      "loss: 0.001447  [12800/209452]\n",
      "loss: 0.000003  [16000/209452]\n",
      "loss: 0.000060  [19200/209452]\n",
      "loss: 0.000035  [22400/209452]\n",
      "loss: 0.000006  [25600/209452]\n",
      "loss: 0.000257  [28800/209452]\n",
      "loss: 0.000050  [32000/209452]\n",
      "loss: 0.000115  [35200/209452]\n",
      "loss: 0.000030  [38400/209452]\n",
      "loss: 0.000034  [41600/209452]\n",
      "loss: 0.000025  [44800/209452]\n",
      "loss: 0.000043  [48000/209452]\n",
      "loss: 0.000018  [51200/209452]\n",
      "loss: 0.000063  [54400/209452]\n",
      "loss: 0.000055  [57600/209452]\n",
      "loss: 0.000209  [60800/209452]\n",
      "loss: 0.000016  [64000/209452]\n",
      "loss: 0.000080  [67200/209452]\n",
      "loss: 0.003328  [70400/209452]\n",
      "loss: 0.000312  [73600/209452]\n",
      "loss: 0.000019  [76800/209452]\n",
      "loss: 0.000080  [80000/209452]\n",
      "loss: 0.000487  [83200/209452]\n",
      "loss: 0.000082  [86400/209452]\n",
      "loss: 0.000028  [89600/209452]\n",
      "loss: 0.000150  [92800/209452]\n",
      "loss: 0.003523  [96000/209452]\n",
      "loss: 0.000377  [99200/209452]\n",
      "loss: 0.000063  [102400/209452]\n",
      "loss: 0.000044  [105600/209452]\n",
      "loss: 0.000131  [108800/209452]\n",
      "loss: 0.000129  [112000/209452]\n",
      "loss: 0.000435  [115200/209452]\n",
      "loss: 0.000052  [118400/209452]\n",
      "loss: 0.000768  [121600/209452]\n",
      "loss: 0.000074  [124800/209452]\n",
      "loss: 0.000310  [128000/209452]\n",
      "loss: 0.000163  [131200/209452]\n",
      "loss: 0.000121  [134400/209452]\n",
      "loss: 0.002895  [137600/209452]\n",
      "loss: 0.000037  [140800/209452]\n",
      "loss: 0.000025  [144000/209452]\n",
      "loss: 0.000034  [147200/209452]\n",
      "loss: 0.000011  [150400/209452]\n",
      "loss: 0.000189  [153600/209452]\n",
      "loss: 0.000007  [156800/209452]\n",
      "loss: 0.000037  [160000/209452]\n",
      "loss: 0.000041  [163200/209452]\n",
      "loss: 0.000003  [166400/209452]\n",
      "loss: 0.000136  [169600/209452]\n",
      "loss: 0.000084  [172800/209452]\n",
      "loss: 0.000426  [176000/209452]\n",
      "loss: 0.000014  [179200/209452]\n",
      "loss: 0.000028  [182400/209452]\n",
      "loss: 0.000019  [185600/209452]\n",
      "loss: 0.000017  [188800/209452]\n",
      "loss: 0.000045  [192000/209452]\n",
      "loss: 0.000049  [195200/209452]\n",
      "loss: 0.000109  [198400/209452]\n",
      "loss: 0.000044  [201600/209452]\n",
      "loss: 0.000011  [204800/209452]\n",
      "loss: 0.000018  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 90\n",
      "---------------------------\n",
      "loss: 0.000346  [ 3200/209452]\n",
      "loss: 0.000013  [ 6400/209452]\n",
      "loss: 0.000059  [ 9600/209452]\n",
      "loss: 0.000123  [12800/209452]\n",
      "loss: 0.000016  [16000/209452]\n",
      "loss: 0.000057  [19200/209452]\n",
      "loss: 0.000158  [22400/209452]\n",
      "loss: 0.000262  [25600/209452]\n",
      "loss: 0.000042  [28800/209452]\n",
      "loss: 0.000045  [32000/209452]\n",
      "loss: 0.000080  [35200/209452]\n",
      "loss: 0.000036  [38400/209452]\n",
      "loss: 0.000847  [41600/209452]\n",
      "loss: 0.000049  [44800/209452]\n",
      "loss: 0.000044  [48000/209452]\n",
      "loss: 0.000278  [51200/209452]\n",
      "loss: 0.001310  [54400/209452]\n",
      "loss: 0.000048  [57600/209452]\n",
      "loss: 0.000083  [60800/209452]\n",
      "loss: 0.000175  [64000/209452]\n",
      "loss: 0.000101  [67200/209452]\n",
      "loss: 0.000005  [70400/209452]\n",
      "loss: 0.000013  [73600/209452]\n",
      "loss: 0.000030  [76800/209452]\n",
      "loss: 0.000278  [80000/209452]\n",
      "loss: 0.000059  [83200/209452]\n",
      "loss: 0.000023  [86400/209452]\n",
      "loss: 0.000029  [89600/209452]\n",
      "loss: 0.001559  [92800/209452]\n",
      "loss: 0.000025  [96000/209452]\n",
      "loss: 0.000058  [99200/209452]\n",
      "loss: 0.000052  [102400/209452]\n",
      "loss: 0.000015  [105600/209452]\n",
      "loss: 0.000627  [108800/209452]\n",
      "loss: 0.000017  [112000/209452]\n",
      "loss: 0.000071  [115200/209452]\n",
      "loss: 0.000137  [118400/209452]\n",
      "loss: 0.000014  [121600/209452]\n",
      "loss: 0.000008  [124800/209452]\n",
      "loss: 0.000446  [128000/209452]\n",
      "loss: 0.000008  [131200/209452]\n",
      "loss: 0.000021  [134400/209452]\n",
      "loss: 0.000522  [137600/209452]\n",
      "loss: 0.000191  [140800/209452]\n",
      "loss: 0.000121  [144000/209452]\n",
      "loss: 0.001460  [147200/209452]\n",
      "loss: 0.001021  [150400/209452]\n",
      "loss: 0.000059  [153600/209452]\n",
      "loss: 0.000091  [156800/209452]\n",
      "loss: 0.000855  [160000/209452]\n",
      "loss: 0.000065  [163200/209452]\n",
      "loss: 0.000013  [166400/209452]\n",
      "loss: 0.000087  [169600/209452]\n",
      "loss: 0.000145  [172800/209452]\n",
      "loss: 0.000602  [176000/209452]\n",
      "loss: 0.000128  [179200/209452]\n",
      "loss: 0.000022  [182400/209452]\n",
      "loss: 0.000015  [185600/209452]\n",
      "loss: 0.000144  [188800/209452]\n",
      "loss: 0.000225  [192000/209452]\n",
      "loss: 0.001212  [195200/209452]\n",
      "loss: 0.000026  [198400/209452]\n",
      "loss: 0.000039  [201600/209452]\n",
      "loss: 0.003139  [204800/209452]\n",
      "loss: 0.000020  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 91\n",
      "---------------------------\n",
      "loss: 0.000098  [ 3200/209452]\n",
      "loss: 0.000038  [ 6400/209452]\n",
      "loss: 0.000004  [ 9600/209452]\n",
      "loss: 0.000094  [12800/209452]\n",
      "loss: 0.000506  [16000/209452]\n",
      "loss: 0.000029  [19200/209452]\n",
      "loss: 0.000030  [22400/209452]\n",
      "loss: 0.000024  [25600/209452]\n",
      "loss: 0.000026  [28800/209452]\n",
      "loss: 0.000042  [32000/209452]\n",
      "loss: 0.000029  [35200/209452]\n",
      "loss: 0.000040  [38400/209452]\n",
      "loss: 0.000061  [41600/209452]\n",
      "loss: 0.000593  [44800/209452]\n",
      "loss: 0.000069  [48000/209452]\n",
      "loss: 0.000045  [51200/209452]\n",
      "loss: 0.000108  [54400/209452]\n",
      "loss: 0.000006  [57600/209452]\n",
      "loss: 0.000083  [60800/209452]\n",
      "loss: 0.000020  [64000/209452]\n",
      "loss: 0.000033  [67200/209452]\n",
      "loss: 0.000063  [70400/209452]\n",
      "loss: 0.000934  [73600/209452]\n",
      "loss: 0.000013  [76800/209452]\n",
      "loss: 0.000022  [80000/209452]\n",
      "loss: 0.000126  [83200/209452]\n",
      "loss: 0.000037  [86400/209452]\n",
      "loss: 0.000001  [89600/209452]\n",
      "loss: 0.000332  [92800/209452]\n",
      "loss: 0.000161  [96000/209452]\n",
      "loss: 0.000558  [99200/209452]\n",
      "loss: 0.000122  [102400/209452]\n",
      "loss: 0.000053  [105600/209452]\n",
      "loss: 0.000010  [108800/209452]\n",
      "loss: 0.000307  [112000/209452]\n",
      "loss: 0.000065  [115200/209452]\n",
      "loss: 0.000008  [118400/209452]\n",
      "loss: 0.000123  [121600/209452]\n",
      "loss: 0.000016  [124800/209452]\n",
      "loss: 0.000045  [128000/209452]\n",
      "loss: 0.000030  [131200/209452]\n",
      "loss: 0.000042  [134400/209452]\n",
      "loss: 0.000078  [137600/209452]\n",
      "loss: 0.000026  [140800/209452]\n",
      "loss: 0.000020  [144000/209452]\n",
      "loss: 0.000306  [147200/209452]\n",
      "loss: 0.000034  [150400/209452]\n",
      "loss: 0.000028  [153600/209452]\n",
      "loss: 0.000100  [156800/209452]\n",
      "loss: 0.000042  [160000/209452]\n",
      "loss: 0.000042  [163200/209452]\n",
      "loss: 0.000026  [166400/209452]\n",
      "loss: 0.000016  [169600/209452]\n",
      "loss: 0.004364  [172800/209452]\n",
      "loss: 0.000134  [176000/209452]\n",
      "loss: 0.000016  [179200/209452]\n",
      "loss: 0.000015  [182400/209452]\n",
      "loss: 0.000203  [185600/209452]\n",
      "loss: 0.000030  [188800/209452]\n",
      "loss: 0.000045  [192000/209452]\n",
      "loss: 0.000126  [195200/209452]\n",
      "loss: 0.000052  [198400/209452]\n",
      "loss: 0.000008  [201600/209452]\n",
      "loss: 0.000153  [204800/209452]\n",
      "loss: 0.000010  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002794 \n",
      "\n",
      "Epoch 92\n",
      "---------------------------\n",
      "loss: 0.000119  [ 3200/209452]\n",
      "loss: 0.000046  [ 6400/209452]\n",
      "loss: 0.000478  [ 9600/209452]\n",
      "loss: 0.000017  [12800/209452]\n",
      "loss: 0.000065  [16000/209452]\n",
      "loss: 0.000010  [19200/209452]\n",
      "loss: 0.000010  [22400/209452]\n",
      "loss: 0.000003  [25600/209452]\n",
      "loss: 0.000063  [28800/209452]\n",
      "loss: 0.000030  [32000/209452]\n",
      "loss: 0.000077  [35200/209452]\n",
      "loss: 0.000034  [38400/209452]\n",
      "loss: 0.000008  [41600/209452]\n",
      "loss: 0.000330  [44800/209452]\n",
      "loss: 0.000425  [48000/209452]\n",
      "loss: 0.000010  [51200/209452]\n",
      "loss: 0.000021  [54400/209452]\n",
      "loss: 0.000032  [57600/209452]\n",
      "loss: 0.000011  [60800/209452]\n",
      "loss: 0.000188  [64000/209452]\n",
      "loss: 0.000009  [67200/209452]\n",
      "loss: 0.000010  [70400/209452]\n",
      "loss: 0.001608  [73600/209452]\n",
      "loss: 0.000261  [76800/209452]\n",
      "loss: 0.000072  [80000/209452]\n",
      "loss: 0.000596  [83200/209452]\n",
      "loss: 0.000023  [86400/209452]\n",
      "loss: 0.000239  [89600/209452]\n",
      "loss: 0.000059  [92800/209452]\n",
      "loss: 0.000013  [96000/209452]\n",
      "loss: 0.000071  [99200/209452]\n",
      "loss: 0.000026  [102400/209452]\n",
      "loss: 0.000017  [105600/209452]\n",
      "loss: 0.000013  [108800/209452]\n",
      "loss: 0.000233  [112000/209452]\n",
      "loss: 0.000515  [115200/209452]\n",
      "loss: 0.000911  [118400/209452]\n",
      "loss: 0.000046  [121600/209452]\n",
      "loss: 0.000068  [124800/209452]\n",
      "loss: 0.000052  [128000/209452]\n",
      "loss: 0.000011  [131200/209452]\n",
      "loss: 0.000075  [134400/209452]\n",
      "loss: 0.000084  [137600/209452]\n",
      "loss: 0.000027  [140800/209452]\n",
      "loss: 0.000082  [144000/209452]\n",
      "loss: 0.000018  [147200/209452]\n",
      "loss: 0.000195  [150400/209452]\n",
      "loss: 0.000014  [153600/209452]\n",
      "loss: 0.000112  [156800/209452]\n",
      "loss: 0.000128  [160000/209452]\n",
      "loss: 0.000090  [163200/209452]\n",
      "loss: 0.000023  [166400/209452]\n",
      "loss: 0.000005  [169600/209452]\n",
      "loss: 0.000008  [172800/209452]\n",
      "loss: 0.000016  [176000/209452]\n",
      "loss: 0.000024  [179200/209452]\n",
      "loss: 0.000009  [182400/209452]\n",
      "loss: 0.000091  [185600/209452]\n",
      "loss: 0.000062  [188800/209452]\n",
      "loss: 0.000058  [192000/209452]\n",
      "loss: 0.000042  [195200/209452]\n",
      "loss: 0.000095  [198400/209452]\n",
      "loss: 0.000340  [201600/209452]\n",
      "loss: 0.000099  [204800/209452]\n",
      "loss: 0.000021  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002687 \n",
      "\n",
      "Epoch 93\n",
      "---------------------------\n",
      "loss: 0.000106  [ 3200/209452]\n",
      "loss: 0.000018  [ 6400/209452]\n",
      "loss: 0.000033  [ 9600/209452]\n",
      "loss: 0.001300  [12800/209452]\n",
      "loss: 0.000115  [16000/209452]\n",
      "loss: 0.000150  [19200/209452]\n",
      "loss: 0.000114  [22400/209452]\n",
      "loss: 0.000189  [25600/209452]\n",
      "loss: 0.000026  [28800/209452]\n",
      "loss: 0.000010  [32000/209452]\n",
      "loss: 0.000006  [35200/209452]\n",
      "loss: 0.000173  [38400/209452]\n",
      "loss: 0.000027  [41600/209452]\n",
      "loss: 0.000089  [44800/209452]\n",
      "loss: 0.000050  [48000/209452]\n",
      "loss: 0.000054  [51200/209452]\n",
      "loss: 0.000078  [54400/209452]\n",
      "loss: 0.000382  [57600/209452]\n",
      "loss: 0.000258  [60800/209452]\n",
      "loss: 0.000192  [64000/209452]\n",
      "loss: 0.000311  [67200/209452]\n",
      "loss: 0.000038  [70400/209452]\n",
      "loss: 0.002047  [73600/209452]\n",
      "loss: 0.000809  [76800/209452]\n",
      "loss: 0.000026  [80000/209452]\n",
      "loss: 0.000035  [83200/209452]\n",
      "loss: 0.000089  [86400/209452]\n",
      "loss: 0.000063  [89600/209452]\n",
      "loss: 0.000190  [92800/209452]\n",
      "loss: 0.000053  [96000/209452]\n",
      "loss: 0.000628  [99200/209452]\n",
      "loss: 0.000169  [102400/209452]\n",
      "loss: 0.000011  [105600/209452]\n",
      "loss: 0.000144  [108800/209452]\n",
      "loss: 0.000385  [112000/209452]\n",
      "loss: 0.000096  [115200/209452]\n",
      "loss: 0.000272  [118400/209452]\n",
      "loss: 0.000051  [121600/209452]\n",
      "loss: 0.000044  [124800/209452]\n",
      "loss: 0.000051  [128000/209452]\n",
      "loss: 0.000448  [131200/209452]\n",
      "loss: 0.000215  [134400/209452]\n",
      "loss: 0.000363  [137600/209452]\n",
      "loss: 0.000292  [140800/209452]\n",
      "loss: 0.000029  [144000/209452]\n",
      "loss: 0.000034  [147200/209452]\n",
      "loss: 0.000261  [150400/209452]\n",
      "loss: 0.000012  [153600/209452]\n",
      "loss: 0.000305  [156800/209452]\n",
      "loss: 0.000111  [160000/209452]\n",
      "loss: 0.000116  [163200/209452]\n",
      "loss: 0.000117  [166400/209452]\n",
      "loss: 0.003190  [169600/209452]\n",
      "loss: 0.000033  [172800/209452]\n",
      "loss: 0.000049  [176000/209452]\n",
      "loss: 0.000066  [179200/209452]\n",
      "loss: 0.000008  [182400/209452]\n",
      "loss: 0.000015  [185600/209452]\n",
      "loss: 0.000017  [188800/209452]\n",
      "loss: 0.000984  [192000/209452]\n",
      "loss: 0.000071  [195200/209452]\n",
      "loss: 0.000283  [198400/209452]\n",
      "loss: 0.000099  [201600/209452]\n",
      "loss: 0.000091  [204800/209452]\n",
      "loss: 0.000057  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002652 \n",
      "\n",
      "Epoch 94\n",
      "---------------------------\n",
      "loss: 0.001642  [ 3200/209452]\n",
      "loss: 0.000001  [ 6400/209452]\n",
      "loss: 0.000059  [ 9600/209452]\n",
      "loss: 0.000048  [12800/209452]\n",
      "loss: 0.000020  [16000/209452]\n",
      "loss: 0.000056  [19200/209452]\n",
      "loss: 0.000270  [22400/209452]\n",
      "loss: 0.000161  [25600/209452]\n",
      "loss: 0.000112  [28800/209452]\n",
      "loss: 0.000059  [32000/209452]\n",
      "loss: 0.000072  [35200/209452]\n",
      "loss: 0.000040  [38400/209452]\n",
      "loss: 0.000027  [41600/209452]\n",
      "loss: 0.000015  [44800/209452]\n",
      "loss: 0.000223  [48000/209452]\n",
      "loss: 0.000030  [51200/209452]\n",
      "loss: 0.000021  [54400/209452]\n",
      "loss: 0.000044  [57600/209452]\n",
      "loss: 0.000018  [60800/209452]\n",
      "loss: 0.000110  [64000/209452]\n",
      "loss: 0.000009  [67200/209452]\n",
      "loss: 0.000018  [70400/209452]\n",
      "loss: 0.000027  [73600/209452]\n",
      "loss: 0.000115  [76800/209452]\n",
      "loss: 0.000056  [80000/209452]\n",
      "loss: 0.000460  [83200/209452]\n",
      "loss: 0.000030  [86400/209452]\n",
      "loss: 0.002824  [89600/209452]\n",
      "loss: 0.000055  [92800/209452]\n",
      "loss: 0.000164  [96000/209452]\n",
      "loss: 0.000093  [99200/209452]\n",
      "loss: 0.000046  [102400/209452]\n",
      "loss: 0.000063  [105600/209452]\n",
      "loss: 0.000086  [108800/209452]\n",
      "loss: 0.000106  [112000/209452]\n",
      "loss: 0.000064  [115200/209452]\n",
      "loss: 0.000018  [118400/209452]\n",
      "loss: 0.001010  [121600/209452]\n",
      "loss: 0.000042  [124800/209452]\n",
      "loss: 0.000172  [128000/209452]\n",
      "loss: 0.000020  [131200/209452]\n",
      "loss: 0.000020  [134400/209452]\n",
      "loss: 0.000015  [137600/209452]\n",
      "loss: 0.000383  [140800/209452]\n",
      "loss: 0.000024  [144000/209452]\n",
      "loss: 0.000050  [147200/209452]\n",
      "loss: 0.000005  [150400/209452]\n",
      "loss: 0.000005  [153600/209452]\n",
      "loss: 0.000096  [156800/209452]\n",
      "loss: 0.000042  [160000/209452]\n",
      "loss: 0.000037  [163200/209452]\n",
      "loss: 0.000820  [166400/209452]\n",
      "loss: 0.000027  [169600/209452]\n",
      "loss: 0.000008  [172800/209452]\n",
      "loss: 0.000046  [176000/209452]\n",
      "loss: 0.000103  [179200/209452]\n",
      "loss: 0.000069  [182400/209452]\n",
      "loss: 0.000032  [185600/209452]\n",
      "loss: 0.000023  [188800/209452]\n",
      "loss: 0.000012  [192000/209452]\n",
      "loss: 0.000029  [195200/209452]\n",
      "loss: 0.000041  [198400/209452]\n",
      "loss: 0.000041  [201600/209452]\n",
      "loss: 0.000107  [204800/209452]\n",
      "loss: 0.000007  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 95\n",
      "---------------------------\n",
      "loss: 0.000045  [ 3200/209452]\n",
      "loss: 0.000048  [ 6400/209452]\n",
      "loss: 0.000054  [ 9600/209452]\n",
      "loss: 0.000028  [12800/209452]\n",
      "loss: 0.000121  [16000/209452]\n",
      "loss: 0.000017  [19200/209452]\n",
      "loss: 0.000053  [22400/209452]\n",
      "loss: 0.005159  [25600/209452]\n",
      "loss: 0.000147  [28800/209452]\n",
      "loss: 0.000003  [32000/209452]\n",
      "loss: 0.000019  [35200/209452]\n",
      "loss: 0.000331  [38400/209452]\n",
      "loss: 0.000029  [41600/209452]\n",
      "loss: 0.000005  [44800/209452]\n",
      "loss: 0.000015  [48000/209452]\n",
      "loss: 0.000249  [51200/209452]\n",
      "loss: 0.000018  [54400/209452]\n",
      "loss: 0.000078  [57600/209452]\n",
      "loss: 0.000011  [60800/209452]\n",
      "loss: 0.000129  [64000/209452]\n",
      "loss: 0.000040  [67200/209452]\n",
      "loss: 0.000180  [70400/209452]\n",
      "loss: 0.001101  [73600/209452]\n",
      "loss: 0.000027  [76800/209452]\n",
      "loss: 0.000020  [80000/209452]\n",
      "loss: 0.000022  [83200/209452]\n",
      "loss: 0.000029  [86400/209452]\n",
      "loss: 0.000028  [89600/209452]\n",
      "loss: 0.000185  [92800/209452]\n",
      "loss: 0.000074  [96000/209452]\n",
      "loss: 0.000289  [99200/209452]\n",
      "loss: 0.000023  [102400/209452]\n",
      "loss: 0.000019  [105600/209452]\n",
      "loss: 0.000012  [108800/209452]\n",
      "loss: 0.000523  [112000/209452]\n",
      "loss: 0.001084  [115200/209452]\n",
      "loss: 0.000018  [118400/209452]\n",
      "loss: 0.000318  [121600/209452]\n",
      "loss: 0.000235  [124800/209452]\n",
      "loss: 0.000499  [128000/209452]\n",
      "loss: 0.000300  [131200/209452]\n",
      "loss: 0.000255  [134400/209452]\n",
      "loss: 0.000067  [137600/209452]\n",
      "loss: 0.000019  [140800/209452]\n",
      "loss: 0.000130  [144000/209452]\n",
      "loss: 0.000167  [147200/209452]\n",
      "loss: 0.000100  [150400/209452]\n",
      "loss: 0.003191  [153600/209452]\n",
      "loss: 0.000067  [156800/209452]\n",
      "loss: 0.000007  [160000/209452]\n",
      "loss: 0.000130  [163200/209452]\n",
      "loss: 0.000040  [166400/209452]\n",
      "loss: 0.000041  [169600/209452]\n",
      "loss: 0.000022  [172800/209452]\n",
      "loss: 0.000034  [176000/209452]\n",
      "loss: 0.000134  [179200/209452]\n",
      "loss: 0.000259  [182400/209452]\n",
      "loss: 0.000309  [185600/209452]\n",
      "loss: 0.000100  [188800/209452]\n",
      "loss: 0.000209  [192000/209452]\n",
      "loss: 0.000019  [195200/209452]\n",
      "loss: 0.000037  [198400/209452]\n",
      "loss: 0.000036  [201600/209452]\n",
      "loss: 0.000061  [204800/209452]\n",
      "loss: 0.000023  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 96\n",
      "---------------------------\n",
      "loss: 0.000150  [ 3200/209452]\n",
      "loss: 0.000067  [ 6400/209452]\n",
      "loss: 0.000107  [ 9600/209452]\n",
      "loss: 0.001856  [12800/209452]\n",
      "loss: 0.000031  [16000/209452]\n",
      "loss: 0.000021  [19200/209452]\n",
      "loss: 0.000032  [22400/209452]\n",
      "loss: 0.003882  [25600/209452]\n",
      "loss: 0.000020  [28800/209452]\n",
      "loss: 0.000568  [32000/209452]\n",
      "loss: 0.000093  [35200/209452]\n",
      "loss: 0.000029  [38400/209452]\n",
      "loss: 0.000012  [41600/209452]\n",
      "loss: 0.000112  [44800/209452]\n",
      "loss: 0.000069  [48000/209452]\n",
      "loss: 0.000124  [51200/209452]\n",
      "loss: 0.000012  [54400/209452]\n",
      "loss: 0.000150  [57600/209452]\n",
      "loss: 0.000004  [60800/209452]\n",
      "loss: 0.000043  [64000/209452]\n",
      "loss: 0.000289  [67200/209452]\n",
      "loss: 0.000097  [70400/209452]\n",
      "loss: 0.000002  [73600/209452]\n",
      "loss: 0.000038  [76800/209452]\n",
      "loss: 0.000401  [80000/209452]\n",
      "loss: 0.000252  [83200/209452]\n",
      "loss: 0.000078  [86400/209452]\n",
      "loss: 0.000035  [89600/209452]\n",
      "loss: 0.000856  [92800/209452]\n",
      "loss: 0.000092  [96000/209452]\n",
      "loss: 0.000081  [99200/209452]\n",
      "loss: 0.000001  [102400/209452]\n",
      "loss: 0.000024  [105600/209452]\n",
      "loss: 0.000215  [108800/209452]\n",
      "loss: 0.000013  [112000/209452]\n",
      "loss: 0.000333  [115200/209452]\n",
      "loss: 0.000046  [118400/209452]\n",
      "loss: 0.000059  [121600/209452]\n",
      "loss: 0.000053  [124800/209452]\n",
      "loss: 0.001780  [128000/209452]\n",
      "loss: 0.000088  [131200/209452]\n",
      "loss: 0.000277  [134400/209452]\n",
      "loss: 0.000074  [137600/209452]\n",
      "loss: 0.000071  [140800/209452]\n",
      "loss: 0.000390  [144000/209452]\n",
      "loss: 0.000013  [147200/209452]\n",
      "loss: 0.000047  [150400/209452]\n",
      "loss: 0.000001  [153600/209452]\n",
      "loss: 0.000020  [156800/209452]\n",
      "loss: 0.000046  [160000/209452]\n",
      "loss: 0.000156  [163200/209452]\n",
      "loss: 0.000094  [166400/209452]\n",
      "loss: 0.000076  [169600/209452]\n",
      "loss: 0.000057  [172800/209452]\n",
      "loss: 0.000102  [176000/209452]\n",
      "loss: 0.000182  [179200/209452]\n",
      "loss: 0.000166  [182400/209452]\n",
      "loss: 0.000065  [185600/209452]\n",
      "loss: 0.000037  [188800/209452]\n",
      "loss: 0.000016  [192000/209452]\n",
      "loss: 0.000004  [195200/209452]\n",
      "loss: 0.000027  [198400/209452]\n",
      "loss: 0.002105  [201600/209452]\n",
      "loss: 0.000070  [204800/209452]\n",
      "loss: 0.000014  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002704 \n",
      "\n",
      "Epoch 97\n",
      "---------------------------\n",
      "loss: 0.001089  [ 3200/209452]\n",
      "loss: 0.000274  [ 6400/209452]\n",
      "loss: 0.000039  [ 9600/209452]\n",
      "loss: 0.000013  [12800/209452]\n",
      "loss: 0.000252  [16000/209452]\n",
      "loss: 0.000053  [19200/209452]\n",
      "loss: 0.000068  [22400/209452]\n",
      "loss: 0.000015  [25600/209452]\n",
      "loss: 0.000007  [28800/209452]\n",
      "loss: 0.000012  [32000/209452]\n",
      "loss: 0.000050  [35200/209452]\n",
      "loss: 0.000265  [38400/209452]\n",
      "loss: 0.000079  [41600/209452]\n",
      "loss: 0.000002  [44800/209452]\n",
      "loss: 0.000057  [48000/209452]\n",
      "loss: 0.001108  [51200/209452]\n",
      "loss: 0.000037  [54400/209452]\n",
      "loss: 0.000013  [57600/209452]\n",
      "loss: 0.000018  [60800/209452]\n",
      "loss: 0.000069  [64000/209452]\n",
      "loss: 0.000179  [67200/209452]\n",
      "loss: 0.000127  [70400/209452]\n",
      "loss: 0.000007  [73600/209452]\n",
      "loss: 0.000368  [76800/209452]\n",
      "loss: 0.000034  [80000/209452]\n",
      "loss: 0.000350  [83200/209452]\n",
      "loss: 0.000235  [86400/209452]\n",
      "loss: 0.000109  [89600/209452]\n",
      "loss: 0.000071  [92800/209452]\n",
      "loss: 0.001799  [96000/209452]\n",
      "loss: 0.000024  [99200/209452]\n",
      "loss: 0.000129  [102400/209452]\n",
      "loss: 0.000010  [105600/209452]\n",
      "loss: 0.000568  [108800/209452]\n",
      "loss: 0.000850  [112000/209452]\n",
      "loss: 0.000464  [115200/209452]\n",
      "loss: 0.000011  [118400/209452]\n",
      "loss: 0.000115  [121600/209452]\n",
      "loss: 0.000039  [124800/209452]\n",
      "loss: 0.000169  [128000/209452]\n",
      "loss: 0.000202  [131200/209452]\n",
      "loss: 0.000017  [134400/209452]\n",
      "loss: 0.000008  [137600/209452]\n",
      "loss: 0.000007  [140800/209452]\n",
      "loss: 0.000017  [144000/209452]\n",
      "loss: 0.000051  [147200/209452]\n",
      "loss: 0.000028  [150400/209452]\n",
      "loss: 0.001217  [153600/209452]\n",
      "loss: 0.000013  [156800/209452]\n",
      "loss: 0.000068  [160000/209452]\n",
      "loss: 0.000065  [163200/209452]\n",
      "loss: 0.000015  [166400/209452]\n",
      "loss: 0.000026  [169600/209452]\n",
      "loss: 0.000011  [172800/209452]\n",
      "loss: 0.000150  [176000/209452]\n",
      "loss: 0.000006  [179200/209452]\n",
      "loss: 0.000195  [182400/209452]\n",
      "loss: 0.000103  [185600/209452]\n",
      "loss: 0.000088  [188800/209452]\n",
      "loss: 0.001102  [192000/209452]\n",
      "loss: 0.000024  [195200/209452]\n",
      "loss: 0.000020  [198400/209452]\n",
      "loss: 0.000024  [201600/209452]\n",
      "loss: 0.000033  [204800/209452]\n",
      "loss: 0.000140  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002661 \n",
      "\n",
      "Epoch 98\n",
      "---------------------------\n",
      "loss: 0.000368  [ 3200/209452]\n",
      "loss: 0.000040  [ 6400/209452]\n",
      "loss: 0.000016  [ 9600/209452]\n",
      "loss: 0.000201  [12800/209452]\n",
      "loss: 0.000082  [16000/209452]\n",
      "loss: 0.000037  [19200/209452]\n",
      "loss: 0.000004  [22400/209452]\n",
      "loss: 0.000138  [25600/209452]\n",
      "loss: 0.000026  [28800/209452]\n",
      "loss: 0.000070  [32000/209452]\n",
      "loss: 0.000020  [35200/209452]\n",
      "loss: 0.000035  [38400/209452]\n",
      "loss: 0.000021  [41600/209452]\n",
      "loss: 0.000019  [44800/209452]\n",
      "loss: 0.000006  [48000/209452]\n",
      "loss: 0.000063  [51200/209452]\n",
      "loss: 0.000024  [54400/209452]\n",
      "loss: 0.000073  [57600/209452]\n",
      "loss: 0.000142  [60800/209452]\n",
      "loss: 0.000034  [64000/209452]\n",
      "loss: 0.000042  [67200/209452]\n",
      "loss: 0.000021  [70400/209452]\n",
      "loss: 0.000047  [73600/209452]\n",
      "loss: 0.000069  [76800/209452]\n",
      "loss: 0.000066  [80000/209452]\n",
      "loss: 0.000011  [83200/209452]\n",
      "loss: 0.000077  [86400/209452]\n",
      "loss: 0.000265  [89600/209452]\n",
      "loss: 0.000488  [92800/209452]\n",
      "loss: 0.000029  [96000/209452]\n",
      "loss: 0.000041  [99200/209452]\n",
      "loss: 0.000112  [102400/209452]\n",
      "loss: 0.000015  [105600/209452]\n",
      "loss: 0.000006  [108800/209452]\n",
      "loss: 0.000237  [112000/209452]\n",
      "loss: 0.000037  [115200/209452]\n",
      "loss: 0.000010  [118400/209452]\n",
      "loss: 0.000046  [121600/209452]\n",
      "loss: 0.000042  [124800/209452]\n",
      "loss: 0.000154  [128000/209452]\n",
      "loss: 0.000069  [131200/209452]\n",
      "loss: 0.000027  [134400/209452]\n",
      "loss: 0.001230  [137600/209452]\n",
      "loss: 0.000054  [140800/209452]\n",
      "loss: 0.000130  [144000/209452]\n",
      "loss: 0.000027  [147200/209452]\n",
      "loss: 0.000023  [150400/209452]\n",
      "loss: 0.000034  [153600/209452]\n",
      "loss: 0.000060  [156800/209452]\n",
      "loss: 0.000077  [160000/209452]\n",
      "loss: 0.001782  [163200/209452]\n",
      "loss: 0.000035  [166400/209452]\n",
      "loss: 0.000127  [169600/209452]\n",
      "loss: 0.000107  [172800/209452]\n",
      "loss: 0.000057  [176000/209452]\n",
      "loss: 0.000309  [179200/209452]\n",
      "loss: 0.000070  [182400/209452]\n",
      "loss: 0.000390  [185600/209452]\n",
      "loss: 0.001773  [188800/209452]\n",
      "loss: 0.000038  [192000/209452]\n",
      "loss: 0.000013  [195200/209452]\n",
      "loss: 0.000063  [198400/209452]\n",
      "loss: 0.000017  [201600/209452]\n",
      "loss: 0.000084  [204800/209452]\n",
      "loss: 0.000013  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 99\n",
      "---------------------------\n",
      "loss: 0.000010  [ 3200/209452]\n",
      "loss: 0.000045  [ 6400/209452]\n",
      "loss: 0.000066  [ 9600/209452]\n",
      "loss: 0.000062  [12800/209452]\n",
      "loss: 0.000302  [16000/209452]\n",
      "loss: 0.000002  [19200/209452]\n",
      "loss: 0.000042  [22400/209452]\n",
      "loss: 0.000308  [25600/209452]\n",
      "loss: 0.000618  [28800/209452]\n",
      "loss: 0.000015  [32000/209452]\n",
      "loss: 0.000009  [35200/209452]\n",
      "loss: 0.000009  [38400/209452]\n",
      "loss: 0.000139  [41600/209452]\n",
      "loss: 0.000022  [44800/209452]\n",
      "loss: 0.000233  [48000/209452]\n",
      "loss: 0.000033  [51200/209452]\n",
      "loss: 0.000201  [54400/209452]\n",
      "loss: 0.000039  [57600/209452]\n",
      "loss: 0.000077  [60800/209452]\n",
      "loss: 0.000264  [64000/209452]\n",
      "loss: 0.000086  [67200/209452]\n",
      "loss: 0.000047  [70400/209452]\n",
      "loss: 0.000017  [73600/209452]\n",
      "loss: 0.000015  [76800/209452]\n",
      "loss: 0.000080  [80000/209452]\n",
      "loss: 0.000001  [83200/209452]\n",
      "loss: 0.000011  [86400/209452]\n",
      "loss: 0.000011  [89600/209452]\n",
      "loss: 0.000458  [92800/209452]\n",
      "loss: 0.000054  [96000/209452]\n",
      "loss: 0.000020  [99200/209452]\n",
      "loss: 0.000049  [102400/209452]\n",
      "loss: 0.000028  [105600/209452]\n",
      "loss: 0.000009  [108800/209452]\n",
      "loss: 0.000059  [112000/209452]\n",
      "loss: 0.000072  [115200/209452]\n",
      "loss: 0.000032  [118400/209452]\n",
      "loss: 0.000212  [121600/209452]\n",
      "loss: 0.001316  [124800/209452]\n",
      "loss: 0.000019  [128000/209452]\n",
      "loss: 0.000051  [131200/209452]\n",
      "loss: 0.000072  [134400/209452]\n",
      "loss: 0.000028  [137600/209452]\n",
      "loss: 0.000864  [140800/209452]\n",
      "loss: 0.000484  [144000/209452]\n",
      "loss: 0.000027  [147200/209452]\n",
      "loss: 0.000049  [150400/209452]\n",
      "loss: 0.000018  [153600/209452]\n",
      "loss: 0.000024  [156800/209452]\n",
      "loss: 0.000073  [160000/209452]\n",
      "loss: 0.000015  [163200/209452]\n",
      "loss: 0.000128  [166400/209452]\n",
      "loss: 0.000360  [169600/209452]\n",
      "loss: 0.000386  [172800/209452]\n",
      "loss: 0.000003  [176000/209452]\n",
      "loss: 0.000032  [179200/209452]\n",
      "loss: 0.000088  [182400/209452]\n",
      "loss: 0.000071  [185600/209452]\n",
      "loss: 0.000045  [188800/209452]\n",
      "loss: 0.000014  [192000/209452]\n",
      "loss: 0.000171  [195200/209452]\n",
      "loss: 0.000200  [198400/209452]\n",
      "loss: 0.000154  [201600/209452]\n",
      "loss: 0.000139  [204800/209452]\n",
      "loss: 0.002245  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002723 \n",
      "\n",
      "Epoch 100\n",
      "---------------------------\n",
      "loss: 0.000015  [ 3200/209452]\n",
      "loss: 0.000043  [ 6400/209452]\n",
      "loss: 0.000088  [ 9600/209452]\n",
      "loss: 0.000273  [12800/209452]\n",
      "loss: 0.000032  [16000/209452]\n",
      "loss: 0.000036  [19200/209452]\n",
      "loss: 0.000047  [22400/209452]\n",
      "loss: 0.000407  [25600/209452]\n",
      "loss: 0.000091  [28800/209452]\n",
      "loss: 0.000018  [32000/209452]\n",
      "loss: 0.000014  [35200/209452]\n",
      "loss: 0.001121  [38400/209452]\n",
      "loss: 0.000138  [41600/209452]\n",
      "loss: 0.000067  [44800/209452]\n",
      "loss: 0.000015  [48000/209452]\n",
      "loss: 0.000023  [51200/209452]\n",
      "loss: 0.000031  [54400/209452]\n",
      "loss: 0.000133  [57600/209452]\n",
      "loss: 0.000150  [60800/209452]\n",
      "loss: 0.000109  [64000/209452]\n",
      "loss: 0.000009  [67200/209452]\n",
      "loss: 0.000080  [70400/209452]\n",
      "loss: 0.000195  [73600/209452]\n",
      "loss: 0.000016  [76800/209452]\n",
      "loss: 0.000008  [80000/209452]\n",
      "loss: 0.000036  [83200/209452]\n",
      "loss: 0.000147  [86400/209452]\n",
      "loss: 0.000050  [89600/209452]\n",
      "loss: 0.000004  [92800/209452]\n",
      "loss: 0.000421  [96000/209452]\n",
      "loss: 0.000140  [99200/209452]\n",
      "loss: 0.000127  [102400/209452]\n",
      "loss: 0.000227  [105600/209452]\n",
      "loss: 0.000012  [108800/209452]\n",
      "loss: 0.000021  [112000/209452]\n",
      "loss: 0.000009  [115200/209452]\n",
      "loss: 0.000049  [118400/209452]\n",
      "loss: 0.000090  [121600/209452]\n",
      "loss: 0.000129  [124800/209452]\n",
      "loss: 0.000016  [128000/209452]\n",
      "loss: 0.000072  [131200/209452]\n",
      "loss: 0.000188  [134400/209452]\n",
      "loss: 0.000282  [137600/209452]\n",
      "loss: 0.000007  [140800/209452]\n",
      "loss: 0.000019  [144000/209452]\n",
      "loss: 0.002243  [147200/209452]\n",
      "loss: 0.000059  [150400/209452]\n",
      "loss: 0.000070  [153600/209452]\n",
      "loss: 0.000206  [156800/209452]\n",
      "loss: 0.000086  [160000/209452]\n",
      "loss: 0.000020  [163200/209452]\n",
      "loss: 0.000460  [166400/209452]\n",
      "loss: 0.000188  [169600/209452]\n",
      "loss: 0.000028  [172800/209452]\n",
      "loss: 0.000035  [176000/209452]\n",
      "loss: 0.000010  [179200/209452]\n",
      "loss: 0.000060  [182400/209452]\n",
      "loss: 0.000039  [185600/209452]\n",
      "loss: 0.000127  [188800/209452]\n",
      "loss: 0.000026  [192000/209452]\n",
      "loss: 0.000069  [195200/209452]\n",
      "loss: 0.000008  [198400/209452]\n",
      "loss: 0.000025  [201600/209452]\n",
      "loss: 0.000167  [204800/209452]\n",
      "loss: 0.000046  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.002670 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(hsd_train_dataloader, hsd_model, loss_fn, hsd_optimizer)\n",
    "    test_loop(hsd_test_dataloader, hsd_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f8dc07ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_accs)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13bea00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_losses[50:])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bc32a",
   "metadata": {},
   "source": [
    "*Best Performance*\n",
    "\n",
    "dataset size = 261,816\n",
    "train/test split = 80/20\n",
    "\n",
    "learning rate = 0.01\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "Accuracy = 100.0% (first at epoch 25 but bounces around a bit)\n",
    "Loss = 0.001933"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163ea41",
   "metadata": {},
   "source": [
    "The saved model achieved 0.002006 with parameters .02, 80.\n",
    "Trying 100 epochs resulted in worse performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c0e73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hsd_NeuralNetwork()\n",
    "torch.save(model, \"hsd_imit_nn.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
