{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75c69788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a02e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for data processing\n",
    "def card_to_num(card):\n",
    "    raw_rank = card[:-1]\n",
    "    \n",
    "    ranks = {\n",
    "        '2' : 0,\n",
    "        '3' : 1,\n",
    "        '4' : 2, \n",
    "        '5' : 3,\n",
    "        '6' : 4, \n",
    "        '7' : 5, \n",
    "        '8' : 6, \n",
    "        '9' : 7, \n",
    "        '10': 8, \n",
    "        'J' : 9, \n",
    "        'Q' : 10, \n",
    "        'K' : 11, \n",
    "        'A': 12\n",
    "    }\n",
    "\n",
    "    return ranks[raw_rank]\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_num(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1222d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_or_not_raw_df = pd.read_csv('CSVs/split_or_not.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb6ad32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_train_df, sn_test_df = train_test_split(split_or_not_raw_df, test_size=0.2)\n",
    "\n",
    "def clean_up(dataframe_raw):\n",
    "    # Cleaned split_or_not\n",
    "    dataframe_raw['dealer_upcard'] = dataframe_raw['dealer_upcard'].apply(card_to_num)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(hand_to_list)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(lambda hand: hand[0])\n",
    "    dataframe_clean = dataframe_raw.rename(columns = {'player_hand':'player_upcard'})\n",
    "\n",
    "    # Turning into tensor matrices\n",
    "    # split_or_not\n",
    "    x1 = torch.tensor(dataframe_clean['player_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "    x2 = torch.tensor(dataframe_clean['dealer_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "    y = torch.tensor(dataframe_clean['result'].values, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "    X = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "    return Blackjack_Dataset(X,y)\n",
    "\n",
    "sn_train_dataset = clean_up(sn_train_df)\n",
    "sn_test_dataset = clean_up(sn_test_df)\n",
    "\n",
    "sn_train_dataloader = DataLoader(sn_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "sn_test_dataloader = DataLoader(sn_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4dbe5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            probs = torch.sigmoid(pred)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            correct += (preds.view(-1) == y.view(-1)).float().sum()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "659c20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sn_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "sn_model = sn_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "epochs = 20\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "sn_optimizer = torch.optim.SGD(sn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e267a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.623670  [ 3200/141921]\n",
      "loss: 0.606927  [ 6400/141921]\n",
      "loss: 0.584664  [ 9600/141921]\n",
      "loss: 0.603284  [12800/141921]\n",
      "loss: 0.537882  [16000/141921]\n",
      "loss: 0.697550  [19200/141921]\n",
      "loss: 0.609404  [22400/141921]\n",
      "loss: 0.706480  [25600/141921]\n",
      "loss: 0.667958  [28800/141921]\n",
      "loss: 0.587952  [32000/141921]\n",
      "loss: 0.626983  [35200/141921]\n",
      "loss: 0.640690  [38400/141921]\n",
      "loss: 0.606481  [41600/141921]\n",
      "loss: 0.606611  [44800/141921]\n",
      "loss: 0.639164  [48000/141921]\n",
      "loss: 0.627495  [51200/141921]\n",
      "loss: 0.614264  [54400/141921]\n",
      "loss: 0.676484  [57600/141921]\n",
      "loss: 0.564499  [60800/141921]\n",
      "loss: 0.506050  [64000/141921]\n",
      "loss: 0.539915  [67200/141921]\n",
      "loss: 0.518879  [70400/141921]\n",
      "loss: 0.814473  [73600/141921]\n",
      "loss: 0.640977  [76800/141921]\n",
      "loss: 0.466473  [80000/141921]\n",
      "loss: 0.631725  [83200/141921]\n",
      "loss: 0.636706  [86400/141921]\n",
      "loss: 0.597137  [89600/141921]\n",
      "loss: 0.629900  [92800/141921]\n",
      "loss: 0.558068  [96000/141921]\n",
      "loss: 0.620879  [99200/141921]\n",
      "loss: 0.475795  [102400/141921]\n",
      "loss: 0.504021  [105600/141921]\n",
      "loss: 0.532592  [108800/141921]\n",
      "loss: 0.650451  [112000/141921]\n",
      "loss: 0.608044  [115200/141921]\n",
      "loss: 0.726518  [118400/141921]\n",
      "loss: 0.696722  [121600/141921]\n",
      "loss: 0.612881  [124800/141921]\n",
      "loss: 0.497761  [128000/141921]\n",
      "loss: 0.483626  [131200/141921]\n",
      "loss: 0.527068  [134400/141921]\n",
      "loss: 0.535756  [137600/141921]\n",
      "loss: 0.651674  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.579253 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 0.656332  [ 3200/141921]\n",
      "loss: 0.637449  [ 6400/141921]\n",
      "loss: 0.568737  [ 9600/141921]\n",
      "loss: 0.433423  [12800/141921]\n",
      "loss: 0.491027  [16000/141921]\n",
      "loss: 0.596350  [19200/141921]\n",
      "loss: 0.472565  [22400/141921]\n",
      "loss: 0.460470  [25600/141921]\n",
      "loss: 0.564248  [28800/141921]\n",
      "loss: 0.591509  [32000/141921]\n",
      "loss: 0.548502  [35200/141921]\n",
      "loss: 0.631559  [38400/141921]\n",
      "loss: 0.563847  [41600/141921]\n",
      "loss: 0.552856  [44800/141921]\n",
      "loss: 0.588749  [48000/141921]\n",
      "loss: 0.586226  [51200/141921]\n",
      "loss: 0.691774  [54400/141921]\n",
      "loss: 0.514057  [57600/141921]\n",
      "loss: 0.532658  [60800/141921]\n",
      "loss: 0.638861  [64000/141921]\n",
      "loss: 0.533518  [67200/141921]\n",
      "loss: 0.617020  [70400/141921]\n",
      "loss: 0.513036  [73600/141921]\n",
      "loss: 0.558598  [76800/141921]\n",
      "loss: 0.534546  [80000/141921]\n",
      "loss: 0.466330  [83200/141921]\n",
      "loss: 0.624005  [86400/141921]\n",
      "loss: 0.684130  [89600/141921]\n",
      "loss: 0.549182  [92800/141921]\n",
      "loss: 0.591407  [96000/141921]\n",
      "loss: 0.583685  [99200/141921]\n",
      "loss: 0.703343  [102400/141921]\n",
      "loss: 0.598899  [105600/141921]\n",
      "loss: 0.563712  [108800/141921]\n",
      "loss: 0.580788  [112000/141921]\n",
      "loss: 0.693571  [115200/141921]\n",
      "loss: 0.733312  [118400/141921]\n",
      "loss: 0.546347  [121600/141921]\n",
      "loss: 0.519776  [124800/141921]\n",
      "loss: 0.498440  [128000/141921]\n",
      "loss: 0.479993  [131200/141921]\n",
      "loss: 0.548353  [134400/141921]\n",
      "loss: 0.568674  [137600/141921]\n",
      "loss: 0.473949  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.571544 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 0.590706  [ 3200/141921]\n",
      "loss: 0.635254  [ 6400/141921]\n",
      "loss: 0.623749  [ 9600/141921]\n",
      "loss: 0.568463  [12800/141921]\n",
      "loss: 0.591081  [16000/141921]\n",
      "loss: 0.574823  [19200/141921]\n",
      "loss: 0.519746  [22400/141921]\n",
      "loss: 0.571648  [25600/141921]\n",
      "loss: 0.434540  [28800/141921]\n",
      "loss: 0.548611  [32000/141921]\n",
      "loss: 0.617423  [35200/141921]\n",
      "loss: 0.509667  [38400/141921]\n",
      "loss: 0.544672  [41600/141921]\n",
      "loss: 0.601123  [44800/141921]\n",
      "loss: 0.513527  [48000/141921]\n",
      "loss: 0.519318  [51200/141921]\n",
      "loss: 0.628621  [54400/141921]\n",
      "loss: 0.593669  [57600/141921]\n",
      "loss: 0.558405  [60800/141921]\n",
      "loss: 0.434182  [64000/141921]\n",
      "loss: 0.503590  [67200/141921]\n",
      "loss: 0.500635  [70400/141921]\n",
      "loss: 0.675735  [73600/141921]\n",
      "loss: 0.661635  [76800/141921]\n",
      "loss: 0.633184  [80000/141921]\n",
      "loss: 0.524423  [83200/141921]\n",
      "loss: 0.529124  [86400/141921]\n",
      "loss: 0.447372  [89600/141921]\n",
      "loss: 0.612543  [92800/141921]\n",
      "loss: 0.536930  [96000/141921]\n",
      "loss: 0.504106  [99200/141921]\n",
      "loss: 0.547243  [102400/141921]\n",
      "loss: 0.584187  [105600/141921]\n",
      "loss: 0.458088  [108800/141921]\n",
      "loss: 0.621107  [112000/141921]\n",
      "loss: 0.488393  [115200/141921]\n",
      "loss: 0.677599  [118400/141921]\n",
      "loss: 0.562357  [121600/141921]\n",
      "loss: 0.534851  [124800/141921]\n",
      "loss: 0.564509  [128000/141921]\n",
      "loss: 0.648476  [131200/141921]\n",
      "loss: 0.614774  [134400/141921]\n",
      "loss: 0.524094  [137600/141921]\n",
      "loss: 0.724456  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.565656 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 0.560939  [ 3200/141921]\n",
      "loss: 0.560311  [ 6400/141921]\n",
      "loss: 0.595026  [ 9600/141921]\n",
      "loss: 0.527785  [12800/141921]\n",
      "loss: 0.496009  [16000/141921]\n",
      "loss: 0.608241  [19200/141921]\n",
      "loss: 0.724146  [22400/141921]\n",
      "loss: 0.467193  [25600/141921]\n",
      "loss: 0.709126  [28800/141921]\n",
      "loss: 0.476972  [32000/141921]\n",
      "loss: 0.561540  [35200/141921]\n",
      "loss: 0.551748  [38400/141921]\n",
      "loss: 0.599833  [41600/141921]\n",
      "loss: 0.666113  [44800/141921]\n",
      "loss: 0.666442  [48000/141921]\n",
      "loss: 0.691397  [51200/141921]\n",
      "loss: 0.643560  [54400/141921]\n",
      "loss: 0.686320  [57600/141921]\n",
      "loss: 0.581290  [60800/141921]\n",
      "loss: 0.672780  [64000/141921]\n",
      "loss: 0.413714  [67200/141921]\n",
      "loss: 0.477333  [70400/141921]\n",
      "loss: 0.606281  [73600/141921]\n",
      "loss: 0.577262  [76800/141921]\n",
      "loss: 0.472245  [80000/141921]\n",
      "loss: 0.497307  [83200/141921]\n",
      "loss: 0.556279  [86400/141921]\n",
      "loss: 0.503055  [89600/141921]\n",
      "loss: 0.486340  [92800/141921]\n",
      "loss: 0.515526  [96000/141921]\n",
      "loss: 0.569566  [99200/141921]\n",
      "loss: 0.619582  [102400/141921]\n",
      "loss: 0.540690  [105600/141921]\n",
      "loss: 0.654829  [108800/141921]\n",
      "loss: 0.550434  [112000/141921]\n",
      "loss: 0.506658  [115200/141921]\n",
      "loss: 0.444335  [118400/141921]\n",
      "loss: 0.583139  [121600/141921]\n",
      "loss: 0.512461  [124800/141921]\n",
      "loss: 0.574103  [128000/141921]\n",
      "loss: 0.601977  [131200/141921]\n",
      "loss: 0.587489  [134400/141921]\n",
      "loss: 0.597169  [137600/141921]\n",
      "loss: 0.575763  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.560664 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 0.489078  [ 3200/141921]\n",
      "loss: 0.626855  [ 6400/141921]\n",
      "loss: 0.585881  [ 9600/141921]\n",
      "loss: 0.613141  [12800/141921]\n",
      "loss: 0.588175  [16000/141921]\n",
      "loss: 0.599568  [19200/141921]\n",
      "loss: 0.552078  [22400/141921]\n",
      "loss: 0.490026  [25600/141921]\n",
      "loss: 0.452733  [28800/141921]\n",
      "loss: 0.492922  [32000/141921]\n",
      "loss: 0.500049  [35200/141921]\n",
      "loss: 0.511610  [38400/141921]\n",
      "loss: 0.562858  [41600/141921]\n",
      "loss: 0.473372  [44800/141921]\n",
      "loss: 0.550729  [48000/141921]\n",
      "loss: 0.488509  [51200/141921]\n",
      "loss: 0.529309  [54400/141921]\n",
      "loss: 0.560833  [57600/141921]\n",
      "loss: 0.496954  [60800/141921]\n",
      "loss: 0.530298  [64000/141921]\n",
      "loss: 0.654052  [67200/141921]\n",
      "loss: 0.405173  [70400/141921]\n",
      "loss: 0.515453  [73600/141921]\n",
      "loss: 0.524937  [76800/141921]\n",
      "loss: 0.643616  [80000/141921]\n",
      "loss: 0.477858  [83200/141921]\n",
      "loss: 0.408445  [86400/141921]\n",
      "loss: 0.481079  [89600/141921]\n",
      "loss: 0.402934  [92800/141921]\n",
      "loss: 0.468351  [96000/141921]\n",
      "loss: 0.552210  [99200/141921]\n",
      "loss: 0.509322  [102400/141921]\n",
      "loss: 0.512428  [105600/141921]\n",
      "loss: 0.488239  [108800/141921]\n",
      "loss: 0.502846  [112000/141921]\n",
      "loss: 0.595190  [115200/141921]\n",
      "loss: 0.515912  [118400/141921]\n",
      "loss: 0.609961  [121600/141921]\n",
      "loss: 0.679402  [124800/141921]\n",
      "loss: 0.660396  [128000/141921]\n",
      "loss: 0.555291  [131200/141921]\n",
      "loss: 0.512463  [134400/141921]\n",
      "loss: 0.522896  [137600/141921]\n",
      "loss: 0.633494  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.556548 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 0.566351  [ 3200/141921]\n",
      "loss: 0.559521  [ 6400/141921]\n",
      "loss: 0.661896  [ 9600/141921]\n",
      "loss: 0.488426  [12800/141921]\n",
      "loss: 0.712720  [16000/141921]\n",
      "loss: 0.719060  [19200/141921]\n",
      "loss: 0.628379  [22400/141921]\n",
      "loss: 0.564005  [25600/141921]\n",
      "loss: 0.597156  [28800/141921]\n",
      "loss: 0.511698  [32000/141921]\n",
      "loss: 0.725013  [35200/141921]\n",
      "loss: 0.408260  [38400/141921]\n",
      "loss: 0.511645  [41600/141921]\n",
      "loss: 0.458883  [44800/141921]\n",
      "loss: 0.489009  [48000/141921]\n",
      "loss: 0.513325  [51200/141921]\n",
      "loss: 0.557908  [54400/141921]\n",
      "loss: 0.552666  [57600/141921]\n",
      "loss: 0.543456  [60800/141921]\n",
      "loss: 0.526487  [64000/141921]\n",
      "loss: 0.499554  [67200/141921]\n",
      "loss: 0.663920  [70400/141921]\n",
      "loss: 0.520538  [73600/141921]\n",
      "loss: 0.539306  [76800/141921]\n",
      "loss: 0.430920  [80000/141921]\n",
      "loss: 0.596962  [83200/141921]\n",
      "loss: 0.524345  [86400/141921]\n",
      "loss: 0.473141  [89600/141921]\n",
      "loss: 0.641689  [92800/141921]\n",
      "loss: 0.486857  [96000/141921]\n",
      "loss: 0.613302  [99200/141921]\n",
      "loss: 0.504090  [102400/141921]\n",
      "loss: 0.580379  [105600/141921]\n",
      "loss: 0.442985  [108800/141921]\n",
      "loss: 0.535906  [112000/141921]\n",
      "loss: 0.561822  [115200/141921]\n",
      "loss: 0.458200  [118400/141921]\n",
      "loss: 0.561953  [121600/141921]\n",
      "loss: 0.515717  [124800/141921]\n",
      "loss: 0.632716  [128000/141921]\n",
      "loss: 0.657022  [131200/141921]\n",
      "loss: 0.551830  [134400/141921]\n",
      "loss: 0.395060  [137600/141921]\n",
      "loss: 0.493714  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.553116 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 0.480551  [ 3200/141921]\n",
      "loss: 0.629326  [ 6400/141921]\n",
      "loss: 0.550764  [ 9600/141921]\n",
      "loss: 0.568669  [12800/141921]\n",
      "loss: 0.677999  [16000/141921]\n",
      "loss: 0.587626  [19200/141921]\n",
      "loss: 0.440175  [22400/141921]\n",
      "loss: 0.545197  [25600/141921]\n",
      "loss: 0.461335  [28800/141921]\n",
      "loss: 0.478774  [32000/141921]\n",
      "loss: 0.614964  [35200/141921]\n",
      "loss: 0.670877  [38400/141921]\n",
      "loss: 0.587261  [41600/141921]\n",
      "loss: 0.655933  [44800/141921]\n",
      "loss: 0.706664  [48000/141921]\n",
      "loss: 0.483915  [51200/141921]\n",
      "loss: 0.509975  [54400/141921]\n",
      "loss: 0.498128  [57600/141921]\n",
      "loss: 0.512661  [60800/141921]\n",
      "loss: 0.528101  [64000/141921]\n",
      "loss: 0.566709  [67200/141921]\n",
      "loss: 0.378831  [70400/141921]\n",
      "loss: 0.486140  [73600/141921]\n",
      "loss: 0.702102  [76800/141921]\n",
      "loss: 0.530364  [80000/141921]\n",
      "loss: 0.495759  [83200/141921]\n",
      "loss: 0.570220  [86400/141921]\n",
      "loss: 0.525766  [89600/141921]\n",
      "loss: 0.503570  [92800/141921]\n",
      "loss: 0.678779  [96000/141921]\n",
      "loss: 0.506108  [99200/141921]\n",
      "loss: 0.555051  [102400/141921]\n",
      "loss: 0.609042  [105600/141921]\n",
      "loss: 0.602175  [108800/141921]\n",
      "loss: 0.494725  [112000/141921]\n",
      "loss: 0.586731  [115200/141921]\n",
      "loss: 0.635272  [118400/141921]\n",
      "loss: 0.449972  [121600/141921]\n",
      "loss: 0.638956  [124800/141921]\n",
      "loss: 0.587921  [128000/141921]\n",
      "loss: 0.547121  [131200/141921]\n",
      "loss: 0.690185  [134400/141921]\n",
      "loss: 0.502680  [137600/141921]\n",
      "loss: 0.427807  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.550015 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 0.619081  [ 3200/141921]\n",
      "loss: 0.597407  [ 6400/141921]\n",
      "loss: 0.564067  [ 9600/141921]\n",
      "loss: 0.612098  [12800/141921]\n",
      "loss: 0.511786  [16000/141921]\n",
      "loss: 0.530131  [19200/141921]\n",
      "loss: 0.462740  [22400/141921]\n",
      "loss: 0.494847  [25600/141921]\n",
      "loss: 0.520266  [28800/141921]\n",
      "loss: 0.471607  [32000/141921]\n",
      "loss: 0.548193  [35200/141921]\n",
      "loss: 0.549569  [38400/141921]\n",
      "loss: 0.586556  [41600/141921]\n",
      "loss: 0.622542  [44800/141921]\n",
      "loss: 0.483854  [48000/141921]\n",
      "loss: 0.549671  [51200/141921]\n",
      "loss: 0.472040  [54400/141921]\n",
      "loss: 0.582355  [57600/141921]\n",
      "loss: 0.487152  [60800/141921]\n",
      "loss: 0.535993  [64000/141921]\n",
      "loss: 0.613955  [67200/141921]\n",
      "loss: 0.594611  [70400/141921]\n",
      "loss: 0.398375  [73600/141921]\n",
      "loss: 0.433250  [76800/141921]\n",
      "loss: 0.540343  [80000/141921]\n",
      "loss: 0.575769  [83200/141921]\n",
      "loss: 0.581973  [86400/141921]\n",
      "loss: 0.888186  [89600/141921]\n",
      "loss: 0.621856  [92800/141921]\n",
      "loss: 0.643542  [96000/141921]\n",
      "loss: 0.539963  [99200/141921]\n",
      "loss: 0.539755  [102400/141921]\n",
      "loss: 0.581654  [105600/141921]\n",
      "loss: 0.623854  [108800/141921]\n",
      "loss: 0.544629  [112000/141921]\n",
      "loss: 0.593608  [115200/141921]\n",
      "loss: 0.414415  [118400/141921]\n",
      "loss: 0.529228  [121600/141921]\n",
      "loss: 0.657226  [124800/141921]\n",
      "loss: 0.549526  [128000/141921]\n",
      "loss: 0.518493  [131200/141921]\n",
      "loss: 0.479428  [134400/141921]\n",
      "loss: 0.447323  [137600/141921]\n",
      "loss: 0.695697  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.547678 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 0.534562  [ 3200/141921]\n",
      "loss: 0.534900  [ 6400/141921]\n",
      "loss: 0.469608  [ 9600/141921]\n",
      "loss: 0.486259  [12800/141921]\n",
      "loss: 0.601404  [16000/141921]\n",
      "loss: 0.438245  [19200/141921]\n",
      "loss: 0.513100  [22400/141921]\n",
      "loss: 0.529352  [25600/141921]\n",
      "loss: 0.551622  [28800/141921]\n",
      "loss: 0.615224  [32000/141921]\n",
      "loss: 0.521421  [35200/141921]\n",
      "loss: 0.520099  [38400/141921]\n",
      "loss: 0.546997  [41600/141921]\n",
      "loss: 0.541104  [44800/141921]\n",
      "loss: 0.406171  [48000/141921]\n",
      "loss: 0.733125  [51200/141921]\n",
      "loss: 0.561235  [54400/141921]\n",
      "loss: 0.512819  [57600/141921]\n",
      "loss: 0.630584  [60800/141921]\n",
      "loss: 0.566658  [64000/141921]\n",
      "loss: 0.626009  [67200/141921]\n",
      "loss: 0.501711  [70400/141921]\n",
      "loss: 0.488007  [73600/141921]\n",
      "loss: 0.495184  [76800/141921]\n",
      "loss: 0.593072  [80000/141921]\n",
      "loss: 0.536397  [83200/141921]\n",
      "loss: 0.438722  [86400/141921]\n",
      "loss: 0.407781  [89600/141921]\n",
      "loss: 0.564949  [92800/141921]\n",
      "loss: 0.529123  [96000/141921]\n",
      "loss: 0.466092  [99200/141921]\n",
      "loss: 0.433937  [102400/141921]\n",
      "loss: 0.530742  [105600/141921]\n",
      "loss: 0.535051  [108800/141921]\n",
      "loss: 0.572235  [112000/141921]\n",
      "loss: 0.499275  [115200/141921]\n",
      "loss: 0.574461  [118400/141921]\n",
      "loss: 0.394804  [121600/141921]\n",
      "loss: 0.520722  [124800/141921]\n",
      "loss: 0.556000  [128000/141921]\n",
      "loss: 0.532788  [131200/141921]\n",
      "loss: 0.555770  [134400/141921]\n",
      "loss: 0.539224  [137600/141921]\n",
      "loss: 0.458460  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.545735 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 0.548075  [ 3200/141921]\n",
      "loss: 0.548791  [ 6400/141921]\n",
      "loss: 0.489280  [ 9600/141921]\n",
      "loss: 0.457101  [12800/141921]\n",
      "loss: 0.596969  [16000/141921]\n",
      "loss: 0.628309  [19200/141921]\n",
      "loss: 0.494274  [22400/141921]\n",
      "loss: 0.480652  [25600/141921]\n",
      "loss: 0.580629  [28800/141921]\n",
      "loss: 0.585607  [32000/141921]\n",
      "loss: 0.460283  [35200/141921]\n",
      "loss: 0.768264  [38400/141921]\n",
      "loss: 0.641663  [41600/141921]\n",
      "loss: 0.648224  [44800/141921]\n",
      "loss: 0.516826  [48000/141921]\n",
      "loss: 0.476139  [51200/141921]\n",
      "loss: 0.477509  [54400/141921]\n",
      "loss: 0.486310  [57600/141921]\n",
      "loss: 0.555902  [60800/141921]\n",
      "loss: 0.546303  [64000/141921]\n",
      "loss: 0.557971  [67200/141921]\n",
      "loss: 0.513059  [70400/141921]\n",
      "loss: 0.588454  [73600/141921]\n",
      "loss: 0.706149  [76800/141921]\n",
      "loss: 0.484843  [80000/141921]\n",
      "loss: 0.438649  [83200/141921]\n",
      "loss: 0.596404  [86400/141921]\n",
      "loss: 0.535032  [89600/141921]\n",
      "loss: 0.628582  [92800/141921]\n",
      "loss: 0.593499  [96000/141921]\n",
      "loss: 0.568905  [99200/141921]\n",
      "loss: 0.690237  [102400/141921]\n",
      "loss: 0.586306  [105600/141921]\n",
      "loss: 0.713114  [108800/141921]\n",
      "loss: 0.586577  [112000/141921]\n",
      "loss: 0.553724  [115200/141921]\n",
      "loss: 0.465186  [118400/141921]\n",
      "loss: 0.470923  [121600/141921]\n",
      "loss: 0.508677  [124800/141921]\n",
      "loss: 0.489233  [128000/141921]\n",
      "loss: 0.611624  [131200/141921]\n",
      "loss: 0.556173  [134400/141921]\n",
      "loss: 0.546540  [137600/141921]\n",
      "loss: 0.589303  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.543456 \n",
      "\n",
      "Epoch 11\n",
      "---------------------------\n",
      "loss: 0.551198  [ 3200/141921]\n",
      "loss: 0.521207  [ 6400/141921]\n",
      "loss: 0.618223  [ 9600/141921]\n",
      "loss: 0.474522  [12800/141921]\n",
      "loss: 0.576740  [16000/141921]\n",
      "loss: 0.438073  [19200/141921]\n",
      "loss: 0.538173  [22400/141921]\n",
      "loss: 0.656496  [25600/141921]\n",
      "loss: 0.409657  [28800/141921]\n",
      "loss: 0.465738  [32000/141921]\n",
      "loss: 0.475089  [35200/141921]\n",
      "loss: 0.537185  [38400/141921]\n",
      "loss: 0.518871  [41600/141921]\n",
      "loss: 0.532501  [44800/141921]\n",
      "loss: 0.486045  [48000/141921]\n",
      "loss: 0.490806  [51200/141921]\n",
      "loss: 0.532811  [54400/141921]\n",
      "loss: 0.488345  [57600/141921]\n",
      "loss: 0.572584  [60800/141921]\n",
      "loss: 0.491865  [64000/141921]\n",
      "loss: 0.570932  [67200/141921]\n",
      "loss: 0.496087  [70400/141921]\n",
      "loss: 0.613165  [73600/141921]\n",
      "loss: 0.584218  [76800/141921]\n",
      "loss: 0.528285  [80000/141921]\n",
      "loss: 0.618897  [83200/141921]\n",
      "loss: 0.503121  [86400/141921]\n",
      "loss: 0.543165  [89600/141921]\n",
      "loss: 0.626910  [92800/141921]\n",
      "loss: 0.560614  [96000/141921]\n",
      "loss: 0.583394  [99200/141921]\n",
      "loss: 0.479875  [102400/141921]\n",
      "loss: 0.658947  [105600/141921]\n",
      "loss: 0.530874  [108800/141921]\n",
      "loss: 0.559405  [112000/141921]\n",
      "loss: 0.526074  [115200/141921]\n",
      "loss: 0.571649  [118400/141921]\n",
      "loss: 0.574795  [121600/141921]\n",
      "loss: 0.637703  [124800/141921]\n",
      "loss: 0.531652  [128000/141921]\n",
      "loss: 0.693393  [131200/141921]\n",
      "loss: 0.633456  [134400/141921]\n",
      "loss: 0.385320  [137600/141921]\n",
      "loss: 0.563756  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.542374 \n",
      "\n",
      "Epoch 12\n",
      "---------------------------\n",
      "loss: 0.706310  [ 3200/141921]\n",
      "loss: 0.499898  [ 6400/141921]\n",
      "loss: 0.521469  [ 9600/141921]\n",
      "loss: 0.565180  [12800/141921]\n",
      "loss: 0.559958  [16000/141921]\n",
      "loss: 0.536596  [19200/141921]\n",
      "loss: 0.545739  [22400/141921]\n",
      "loss: 0.536476  [25600/141921]\n",
      "loss: 0.450806  [28800/141921]\n",
      "loss: 0.638774  [32000/141921]\n",
      "loss: 0.625778  [35200/141921]\n",
      "loss: 0.618242  [38400/141921]\n",
      "loss: 0.474067  [41600/141921]\n",
      "loss: 0.663335  [44800/141921]\n",
      "loss: 0.466393  [48000/141921]\n",
      "loss: 0.508491  [51200/141921]\n",
      "loss: 0.614704  [54400/141921]\n",
      "loss: 0.639239  [57600/141921]\n",
      "loss: 0.533388  [60800/141921]\n",
      "loss: 0.576353  [64000/141921]\n",
      "loss: 0.688218  [67200/141921]\n",
      "loss: 0.545516  [70400/141921]\n",
      "loss: 0.577467  [73600/141921]\n",
      "loss: 0.498032  [76800/141921]\n",
      "loss: 0.486375  [80000/141921]\n",
      "loss: 0.620981  [83200/141921]\n",
      "loss: 0.434595  [86400/141921]\n",
      "loss: 0.540124  [89600/141921]\n",
      "loss: 0.525858  [92800/141921]\n",
      "loss: 0.469955  [96000/141921]\n",
      "loss: 0.531735  [99200/141921]\n",
      "loss: 0.510670  [102400/141921]\n",
      "loss: 0.516858  [105600/141921]\n",
      "loss: 0.528919  [108800/141921]\n",
      "loss: 0.533026  [112000/141921]\n",
      "loss: 0.572582  [115200/141921]\n",
      "loss: 0.471583  [118400/141921]\n",
      "loss: 0.587564  [121600/141921]\n",
      "loss: 0.521964  [124800/141921]\n",
      "loss: 0.489130  [128000/141921]\n",
      "loss: 0.546587  [131200/141921]\n",
      "loss: 0.518047  [134400/141921]\n",
      "loss: 0.559071  [137600/141921]\n",
      "loss: 0.448759  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.540374 \n",
      "\n",
      "Epoch 13\n",
      "---------------------------\n",
      "loss: 0.479682  [ 3200/141921]\n",
      "loss: 0.536010  [ 6400/141921]\n",
      "loss: 0.729677  [ 9600/141921]\n",
      "loss: 0.517568  [12800/141921]\n",
      "loss: 0.571484  [16000/141921]\n",
      "loss: 0.492149  [19200/141921]\n",
      "loss: 0.430243  [22400/141921]\n",
      "loss: 0.544396  [25600/141921]\n",
      "loss: 0.762316  [28800/141921]\n",
      "loss: 0.742589  [32000/141921]\n",
      "loss: 0.505593  [35200/141921]\n",
      "loss: 0.440140  [38400/141921]\n",
      "loss: 0.708823  [41600/141921]\n",
      "loss: 0.592341  [44800/141921]\n",
      "loss: 0.499982  [48000/141921]\n",
      "loss: 0.486494  [51200/141921]\n",
      "loss: 0.506327  [54400/141921]\n",
      "loss: 0.610577  [57600/141921]\n",
      "loss: 0.428256  [60800/141921]\n",
      "loss: 0.579123  [64000/141921]\n",
      "loss: 0.435933  [67200/141921]\n",
      "loss: 0.481060  [70400/141921]\n",
      "loss: 0.487971  [73600/141921]\n",
      "loss: 0.593736  [76800/141921]\n",
      "loss: 0.454113  [80000/141921]\n",
      "loss: 0.553199  [83200/141921]\n",
      "loss: 0.682569  [86400/141921]\n",
      "loss: 0.575707  [89600/141921]\n",
      "loss: 0.561056  [92800/141921]\n",
      "loss: 0.487792  [96000/141921]\n",
      "loss: 0.525198  [99200/141921]\n",
      "loss: 0.628051  [102400/141921]\n",
      "loss: 0.534876  [105600/141921]\n",
      "loss: 0.476265  [108800/141921]\n",
      "loss: 0.539581  [112000/141921]\n",
      "loss: 0.553970  [115200/141921]\n",
      "loss: 0.491563  [118400/141921]\n",
      "loss: 0.583066  [121600/141921]\n",
      "loss: 0.468135  [124800/141921]\n",
      "loss: 0.593729  [128000/141921]\n",
      "loss: 0.455315  [131200/141921]\n",
      "loss: 0.441840  [134400/141921]\n",
      "loss: 0.529925  [137600/141921]\n",
      "loss: 0.541902  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.538604 \n",
      "\n",
      "Epoch 14\n",
      "---------------------------\n",
      "loss: 0.525870  [ 3200/141921]\n",
      "loss: 0.457665  [ 6400/141921]\n",
      "loss: 0.413260  [ 9600/141921]\n",
      "loss: 0.564542  [12800/141921]\n",
      "loss: 0.384842  [16000/141921]\n",
      "loss: 0.594646  [19200/141921]\n",
      "loss: 0.411818  [22400/141921]\n",
      "loss: 0.558713  [25600/141921]\n",
      "loss: 0.551873  [28800/141921]\n",
      "loss: 0.558622  [32000/141921]\n",
      "loss: 0.531529  [35200/141921]\n",
      "loss: 0.629330  [38400/141921]\n",
      "loss: 0.605242  [41600/141921]\n",
      "loss: 0.510653  [44800/141921]\n",
      "loss: 0.561484  [48000/141921]\n",
      "loss: 0.431672  [51200/141921]\n",
      "loss: 0.662870  [54400/141921]\n",
      "loss: 0.613030  [57600/141921]\n",
      "loss: 0.655546  [60800/141921]\n",
      "loss: 0.540001  [64000/141921]\n",
      "loss: 0.348578  [67200/141921]\n",
      "loss: 0.671230  [70400/141921]\n",
      "loss: 0.616439  [73600/141921]\n",
      "loss: 0.483698  [76800/141921]\n",
      "loss: 0.518597  [80000/141921]\n",
      "loss: 0.634231  [83200/141921]\n",
      "loss: 0.601370  [86400/141921]\n",
      "loss: 0.584015  [89600/141921]\n",
      "loss: 0.515712  [92800/141921]\n",
      "loss: 0.603851  [96000/141921]\n",
      "loss: 0.552683  [99200/141921]\n",
      "loss: 0.731984  [102400/141921]\n",
      "loss: 0.571929  [105600/141921]\n",
      "loss: 0.466493  [108800/141921]\n",
      "loss: 0.495810  [112000/141921]\n",
      "loss: 0.606751  [115200/141921]\n",
      "loss: 0.456381  [118400/141921]\n",
      "loss: 0.565123  [121600/141921]\n",
      "loss: 0.637492  [124800/141921]\n",
      "loss: 0.445496  [128000/141921]\n",
      "loss: 0.637864  [131200/141921]\n",
      "loss: 0.528860  [134400/141921]\n",
      "loss: 0.490583  [137600/141921]\n",
      "loss: 0.520039  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.538868 \n",
      "\n",
      "Epoch 15\n",
      "---------------------------\n",
      "loss: 0.545660  [ 3200/141921]\n",
      "loss: 0.475920  [ 6400/141921]\n",
      "loss: 0.548345  [ 9600/141921]\n",
      "loss: 0.477203  [12800/141921]\n",
      "loss: 0.441193  [16000/141921]\n",
      "loss: 0.669549  [19200/141921]\n",
      "loss: 0.539704  [22400/141921]\n",
      "loss: 0.395013  [25600/141921]\n",
      "loss: 0.486776  [28800/141921]\n",
      "loss: 0.526265  [32000/141921]\n",
      "loss: 0.466660  [35200/141921]\n",
      "loss: 0.385549  [38400/141921]\n",
      "loss: 0.608508  [41600/141921]\n",
      "loss: 0.501241  [44800/141921]\n",
      "loss: 0.435064  [48000/141921]\n",
      "loss: 0.521901  [51200/141921]\n",
      "loss: 0.654378  [54400/141921]\n",
      "loss: 0.604221  [57600/141921]\n",
      "loss: 0.538971  [60800/141921]\n",
      "loss: 0.541381  [64000/141921]\n",
      "loss: 0.488269  [67200/141921]\n",
      "loss: 0.549274  [70400/141921]\n",
      "loss: 0.377907  [73600/141921]\n",
      "loss: 0.498985  [76800/141921]\n",
      "loss: 0.663491  [80000/141921]\n",
      "loss: 0.618934  [83200/141921]\n",
      "loss: 0.466898  [86400/141921]\n",
      "loss: 0.459661  [89600/141921]\n",
      "loss: 0.549678  [92800/141921]\n",
      "loss: 0.593931  [96000/141921]\n",
      "loss: 0.712421  [99200/141921]\n",
      "loss: 0.505976  [102400/141921]\n",
      "loss: 0.674625  [105600/141921]\n",
      "loss: 0.484719  [108800/141921]\n",
      "loss: 0.633176  [112000/141921]\n",
      "loss: 0.759744  [115200/141921]\n",
      "loss: 0.505032  [118400/141921]\n",
      "loss: 0.571318  [121600/141921]\n",
      "loss: 0.599429  [124800/141921]\n",
      "loss: 0.587627  [128000/141921]\n",
      "loss: 0.593825  [131200/141921]\n",
      "loss: 0.545920  [134400/141921]\n",
      "loss: 0.585476  [137600/141921]\n",
      "loss: 0.473044  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.535374 \n",
      "\n",
      "Epoch 16\n",
      "---------------------------\n",
      "loss: 0.532463  [ 3200/141921]\n",
      "loss: 0.603649  [ 6400/141921]\n",
      "loss: 0.411940  [ 9600/141921]\n",
      "loss: 0.503631  [12800/141921]\n",
      "loss: 0.700130  [16000/141921]\n",
      "loss: 0.503457  [19200/141921]\n",
      "loss: 0.554160  [22400/141921]\n",
      "loss: 0.587439  [25600/141921]\n",
      "loss: 0.462427  [28800/141921]\n",
      "loss: 0.583345  [32000/141921]\n",
      "loss: 0.641526  [35200/141921]\n",
      "loss: 0.593530  [38400/141921]\n",
      "loss: 0.620039  [41600/141921]\n",
      "loss: 0.457609  [44800/141921]\n",
      "loss: 0.546480  [48000/141921]\n",
      "loss: 0.511314  [51200/141921]\n",
      "loss: 0.637694  [54400/141921]\n",
      "loss: 0.618424  [57600/141921]\n",
      "loss: 0.550440  [60800/141921]\n",
      "loss: 0.601813  [64000/141921]\n",
      "loss: 0.669250  [67200/141921]\n",
      "loss: 0.580245  [70400/141921]\n",
      "loss: 0.551811  [73600/141921]\n",
      "loss: 0.519901  [76800/141921]\n",
      "loss: 0.482727  [80000/141921]\n",
      "loss: 0.516967  [83200/141921]\n",
      "loss: 0.718993  [86400/141921]\n",
      "loss: 0.710567  [89600/141921]\n",
      "loss: 0.438681  [92800/141921]\n",
      "loss: 0.551665  [96000/141921]\n",
      "loss: 0.401682  [99200/141921]\n",
      "loss: 0.425973  [102400/141921]\n",
      "loss: 0.505015  [105600/141921]\n",
      "loss: 0.512106  [108800/141921]\n",
      "loss: 0.563628  [112000/141921]\n",
      "loss: 0.482132  [115200/141921]\n",
      "loss: 0.599682  [118400/141921]\n",
      "loss: 0.530505  [121600/141921]\n",
      "loss: 0.387229  [124800/141921]\n",
      "loss: 0.433026  [128000/141921]\n",
      "loss: 0.522224  [131200/141921]\n",
      "loss: 0.545695  [134400/141921]\n",
      "loss: 0.428082  [137600/141921]\n",
      "loss: 0.561008  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.534317 \n",
      "\n",
      "Epoch 17\n",
      "---------------------------\n",
      "loss: 0.624267  [ 3200/141921]\n",
      "loss: 0.593280  [ 6400/141921]\n",
      "loss: 0.531402  [ 9600/141921]\n",
      "loss: 0.559641  [12800/141921]\n",
      "loss: 0.567286  [16000/141921]\n",
      "loss: 0.767725  [19200/141921]\n",
      "loss: 0.590641  [22400/141921]\n",
      "loss: 0.670984  [25600/141921]\n",
      "loss: 0.487873  [28800/141921]\n",
      "loss: 0.550066  [32000/141921]\n",
      "loss: 0.376849  [35200/141921]\n",
      "loss: 0.522300  [38400/141921]\n",
      "loss: 0.572473  [41600/141921]\n",
      "loss: 0.454044  [44800/141921]\n",
      "loss: 0.580472  [48000/141921]\n",
      "loss: 0.526628  [51200/141921]\n",
      "loss: 0.469772  [54400/141921]\n",
      "loss: 0.385223  [57600/141921]\n",
      "loss: 0.603436  [60800/141921]\n",
      "loss: 0.456827  [64000/141921]\n",
      "loss: 0.593996  [67200/141921]\n",
      "loss: 0.461138  [70400/141921]\n",
      "loss: 0.495637  [73600/141921]\n",
      "loss: 0.451940  [76800/141921]\n",
      "loss: 0.521145  [80000/141921]\n",
      "loss: 0.695430  [83200/141921]\n",
      "loss: 0.478664  [86400/141921]\n",
      "loss: 0.609569  [89600/141921]\n",
      "loss: 0.562860  [92800/141921]\n",
      "loss: 0.491517  [96000/141921]\n",
      "loss: 0.515951  [99200/141921]\n",
      "loss: 0.523588  [102400/141921]\n",
      "loss: 0.456298  [105600/141921]\n",
      "loss: 0.688975  [108800/141921]\n",
      "loss: 0.672697  [112000/141921]\n",
      "loss: 0.463323  [115200/141921]\n",
      "loss: 0.565061  [118400/141921]\n",
      "loss: 0.559004  [121600/141921]\n",
      "loss: 0.674895  [124800/141921]\n",
      "loss: 0.654809  [128000/141921]\n",
      "loss: 0.529164  [131200/141921]\n",
      "loss: 0.551791  [134400/141921]\n",
      "loss: 0.500803  [137600/141921]\n",
      "loss: 0.662613  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.531873 \n",
      "\n",
      "Epoch 18\n",
      "---------------------------\n",
      "loss: 0.558152  [ 3200/141921]\n",
      "loss: 0.457197  [ 6400/141921]\n",
      "loss: 0.584990  [ 9600/141921]\n",
      "loss: 0.548374  [12800/141921]\n",
      "loss: 0.490186  [16000/141921]\n",
      "loss: 0.388154  [19200/141921]\n",
      "loss: 0.449419  [22400/141921]\n",
      "loss: 0.550622  [25600/141921]\n",
      "loss: 0.660551  [28800/141921]\n",
      "loss: 0.518579  [32000/141921]\n",
      "loss: 0.642008  [35200/141921]\n",
      "loss: 0.578241  [38400/141921]\n",
      "loss: 0.492668  [41600/141921]\n",
      "loss: 0.370427  [44800/141921]\n",
      "loss: 0.518312  [48000/141921]\n",
      "loss: 0.605492  [51200/141921]\n",
      "loss: 0.638264  [54400/141921]\n",
      "loss: 0.474283  [57600/141921]\n",
      "loss: 0.586892  [60800/141921]\n",
      "loss: 0.467835  [64000/141921]\n",
      "loss: 0.400764  [67200/141921]\n",
      "loss: 0.518327  [70400/141921]\n",
      "loss: 0.602932  [73600/141921]\n",
      "loss: 0.431636  [76800/141921]\n",
      "loss: 0.532747  [80000/141921]\n",
      "loss: 0.580168  [83200/141921]\n",
      "loss: 0.498676  [86400/141921]\n",
      "loss: 0.470636  [89600/141921]\n",
      "loss: 0.630735  [92800/141921]\n",
      "loss: 0.536683  [96000/141921]\n",
      "loss: 0.570825  [99200/141921]\n",
      "loss: 0.524496  [102400/141921]\n",
      "loss: 0.605612  [105600/141921]\n",
      "loss: 0.470115  [108800/141921]\n",
      "loss: 0.590635  [112000/141921]\n",
      "loss: 0.554989  [115200/141921]\n",
      "loss: 0.543889  [118400/141921]\n",
      "loss: 0.503339  [121600/141921]\n",
      "loss: 0.528577  [124800/141921]\n",
      "loss: 0.378779  [128000/141921]\n",
      "loss: 0.558362  [131200/141921]\n",
      "loss: 0.590823  [134400/141921]\n",
      "loss: 0.442287  [137600/141921]\n",
      "loss: 0.688420  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.530455 \n",
      "\n",
      "Epoch 19\n",
      "---------------------------\n",
      "loss: 0.507215  [ 3200/141921]\n",
      "loss: 0.434243  [ 6400/141921]\n",
      "loss: 0.577846  [ 9600/141921]\n",
      "loss: 0.590719  [12800/141921]\n",
      "loss: 0.533114  [16000/141921]\n",
      "loss: 0.549399  [19200/141921]\n",
      "loss: 0.559953  [22400/141921]\n",
      "loss: 0.375785  [25600/141921]\n",
      "loss: 0.543649  [28800/141921]\n",
      "loss: 0.504905  [32000/141921]\n",
      "loss: 0.520316  [35200/141921]\n",
      "loss: 0.546667  [38400/141921]\n",
      "loss: 0.467424  [41600/141921]\n",
      "loss: 0.540970  [44800/141921]\n",
      "loss: 0.595679  [48000/141921]\n",
      "loss: 0.467374  [51200/141921]\n",
      "loss: 0.458312  [54400/141921]\n",
      "loss: 0.551545  [57600/141921]\n",
      "loss: 0.502972  [60800/141921]\n",
      "loss: 0.562606  [64000/141921]\n",
      "loss: 0.411820  [67200/141921]\n",
      "loss: 0.494858  [70400/141921]\n",
      "loss: 0.574416  [73600/141921]\n",
      "loss: 0.491019  [76800/141921]\n",
      "loss: 0.598148  [80000/141921]\n",
      "loss: 0.580298  [83200/141921]\n",
      "loss: 0.644521  [86400/141921]\n",
      "loss: 0.698531  [89600/141921]\n",
      "loss: 0.509500  [92800/141921]\n",
      "loss: 0.484610  [96000/141921]\n",
      "loss: 0.502207  [99200/141921]\n",
      "loss: 0.506788  [102400/141921]\n",
      "loss: 0.550881  [105600/141921]\n",
      "loss: 0.423920  [108800/141921]\n",
      "loss: 0.580787  [112000/141921]\n",
      "loss: 0.439411  [115200/141921]\n",
      "loss: 0.503850  [118400/141921]\n",
      "loss: 0.458448  [121600/141921]\n",
      "loss: 0.444463  [124800/141921]\n",
      "loss: 0.523488  [128000/141921]\n",
      "loss: 0.561931  [131200/141921]\n",
      "loss: 0.384746  [134400/141921]\n",
      "loss: 0.567210  [137600/141921]\n",
      "loss: 0.400374  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.530273 \n",
      "\n",
      "Epoch 20\n",
      "---------------------------\n",
      "loss: 0.473775  [ 3200/141921]\n",
      "loss: 0.431565  [ 6400/141921]\n",
      "loss: 0.389550  [ 9600/141921]\n",
      "loss: 0.549592  [12800/141921]\n",
      "loss: 0.420506  [16000/141921]\n",
      "loss: 0.576558  [19200/141921]\n",
      "loss: 0.524241  [22400/141921]\n",
      "loss: 0.512750  [25600/141921]\n",
      "loss: 0.563467  [28800/141921]\n",
      "loss: 0.463650  [32000/141921]\n",
      "loss: 0.372652  [35200/141921]\n",
      "loss: 0.495561  [38400/141921]\n",
      "loss: 0.586008  [41600/141921]\n",
      "loss: 0.552171  [44800/141921]\n",
      "loss: 0.562219  [48000/141921]\n",
      "loss: 0.500572  [51200/141921]\n",
      "loss: 0.533656  [54400/141921]\n",
      "loss: 0.477784  [57600/141921]\n",
      "loss: 0.527854  [60800/141921]\n",
      "loss: 0.604484  [64000/141921]\n",
      "loss: 0.527813  [67200/141921]\n",
      "loss: 0.539815  [70400/141921]\n",
      "loss: 0.526846  [73600/141921]\n",
      "loss: 0.571434  [76800/141921]\n",
      "loss: 0.529397  [80000/141921]\n",
      "loss: 0.391117  [83200/141921]\n",
      "loss: 0.642535  [86400/141921]\n",
      "loss: 0.560388  [89600/141921]\n",
      "loss: 0.559556  [92800/141921]\n",
      "loss: 0.523318  [96000/141921]\n",
      "loss: 0.524614  [99200/141921]\n",
      "loss: 0.480900  [102400/141921]\n",
      "loss: 0.546848  [105600/141921]\n",
      "loss: 0.588038  [108800/141921]\n",
      "loss: 0.443096  [112000/141921]\n",
      "loss: 0.498877  [115200/141921]\n",
      "loss: 0.525734  [118400/141921]\n",
      "loss: 0.495959  [121600/141921]\n",
      "loss: 0.561018  [124800/141921]\n",
      "loss: 0.542468  [128000/141921]\n",
      "loss: 0.473278  [131200/141921]\n",
      "loss: 0.576897  [134400/141921]\n",
      "loss: 0.466307  [137600/141921]\n",
      "loss: 0.568929  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.529029 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(sn_train_dataloader, sn_model, loss_fn, sn_optimizer)\n",
    "    test_loop(sn_test_dataloader, sn_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
