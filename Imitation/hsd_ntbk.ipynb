{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991806d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ceab1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for data processing\n",
    "def card_to_num(card):\n",
    "    raw_rank = card[:-1]\n",
    "    \n",
    "    ranks = {\n",
    "        '2' : 0,\n",
    "        '3' : 1,\n",
    "        '4' : 2, \n",
    "        '5' : 3,\n",
    "        '6' : 4, \n",
    "        '7' : 5, \n",
    "        '8' : 6, \n",
    "        '9' : 7, \n",
    "        '10': 8, \n",
    "        'J' : 9, \n",
    "        'Q' : 10, \n",
    "        'K' : 11, \n",
    "        'A': 12\n",
    "    }\n",
    "\n",
    "    return ranks[raw_rank]\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_num(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9ef0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "hit_stand_dd_df = pd.read_csv('CSVs/hit_stand_dd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b8eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsd_train_df, hsd_test_df = train_test_split(hit_stand_dd_df, test_size = 0.2)\n",
    "\n",
    "def clean_up(dataframe_raw):\n",
    "    # Cleaned hit_stand_dd\n",
    "    MAX_LEN = 7\n",
    "    dataframe_raw['dealer_upcard'] = dataframe_raw['dealer_upcard'].apply(card_to_num)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(hand_to_list)\n",
    "    dataframe_raw['result'] = dataframe_raw['result'].map(result_mapping)\n",
    "    dataframe_raw['player_hand'] = [\n",
    "        hand + [0] * (MAX_LEN - len(hand)) if len(hand) < MAX_LEN else hand[:MAX_LEN] for hand in dataframe_raw['player_hand']\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Turning into tensor matrices\n",
    "    # hit_stand_dd\n",
    "    x1 = torch.tensor(dataframe_raw['player_hand'].to_list(), dtype=torch.float32)\n",
    "    x2 = torch.tensor(dataframe_raw['dealer_upcard'].values, dtype=torch.float32).unsqueeze(1)\n",
    "    x3 = torch.tensor(dataframe_raw['can_double'].values, dtype=torch.float32).unsqueeze(1)\n",
    "    y = torch.tensor(dataframe_raw['result'].values, dtype=torch.long)\n",
    "\n",
    "    X = torch.cat([x1,x2,x3], dim=1)\n",
    "\n",
    "    return Blackjack_Dataset(X,y)\n",
    "\n",
    "hsd_train_dataset = clean_up(hsd_train_df)\n",
    "hsd_test_dataset = clean_up(hsd_test_df)\n",
    "\n",
    "hsd_train_dataloader = DataLoader(hsd_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "hsd_test_dataloader = DataLoader(hsd_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dd46cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93418e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hsd_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "hsd_model = hsd_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "epochs = 1\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "hsd_optimizer = torch.optim.SGD(hsd_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb83a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.880699  [ 3200/209452]\n",
      "loss: 0.978093  [ 6400/209452]\n",
      "loss: 0.974575  [ 9600/209452]\n",
      "loss: 0.811601  [12800/209452]\n",
      "loss: 0.796542  [16000/209452]\n",
      "loss: 0.895215  [19200/209452]\n",
      "loss: 0.693790  [22400/209452]\n",
      "loss: 0.867890  [25600/209452]\n",
      "loss: 0.931756  [28800/209452]\n",
      "loss: 0.728318  [32000/209452]\n",
      "loss: 0.845487  [35200/209452]\n",
      "loss: 0.839700  [38400/209452]\n",
      "loss: 0.720325  [41600/209452]\n",
      "loss: 0.774570  [44800/209452]\n",
      "loss: 0.959743  [48000/209452]\n",
      "loss: 0.567118  [51200/209452]\n",
      "loss: 0.705298  [54400/209452]\n",
      "loss: 0.718200  [57600/209452]\n",
      "loss: 0.547042  [60800/209452]\n",
      "loss: 0.637333  [64000/209452]\n",
      "loss: 0.850500  [67200/209452]\n",
      "loss: 0.656089  [70400/209452]\n",
      "loss: 0.674375  [73600/209452]\n",
      "loss: 0.825141  [76800/209452]\n",
      "loss: 0.769935  [80000/209452]\n",
      "loss: 0.834252  [83200/209452]\n",
      "loss: 0.613182  [86400/209452]\n",
      "loss: 0.629921  [89600/209452]\n",
      "loss: 0.737720  [92800/209452]\n",
      "loss: 0.760328  [96000/209452]\n",
      "loss: 0.751124  [99200/209452]\n",
      "loss: 0.911626  [102400/209452]\n",
      "loss: 0.619706  [105600/209452]\n",
      "loss: 0.553278  [108800/209452]\n",
      "loss: 0.780970  [112000/209452]\n",
      "loss: 0.722497  [115200/209452]\n",
      "loss: 0.787606  [118400/209452]\n",
      "loss: 0.628830  [121600/209452]\n",
      "loss: 0.824145  [124800/209452]\n",
      "loss: 0.547470  [128000/209452]\n",
      "loss: 0.634181  [131200/209452]\n",
      "loss: 0.656049  [134400/209452]\n",
      "loss: 0.537082  [137600/209452]\n",
      "loss: 0.685250  [140800/209452]\n",
      "loss: 0.599911  [144000/209452]\n",
      "loss: 0.663959  [147200/209452]\n",
      "loss: 0.722771  [150400/209452]\n",
      "loss: 0.941817  [153600/209452]\n",
      "loss: 0.630469  [156800/209452]\n",
      "loss: 0.497768  [160000/209452]\n",
      "loss: 0.675304  [163200/209452]\n",
      "loss: 0.531616  [166400/209452]\n",
      "loss: 0.829915  [169600/209452]\n",
      "loss: 0.735485  [172800/209452]\n",
      "loss: 0.808320  [176000/209452]\n",
      "loss: 0.629913  [179200/209452]\n",
      "loss: 0.789186  [182400/209452]\n",
      "loss: 0.858415  [185600/209452]\n",
      "loss: 0.576455  [188800/209452]\n",
      "loss: 0.660385  [192000/209452]\n",
      "loss: 0.818006  [195200/209452]\n",
      "loss: 0.614865  [198400/209452]\n",
      "loss: 0.561044  [201600/209452]\n",
      "loss: 0.654636  [204800/209452]\n",
      "loss: 0.698328  [208000/209452]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.666099 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(hsd_train_dataloader, hsd_model, loss_fn, hsd_optimizer)\n",
    "    test_loop(hsd_test_dataloader, hsd_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
