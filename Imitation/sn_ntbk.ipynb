{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75c69788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a02e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n",
    "rank_to_index = {rank: i for i, rank in enumerate(ranks)}\n",
    "rank_len = len(ranks)\n",
    "\n",
    "#Helper functions for data processing\n",
    "def card_to_vec(card):\n",
    "    raw_rank = card[:-1]\n",
    "    one_hot_vector = [0] * rank_len\n",
    "    one_hot_vector[rank_to_index[raw_rank]] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "def hand_to_list(hand):\n",
    "    '''Takes hand like KH-AC and outputs list of card numbers'''\n",
    "    hand_list_1 = hand.split(\"-\")\n",
    "    hand_list_2 = [card_to_vec(card) for card in hand_list_1]\n",
    "    return hand_list_2\n",
    "\n",
    "result_mapping = {\n",
    "    'hit' : 0,\n",
    "    'stand' : 1,\n",
    "    'double down' : 2\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Defining Dataset Class\n",
    "class Blackjack_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1222d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_or_not_raw_df = pd.read_csv('CSVs/split_or_not.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb6ad32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_train_df, sn_test_df = train_test_split(split_or_not_raw_df, test_size=0.2)\n",
    "\n",
    "def clean_up(dataframe_raw):\n",
    "    # Cleaned split_or_not\n",
    "    dataframe_raw['dealer_upcard'] = dataframe_raw['dealer_upcard'].apply(card_to_vec)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(hand_to_list)\n",
    "    dataframe_raw['player_hand'] = dataframe_raw['player_hand'].apply(lambda hand: hand[0])\n",
    "    dataframe_clean = dataframe_raw.rename(columns = {'player_hand':'player_upcard'})\n",
    "\n",
    "    # Turning into tensor matrices\n",
    "    # split_or_not\n",
    "    x1 = torch.tensor(dataframe_clean['player_upcard'].to_list(), dtype=torch.float32)\n",
    "    x2 = torch.tensor(dataframe_clean['dealer_upcard'].to_list(), dtype=torch.float32)\n",
    "    y = torch.tensor(dataframe_clean['result'].values, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "    X = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "    return Blackjack_Dataset(X,y)\n",
    "\n",
    "sn_train_dataset = clean_up(sn_train_df)\n",
    "sn_test_dataset = clean_up(sn_test_df)\n",
    "\n",
    "sn_train_dataloader = DataLoader(sn_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "sn_test_dataloader = DataLoader(sn_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4dbe5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing Training Update on every 100th batch\n",
    "        if (batch + 1) % 100 == 0: \n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    #Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    #Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: \n",
    "            pred = model(X)\n",
    "            probs = torch.sigmoid(pred)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            correct += (preds.view(-1) == y.view(-1)).float().sum()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "659c20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sn_NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(26, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "sn_model = sn_NeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "epochs = 20\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "sn_optimizer = torch.optim.SGD(sn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e267a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "loss: 0.678461  [ 3200/141921]\n",
      "loss: 0.686297  [ 6400/141921]\n",
      "loss: 0.687797  [ 9600/141921]\n",
      "loss: 0.672884  [12800/141921]\n",
      "loss: 0.686228  [16000/141921]\n",
      "loss: 0.688225  [19200/141921]\n",
      "loss: 0.681758  [22400/141921]\n",
      "loss: 0.669535  [25600/141921]\n",
      "loss: 0.676238  [28800/141921]\n",
      "loss: 0.663610  [32000/141921]\n",
      "loss: 0.662016  [35200/141921]\n",
      "loss: 0.665695  [38400/141921]\n",
      "loss: 0.694881  [41600/141921]\n",
      "loss: 0.682710  [44800/141921]\n",
      "loss: 0.668668  [48000/141921]\n",
      "loss: 0.694318  [51200/141921]\n",
      "loss: 0.664236  [54400/141921]\n",
      "loss: 0.678582  [57600/141921]\n",
      "loss: 0.670991  [60800/141921]\n",
      "loss: 0.673826  [64000/141921]\n",
      "loss: 0.653522  [67200/141921]\n",
      "loss: 0.647822  [70400/141921]\n",
      "loss: 0.673746  [73600/141921]\n",
      "loss: 0.648783  [76800/141921]\n",
      "loss: 0.646369  [80000/141921]\n",
      "loss: 0.690536  [83200/141921]\n",
      "loss: 0.677025  [86400/141921]\n",
      "loss: 0.683495  [89600/141921]\n",
      "loss: 0.656802  [92800/141921]\n",
      "loss: 0.660576  [96000/141921]\n",
      "loss: 0.663286  [99200/141921]\n",
      "loss: 0.629617  [102400/141921]\n",
      "loss: 0.656206  [105600/141921]\n",
      "loss: 0.660746  [108800/141921]\n",
      "loss: 0.626199  [112000/141921]\n",
      "loss: 0.652641  [115200/141921]\n",
      "loss: 0.643394  [118400/141921]\n",
      "loss: 0.615152  [121600/141921]\n",
      "loss: 0.681742  [124800/141921]\n",
      "loss: 0.709331  [128000/141921]\n",
      "loss: 0.633752  [131200/141921]\n",
      "loss: 0.639256  [134400/141921]\n",
      "loss: 0.657090  [137600/141921]\n",
      "loss: 0.689490  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.655306 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "loss: 0.714797  [ 3200/141921]\n",
      "loss: 0.648940  [ 6400/141921]\n",
      "loss: 0.659938  [ 9600/141921]\n",
      "loss: 0.689798  [12800/141921]\n",
      "loss: 0.650550  [16000/141921]\n",
      "loss: 0.691849  [19200/141921]\n",
      "loss: 0.648548  [22400/141921]\n",
      "loss: 0.703804  [25600/141921]\n",
      "loss: 0.681365  [28800/141921]\n",
      "loss: 0.600753  [32000/141921]\n",
      "loss: 0.588879  [35200/141921]\n",
      "loss: 0.681571  [38400/141921]\n",
      "loss: 0.658238  [41600/141921]\n",
      "loss: 0.619920  [44800/141921]\n",
      "loss: 0.634128  [48000/141921]\n",
      "loss: 0.669626  [51200/141921]\n",
      "loss: 0.657706  [54400/141921]\n",
      "loss: 0.594711  [57600/141921]\n",
      "loss: 0.596597  [60800/141921]\n",
      "loss: 0.628127  [64000/141921]\n",
      "loss: 0.630603  [67200/141921]\n",
      "loss: 0.631170  [70400/141921]\n",
      "loss: 0.663532  [73600/141921]\n",
      "loss: 0.627244  [76800/141921]\n",
      "loss: 0.634110  [80000/141921]\n",
      "loss: 0.658886  [83200/141921]\n",
      "loss: 0.655261  [86400/141921]\n",
      "loss: 0.615631  [89600/141921]\n",
      "loss: 0.600009  [92800/141921]\n",
      "loss: 0.654495  [96000/141921]\n",
      "loss: 0.640083  [99200/141921]\n",
      "loss: 0.666833  [102400/141921]\n",
      "loss: 0.732570  [105600/141921]\n",
      "loss: 0.680586  [108800/141921]\n",
      "loss: 0.601368  [112000/141921]\n",
      "loss: 0.651298  [115200/141921]\n",
      "loss: 0.691158  [118400/141921]\n",
      "loss: 0.608945  [121600/141921]\n",
      "loss: 0.654294  [124800/141921]\n",
      "loss: 0.571691  [128000/141921]\n",
      "loss: 0.635859  [131200/141921]\n",
      "loss: 0.665240  [134400/141921]\n",
      "loss: 0.583228  [137600/141921]\n",
      "loss: 0.622881  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.645239 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "loss: 0.637181  [ 3200/141921]\n",
      "loss: 0.694004  [ 6400/141921]\n",
      "loss: 0.695435  [ 9600/141921]\n",
      "loss: 0.708682  [12800/141921]\n",
      "loss: 0.649463  [16000/141921]\n",
      "loss: 0.619116  [19200/141921]\n",
      "loss: 0.678483  [22400/141921]\n",
      "loss: 0.650170  [25600/141921]\n",
      "loss: 0.652795  [28800/141921]\n",
      "loss: 0.617976  [32000/141921]\n",
      "loss: 0.650323  [35200/141921]\n",
      "loss: 0.635046  [38400/141921]\n",
      "loss: 0.690854  [41600/141921]\n",
      "loss: 0.603139  [44800/141921]\n",
      "loss: 0.578650  [48000/141921]\n",
      "loss: 0.727862  [51200/141921]\n",
      "loss: 0.774284  [54400/141921]\n",
      "loss: 0.666548  [57600/141921]\n",
      "loss: 0.664348  [60800/141921]\n",
      "loss: 0.679456  [64000/141921]\n",
      "loss: 0.657142  [67200/141921]\n",
      "loss: 0.601548  [70400/141921]\n",
      "loss: 0.649429  [73600/141921]\n",
      "loss: 0.693401  [76800/141921]\n",
      "loss: 0.618695  [80000/141921]\n",
      "loss: 0.666093  [83200/141921]\n",
      "loss: 0.665834  [86400/141921]\n",
      "loss: 0.662705  [89600/141921]\n",
      "loss: 0.695566  [92800/141921]\n",
      "loss: 0.679175  [96000/141921]\n",
      "loss: 0.677251  [99200/141921]\n",
      "loss: 0.643563  [102400/141921]\n",
      "loss: 0.674555  [105600/141921]\n",
      "loss: 0.629206  [108800/141921]\n",
      "loss: 0.676004  [112000/141921]\n",
      "loss: 0.650038  [115200/141921]\n",
      "loss: 0.678936  [118400/141921]\n",
      "loss: 0.627565  [121600/141921]\n",
      "loss: 0.581492  [124800/141921]\n",
      "loss: 0.596885  [128000/141921]\n",
      "loss: 0.708144  [131200/141921]\n",
      "loss: 0.584715  [134400/141921]\n",
      "loss: 0.739532  [137600/141921]\n",
      "loss: 0.654159  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.637286 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "loss: 0.637984  [ 3200/141921]\n",
      "loss: 0.671117  [ 6400/141921]\n",
      "loss: 0.629793  [ 9600/141921]\n",
      "loss: 0.659753  [12800/141921]\n",
      "loss: 0.709655  [16000/141921]\n",
      "loss: 0.720161  [19200/141921]\n",
      "loss: 0.609961  [22400/141921]\n",
      "loss: 0.691591  [25600/141921]\n",
      "loss: 0.643629  [28800/141921]\n",
      "loss: 0.591612  [32000/141921]\n",
      "loss: 0.575384  [35200/141921]\n",
      "loss: 0.610840  [38400/141921]\n",
      "loss: 0.596041  [41600/141921]\n",
      "loss: 0.610061  [44800/141921]\n",
      "loss: 0.558955  [48000/141921]\n",
      "loss: 0.741370  [51200/141921]\n",
      "loss: 0.673854  [54400/141921]\n",
      "loss: 0.599032  [57600/141921]\n",
      "loss: 0.610382  [60800/141921]\n",
      "loss: 0.670940  [64000/141921]\n",
      "loss: 0.637484  [67200/141921]\n",
      "loss: 0.612097  [70400/141921]\n",
      "loss: 0.706927  [73600/141921]\n",
      "loss: 0.595433  [76800/141921]\n",
      "loss: 0.602970  [80000/141921]\n",
      "loss: 0.635464  [83200/141921]\n",
      "loss: 0.605894  [86400/141921]\n",
      "loss: 0.675500  [89600/141921]\n",
      "loss: 0.655228  [92800/141921]\n",
      "loss: 0.733968  [96000/141921]\n",
      "loss: 0.574632  [99200/141921]\n",
      "loss: 0.700136  [102400/141921]\n",
      "loss: 0.654520  [105600/141921]\n",
      "loss: 0.626105  [108800/141921]\n",
      "loss: 0.531447  [112000/141921]\n",
      "loss: 0.588913  [115200/141921]\n",
      "loss: 0.617915  [118400/141921]\n",
      "loss: 0.590707  [121600/141921]\n",
      "loss: 0.677814  [124800/141921]\n",
      "loss: 0.635938  [128000/141921]\n",
      "loss: 0.705837  [131200/141921]\n",
      "loss: 0.651343  [134400/141921]\n",
      "loss: 0.749795  [137600/141921]\n",
      "loss: 0.595836  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.626472 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "loss: 0.611928  [ 3200/141921]\n",
      "loss: 0.639046  [ 6400/141921]\n",
      "loss: 0.613245  [ 9600/141921]\n",
      "loss: 0.618559  [12800/141921]\n",
      "loss: 0.613643  [16000/141921]\n",
      "loss: 0.533392  [19200/141921]\n",
      "loss: 0.593487  [22400/141921]\n",
      "loss: 0.542784  [25600/141921]\n",
      "loss: 0.686161  [28800/141921]\n",
      "loss: 0.600714  [32000/141921]\n",
      "loss: 0.596559  [35200/141921]\n",
      "loss: 0.590492  [38400/141921]\n",
      "loss: 0.695567  [41600/141921]\n",
      "loss: 0.630899  [44800/141921]\n",
      "loss: 0.603993  [48000/141921]\n",
      "loss: 0.597161  [51200/141921]\n",
      "loss: 0.625298  [54400/141921]\n",
      "loss: 0.593760  [57600/141921]\n",
      "loss: 0.659679  [60800/141921]\n",
      "loss: 0.664968  [64000/141921]\n",
      "loss: 0.623813  [67200/141921]\n",
      "loss: 0.618211  [70400/141921]\n",
      "loss: 0.612046  [73600/141921]\n",
      "loss: 0.552812  [76800/141921]\n",
      "loss: 0.640049  [80000/141921]\n",
      "loss: 0.581016  [83200/141921]\n",
      "loss: 0.607104  [86400/141921]\n",
      "loss: 0.679564  [89600/141921]\n",
      "loss: 0.605623  [92800/141921]\n",
      "loss: 0.643074  [96000/141921]\n",
      "loss: 0.538886  [99200/141921]\n",
      "loss: 0.565485  [102400/141921]\n",
      "loss: 0.695526  [105600/141921]\n",
      "loss: 0.595330  [108800/141921]\n",
      "loss: 0.656632  [112000/141921]\n",
      "loss: 0.536524  [115200/141921]\n",
      "loss: 0.604649  [118400/141921]\n",
      "loss: 0.632510  [121600/141921]\n",
      "loss: 0.649225  [124800/141921]\n",
      "loss: 0.573538  [128000/141921]\n",
      "loss: 0.679812  [131200/141921]\n",
      "loss: 0.576954  [134400/141921]\n",
      "loss: 0.653607  [137600/141921]\n",
      "loss: 0.625694  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.609529 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "loss: 0.573759  [ 3200/141921]\n",
      "loss: 0.733056  [ 6400/141921]\n",
      "loss: 0.623591  [ 9600/141921]\n",
      "loss: 0.618807  [12800/141921]\n",
      "loss: 0.549324  [16000/141921]\n",
      "loss: 0.617966  [19200/141921]\n",
      "loss: 0.566429  [22400/141921]\n",
      "loss: 0.607680  [25600/141921]\n",
      "loss: 0.592354  [28800/141921]\n",
      "loss: 0.620645  [32000/141921]\n",
      "loss: 0.652376  [35200/141921]\n",
      "loss: 0.529702  [38400/141921]\n",
      "loss: 0.658244  [41600/141921]\n",
      "loss: 0.607106  [44800/141921]\n",
      "loss: 0.615030  [48000/141921]\n",
      "loss: 0.581016  [51200/141921]\n",
      "loss: 0.609147  [54400/141921]\n",
      "loss: 0.615784  [57600/141921]\n",
      "loss: 0.602049  [60800/141921]\n",
      "loss: 0.595844  [64000/141921]\n",
      "loss: 0.500986  [67200/141921]\n",
      "loss: 0.520438  [70400/141921]\n",
      "loss: 0.600712  [73600/141921]\n",
      "loss: 0.554620  [76800/141921]\n",
      "loss: 0.583258  [80000/141921]\n",
      "loss: 0.609912  [83200/141921]\n",
      "loss: 0.573483  [86400/141921]\n",
      "loss: 0.539258  [89600/141921]\n",
      "loss: 0.589682  [92800/141921]\n",
      "loss: 0.613595  [96000/141921]\n",
      "loss: 0.578503  [99200/141921]\n",
      "loss: 0.544758  [102400/141921]\n",
      "loss: 0.618311  [105600/141921]\n",
      "loss: 0.627417  [108800/141921]\n",
      "loss: 0.606732  [112000/141921]\n",
      "loss: 0.588973  [115200/141921]\n",
      "loss: 0.575068  [118400/141921]\n",
      "loss: 0.530783  [121600/141921]\n",
      "loss: 0.540682  [124800/141921]\n",
      "loss: 0.592040  [128000/141921]\n",
      "loss: 0.611914  [131200/141921]\n",
      "loss: 0.589480  [134400/141921]\n",
      "loss: 0.568648  [137600/141921]\n",
      "loss: 0.611224  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.581489 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "loss: 0.549926  [ 3200/141921]\n",
      "loss: 0.582952  [ 6400/141921]\n",
      "loss: 0.659203  [ 9600/141921]\n",
      "loss: 0.570595  [12800/141921]\n",
      "loss: 0.558878  [16000/141921]\n",
      "loss: 0.528704  [19200/141921]\n",
      "loss: 0.537954  [22400/141921]\n",
      "loss: 0.594221  [25600/141921]\n",
      "loss: 0.562495  [28800/141921]\n",
      "loss: 0.578552  [32000/141921]\n",
      "loss: 0.565438  [35200/141921]\n",
      "loss: 0.525878  [38400/141921]\n",
      "loss: 0.578044  [41600/141921]\n",
      "loss: 0.543893  [44800/141921]\n",
      "loss: 0.464499  [48000/141921]\n",
      "loss: 0.633921  [51200/141921]\n",
      "loss: 0.582516  [54400/141921]\n",
      "loss: 0.531177  [57600/141921]\n",
      "loss: 0.631435  [60800/141921]\n",
      "loss: 0.559828  [64000/141921]\n",
      "loss: 0.619559  [67200/141921]\n",
      "loss: 0.480761  [70400/141921]\n",
      "loss: 0.545223  [73600/141921]\n",
      "loss: 0.533882  [76800/141921]\n",
      "loss: 0.566795  [80000/141921]\n",
      "loss: 0.563803  [83200/141921]\n",
      "loss: 0.539993  [86400/141921]\n",
      "loss: 0.488382  [89600/141921]\n",
      "loss: 0.541751  [92800/141921]\n",
      "loss: 0.516849  [96000/141921]\n",
      "loss: 0.550416  [99200/141921]\n",
      "loss: 0.582552  [102400/141921]\n",
      "loss: 0.553779  [105600/141921]\n",
      "loss: 0.530026  [108800/141921]\n",
      "loss: 0.513200  [112000/141921]\n",
      "loss: 0.579796  [115200/141921]\n",
      "loss: 0.566940  [118400/141921]\n",
      "loss: 0.487933  [121600/141921]\n",
      "loss: 0.581188  [124800/141921]\n",
      "loss: 0.512953  [128000/141921]\n",
      "loss: 0.455477  [131200/141921]\n",
      "loss: 0.547849  [134400/141921]\n",
      "loss: 0.656405  [137600/141921]\n",
      "loss: 0.614009  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.534414 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "loss: 0.567330  [ 3200/141921]\n",
      "loss: 0.495791  [ 6400/141921]\n",
      "loss: 0.542460  [ 9600/141921]\n",
      "loss: 0.488984  [12800/141921]\n",
      "loss: 0.463205  [16000/141921]\n",
      "loss: 0.477415  [19200/141921]\n",
      "loss: 0.488265  [22400/141921]\n",
      "loss: 0.491191  [25600/141921]\n",
      "loss: 0.465712  [28800/141921]\n",
      "loss: 0.499352  [32000/141921]\n",
      "loss: 0.467224  [35200/141921]\n",
      "loss: 0.472721  [38400/141921]\n",
      "loss: 0.582201  [41600/141921]\n",
      "loss: 0.507593  [44800/141921]\n",
      "loss: 0.511463  [48000/141921]\n",
      "loss: 0.562774  [51200/141921]\n",
      "loss: 0.490074  [54400/141921]\n",
      "loss: 0.453310  [57600/141921]\n",
      "loss: 0.480672  [60800/141921]\n",
      "loss: 0.563712  [64000/141921]\n",
      "loss: 0.494005  [67200/141921]\n",
      "loss: 0.447932  [70400/141921]\n",
      "loss: 0.515242  [73600/141921]\n",
      "loss: 0.517934  [76800/141921]\n",
      "loss: 0.498327  [80000/141921]\n",
      "loss: 0.521371  [83200/141921]\n",
      "loss: 0.492550  [86400/141921]\n",
      "loss: 0.540551  [89600/141921]\n",
      "loss: 0.445720  [92800/141921]\n",
      "loss: 0.462910  [96000/141921]\n",
      "loss: 0.431827  [99200/141921]\n",
      "loss: 0.518971  [102400/141921]\n",
      "loss: 0.473412  [105600/141921]\n",
      "loss: 0.549433  [108800/141921]\n",
      "loss: 0.462066  [112000/141921]\n",
      "loss: 0.465690  [115200/141921]\n",
      "loss: 0.568327  [118400/141921]\n",
      "loss: 0.458355  [121600/141921]\n",
      "loss: 0.470060  [124800/141921]\n",
      "loss: 0.489942  [128000/141921]\n",
      "loss: 0.442030  [131200/141921]\n",
      "loss: 0.425755  [134400/141921]\n",
      "loss: 0.397926  [137600/141921]\n",
      "loss: 0.419742  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.460259 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "loss: 0.497981  [ 3200/141921]\n",
      "loss: 0.437841  [ 6400/141921]\n",
      "loss: 0.433356  [ 9600/141921]\n",
      "loss: 0.470545  [12800/141921]\n",
      "loss: 0.470153  [16000/141921]\n",
      "loss: 0.518670  [19200/141921]\n",
      "loss: 0.436940  [22400/141921]\n",
      "loss: 0.499773  [25600/141921]\n",
      "loss: 0.364603  [28800/141921]\n",
      "loss: 0.474457  [32000/141921]\n",
      "loss: 0.408024  [35200/141921]\n",
      "loss: 0.445561  [38400/141921]\n",
      "loss: 0.396932  [41600/141921]\n",
      "loss: 0.520740  [44800/141921]\n",
      "loss: 0.465598  [48000/141921]\n",
      "loss: 0.359969  [51200/141921]\n",
      "loss: 0.399700  [54400/141921]\n",
      "loss: 0.464959  [57600/141921]\n",
      "loss: 0.434640  [60800/141921]\n",
      "loss: 0.393367  [64000/141921]\n",
      "loss: 0.504785  [67200/141921]\n",
      "loss: 0.436916  [70400/141921]\n",
      "loss: 0.359141  [73600/141921]\n",
      "loss: 0.496021  [76800/141921]\n",
      "loss: 0.451193  [80000/141921]\n",
      "loss: 0.355484  [83200/141921]\n",
      "loss: 0.485827  [86400/141921]\n",
      "loss: 0.397180  [89600/141921]\n",
      "loss: 0.407742  [92800/141921]\n",
      "loss: 0.438283  [96000/141921]\n",
      "loss: 0.390686  [99200/141921]\n",
      "loss: 0.390575  [102400/141921]\n",
      "loss: 0.429051  [105600/141921]\n",
      "loss: 0.378071  [108800/141921]\n",
      "loss: 0.345060  [112000/141921]\n",
      "loss: 0.293853  [115200/141921]\n",
      "loss: 0.348541  [118400/141921]\n",
      "loss: 0.394267  [121600/141921]\n",
      "loss: 0.323256  [124800/141921]\n",
      "loss: 0.330029  [128000/141921]\n",
      "loss: 0.430344  [131200/141921]\n",
      "loss: 0.441357  [134400/141921]\n",
      "loss: 0.391518  [137600/141921]\n",
      "loss: 0.405909  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.363918 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "loss: 0.334195  [ 3200/141921]\n",
      "loss: 0.360459  [ 6400/141921]\n",
      "loss: 0.394879  [ 9600/141921]\n",
      "loss: 0.365858  [12800/141921]\n",
      "loss: 0.346220  [16000/141921]\n",
      "loss: 0.326936  [19200/141921]\n",
      "loss: 0.270606  [22400/141921]\n",
      "loss: 0.351588  [25600/141921]\n",
      "loss: 0.300734  [28800/141921]\n",
      "loss: 0.346456  [32000/141921]\n",
      "loss: 0.307506  [35200/141921]\n",
      "loss: 0.327828  [38400/141921]\n",
      "loss: 0.341991  [41600/141921]\n",
      "loss: 0.326931  [44800/141921]\n",
      "loss: 0.387245  [48000/141921]\n",
      "loss: 0.357681  [51200/141921]\n",
      "loss: 0.348910  [54400/141921]\n",
      "loss: 0.320555  [57600/141921]\n",
      "loss: 0.332011  [60800/141921]\n",
      "loss: 0.286665  [64000/141921]\n",
      "loss: 0.304424  [67200/141921]\n",
      "loss: 0.303108  [70400/141921]\n",
      "loss: 0.329311  [73600/141921]\n",
      "loss: 0.234811  [76800/141921]\n",
      "loss: 0.337503  [80000/141921]\n",
      "loss: 0.231979  [83200/141921]\n",
      "loss: 0.329102  [86400/141921]\n",
      "loss: 0.284064  [89600/141921]\n",
      "loss: 0.256260  [92800/141921]\n",
      "loss: 0.264226  [96000/141921]\n",
      "loss: 0.322281  [99200/141921]\n",
      "loss: 0.293280  [102400/141921]\n",
      "loss: 0.341534  [105600/141921]\n",
      "loss: 0.349891  [108800/141921]\n",
      "loss: 0.292206  [112000/141921]\n",
      "loss: 0.347184  [115200/141921]\n",
      "loss: 0.256203  [118400/141921]\n",
      "loss: 0.284391  [121600/141921]\n",
      "loss: 0.241778  [124800/141921]\n",
      "loss: 0.279746  [128000/141921]\n",
      "loss: 0.270116  [131200/141921]\n",
      "loss: 0.249106  [134400/141921]\n",
      "loss: 0.304441  [137600/141921]\n",
      "loss: 0.270989  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.269532 \n",
      "\n",
      "Epoch 11\n",
      "---------------------------\n",
      "loss: 0.239979  [ 3200/141921]\n",
      "loss: 0.254261  [ 6400/141921]\n",
      "loss: 0.224764  [ 9600/141921]\n",
      "loss: 0.335314  [12800/141921]\n",
      "loss: 0.285513  [16000/141921]\n",
      "loss: 0.279985  [19200/141921]\n",
      "loss: 0.259311  [22400/141921]\n",
      "loss: 0.266753  [25600/141921]\n",
      "loss: 0.231490  [28800/141921]\n",
      "loss: 0.224195  [32000/141921]\n",
      "loss: 0.251037  [35200/141921]\n",
      "loss: 0.222362  [38400/141921]\n",
      "loss: 0.262586  [41600/141921]\n",
      "loss: 0.229709  [44800/141921]\n",
      "loss: 0.192346  [48000/141921]\n",
      "loss: 0.221160  [51200/141921]\n",
      "loss: 0.184064  [54400/141921]\n",
      "loss: 0.267790  [57600/141921]\n",
      "loss: 0.251128  [60800/141921]\n",
      "loss: 0.247256  [64000/141921]\n",
      "loss: 0.206094  [67200/141921]\n",
      "loss: 0.213751  [70400/141921]\n",
      "loss: 0.187910  [73600/141921]\n",
      "loss: 0.222221  [76800/141921]\n",
      "loss: 0.209317  [80000/141921]\n",
      "loss: 0.213598  [83200/141921]\n",
      "loss: 0.184765  [86400/141921]\n",
      "loss: 0.230171  [89600/141921]\n",
      "loss: 0.195775  [92800/141921]\n",
      "loss: 0.239780  [96000/141921]\n",
      "loss: 0.247990  [99200/141921]\n",
      "loss: 0.209108  [102400/141921]\n",
      "loss: 0.185293  [105600/141921]\n",
      "loss: 0.197646  [108800/141921]\n",
      "loss: 0.225293  [112000/141921]\n",
      "loss: 0.234867  [115200/141921]\n",
      "loss: 0.160979  [118400/141921]\n",
      "loss: 0.233891  [121600/141921]\n",
      "loss: 0.234835  [124800/141921]\n",
      "loss: 0.265901  [128000/141921]\n",
      "loss: 0.208677  [131200/141921]\n",
      "loss: 0.206687  [134400/141921]\n",
      "loss: 0.172615  [137600/141921]\n",
      "loss: 0.195088  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.198028 \n",
      "\n",
      "Epoch 12\n",
      "---------------------------\n",
      "loss: 0.170918  [ 3200/141921]\n",
      "loss: 0.181223  [ 6400/141921]\n",
      "loss: 0.251707  [ 9600/141921]\n",
      "loss: 0.235303  [12800/141921]\n",
      "loss: 0.239731  [16000/141921]\n",
      "loss: 0.155980  [19200/141921]\n",
      "loss: 0.273982  [22400/141921]\n",
      "loss: 0.178938  [25600/141921]\n",
      "loss: 0.111275  [28800/141921]\n",
      "loss: 0.122942  [32000/141921]\n",
      "loss: 0.180926  [35200/141921]\n",
      "loss: 0.132594  [38400/141921]\n",
      "loss: 0.157162  [41600/141921]\n",
      "loss: 0.156103  [44800/141921]\n",
      "loss: 0.160883  [48000/141921]\n",
      "loss: 0.257098  [51200/141921]\n",
      "loss: 0.119939  [54400/141921]\n",
      "loss: 0.193190  [57600/141921]\n",
      "loss: 0.194887  [60800/141921]\n",
      "loss: 0.133238  [64000/141921]\n",
      "loss: 0.189512  [67200/141921]\n",
      "loss: 0.123616  [70400/141921]\n",
      "loss: 0.195731  [73600/141921]\n",
      "loss: 0.115743  [76800/141921]\n",
      "loss: 0.171992  [80000/141921]\n",
      "loss: 0.143801  [83200/141921]\n",
      "loss: 0.163338  [86400/141921]\n",
      "loss: 0.155821  [89600/141921]\n",
      "loss: 0.149804  [92800/141921]\n",
      "loss: 0.163664  [96000/141921]\n",
      "loss: 0.154501  [99200/141921]\n",
      "loss: 0.149313  [102400/141921]\n",
      "loss: 0.151993  [105600/141921]\n",
      "loss: 0.161349  [108800/141921]\n",
      "loss: 0.093165  [112000/141921]\n",
      "loss: 0.132094  [115200/141921]\n",
      "loss: 0.167611  [118400/141921]\n",
      "loss: 0.155914  [121600/141921]\n",
      "loss: 0.143107  [124800/141921]\n",
      "loss: 0.213216  [128000/141921]\n",
      "loss: 0.164536  [131200/141921]\n",
      "loss: 0.185217  [134400/141921]\n",
      "loss: 0.102797  [137600/141921]\n",
      "loss: 0.160367  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.150615 \n",
      "\n",
      "Epoch 13\n",
      "---------------------------\n",
      "loss: 0.113201  [ 3200/141921]\n",
      "loss: 0.139101  [ 6400/141921]\n",
      "loss: 0.115914  [ 9600/141921]\n",
      "loss: 0.194396  [12800/141921]\n",
      "loss: 0.195735  [16000/141921]\n",
      "loss: 0.135833  [19200/141921]\n",
      "loss: 0.202437  [22400/141921]\n",
      "loss: 0.124579  [25600/141921]\n",
      "loss: 0.230894  [28800/141921]\n",
      "loss: 0.186998  [32000/141921]\n",
      "loss: 0.141698  [35200/141921]\n",
      "loss: 0.176247  [38400/141921]\n",
      "loss: 0.104845  [41600/141921]\n",
      "loss: 0.195373  [44800/141921]\n",
      "loss: 0.137016  [48000/141921]\n",
      "loss: 0.174746  [51200/141921]\n",
      "loss: 0.099071  [54400/141921]\n",
      "loss: 0.171029  [57600/141921]\n",
      "loss: 0.155478  [60800/141921]\n",
      "loss: 0.100784  [64000/141921]\n",
      "loss: 0.093346  [67200/141921]\n",
      "loss: 0.122490  [70400/141921]\n",
      "loss: 0.208710  [73600/141921]\n",
      "loss: 0.127200  [76800/141921]\n",
      "loss: 0.100083  [80000/141921]\n",
      "loss: 0.138547  [83200/141921]\n",
      "loss: 0.162036  [86400/141921]\n",
      "loss: 0.123882  [89600/141921]\n",
      "loss: 0.136112  [92800/141921]\n",
      "loss: 0.118903  [96000/141921]\n",
      "loss: 0.119336  [99200/141921]\n",
      "loss: 0.142709  [102400/141921]\n",
      "loss: 0.146527  [105600/141921]\n",
      "loss: 0.110055  [108800/141921]\n",
      "loss: 0.118660  [112000/141921]\n",
      "loss: 0.157212  [115200/141921]\n",
      "loss: 0.074024  [118400/141921]\n",
      "loss: 0.152206  [121600/141921]\n",
      "loss: 0.138375  [124800/141921]\n",
      "loss: 0.182948  [128000/141921]\n",
      "loss: 0.146630  [131200/141921]\n",
      "loss: 0.198572  [134400/141921]\n",
      "loss: 0.145736  [137600/141921]\n",
      "loss: 0.104561  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.120024 \n",
      "\n",
      "Epoch 14\n",
      "---------------------------\n",
      "loss: 0.135752  [ 3200/141921]\n",
      "loss: 0.137587  [ 6400/141921]\n",
      "loss: 0.106814  [ 9600/141921]\n",
      "loss: 0.128803  [12800/141921]\n",
      "loss: 0.108326  [16000/141921]\n",
      "loss: 0.148881  [19200/141921]\n",
      "loss: 0.133676  [22400/141921]\n",
      "loss: 0.172754  [25600/141921]\n",
      "loss: 0.110120  [28800/141921]\n",
      "loss: 0.102019  [32000/141921]\n",
      "loss: 0.104712  [35200/141921]\n",
      "loss: 0.081008  [38400/141921]\n",
      "loss: 0.083675  [41600/141921]\n",
      "loss: 0.088687  [44800/141921]\n",
      "loss: 0.090797  [48000/141921]\n",
      "loss: 0.068854  [51200/141921]\n",
      "loss: 0.088975  [54400/141921]\n",
      "loss: 0.077652  [57600/141921]\n",
      "loss: 0.107073  [60800/141921]\n",
      "loss: 0.112787  [64000/141921]\n",
      "loss: 0.098070  [67200/141921]\n",
      "loss: 0.101373  [70400/141921]\n",
      "loss: 0.104347  [73600/141921]\n",
      "loss: 0.063342  [76800/141921]\n",
      "loss: 0.078793  [80000/141921]\n",
      "loss: 0.072307  [83200/141921]\n",
      "loss: 0.084824  [86400/141921]\n",
      "loss: 0.112034  [89600/141921]\n",
      "loss: 0.061629  [92800/141921]\n",
      "loss: 0.081853  [96000/141921]\n",
      "loss: 0.076505  [99200/141921]\n",
      "loss: 0.142147  [102400/141921]\n",
      "loss: 0.110393  [105600/141921]\n",
      "loss: 0.064253  [108800/141921]\n",
      "loss: 0.060108  [112000/141921]\n",
      "loss: 0.053710  [115200/141921]\n",
      "loss: 0.068822  [118400/141921]\n",
      "loss: 0.093628  [121600/141921]\n",
      "loss: 0.126734  [124800/141921]\n",
      "loss: 0.114410  [128000/141921]\n",
      "loss: 0.067582  [131200/141921]\n",
      "loss: 0.033062  [134400/141921]\n",
      "loss: 0.188063  [137600/141921]\n",
      "loss: 0.135476  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.099717 \n",
      "\n",
      "Epoch 15\n",
      "---------------------------\n",
      "loss: 0.060510  [ 3200/141921]\n",
      "loss: 0.101696  [ 6400/141921]\n",
      "loss: 0.045750  [ 9600/141921]\n",
      "loss: 0.093669  [12800/141921]\n",
      "loss: 0.136944  [16000/141921]\n",
      "loss: 0.120209  [19200/141921]\n",
      "loss: 0.116547  [22400/141921]\n",
      "loss: 0.103362  [25600/141921]\n",
      "loss: 0.105941  [28800/141921]\n",
      "loss: 0.116267  [32000/141921]\n",
      "loss: 0.138359  [35200/141921]\n",
      "loss: 0.168840  [38400/141921]\n",
      "loss: 0.078755  [41600/141921]\n",
      "loss: 0.061455  [44800/141921]\n",
      "loss: 0.056181  [48000/141921]\n",
      "loss: 0.092644  [51200/141921]\n",
      "loss: 0.114593  [54400/141921]\n",
      "loss: 0.060304  [57600/141921]\n",
      "loss: 0.079798  [60800/141921]\n",
      "loss: 0.051464  [64000/141921]\n",
      "loss: 0.068486  [67200/141921]\n",
      "loss: 0.084362  [70400/141921]\n",
      "loss: 0.099835  [73600/141921]\n",
      "loss: 0.070751  [76800/141921]\n",
      "loss: 0.070607  [80000/141921]\n",
      "loss: 0.101247  [83200/141921]\n",
      "loss: 0.106783  [86400/141921]\n",
      "loss: 0.133002  [89600/141921]\n",
      "loss: 0.103763  [92800/141921]\n",
      "loss: 0.079907  [96000/141921]\n",
      "loss: 0.087939  [99200/141921]\n",
      "loss: 0.075139  [102400/141921]\n",
      "loss: 0.056840  [105600/141921]\n",
      "loss: 0.109232  [108800/141921]\n",
      "loss: 0.094252  [112000/141921]\n",
      "loss: 0.103105  [115200/141921]\n",
      "loss: 0.070956  [118400/141921]\n",
      "loss: 0.063185  [121600/141921]\n",
      "loss: 0.103356  [124800/141921]\n",
      "loss: 0.080696  [128000/141921]\n",
      "loss: 0.124300  [131200/141921]\n",
      "loss: 0.080055  [134400/141921]\n",
      "loss: 0.059601  [137600/141921]\n",
      "loss: 0.063662  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.085536 \n",
      "\n",
      "Epoch 16\n",
      "---------------------------\n",
      "loss: 0.125120  [ 3200/141921]\n",
      "loss: 0.137202  [ 6400/141921]\n",
      "loss: 0.072155  [ 9600/141921]\n",
      "loss: 0.049988  [12800/141921]\n",
      "loss: 0.044942  [16000/141921]\n",
      "loss: 0.071881  [19200/141921]\n",
      "loss: 0.074863  [22400/141921]\n",
      "loss: 0.057530  [25600/141921]\n",
      "loss: 0.081047  [28800/141921]\n",
      "loss: 0.090013  [32000/141921]\n",
      "loss: 0.144647  [35200/141921]\n",
      "loss: 0.082762  [38400/141921]\n",
      "loss: 0.097016  [41600/141921]\n",
      "loss: 0.130451  [44800/141921]\n",
      "loss: 0.047200  [48000/141921]\n",
      "loss: 0.077803  [51200/141921]\n",
      "loss: 0.082387  [54400/141921]\n",
      "loss: 0.080999  [57600/141921]\n",
      "loss: 0.100234  [60800/141921]\n",
      "loss: 0.081173  [64000/141921]\n",
      "loss: 0.067181  [67200/141921]\n",
      "loss: 0.080644  [70400/141921]\n",
      "loss: 0.134832  [73600/141921]\n",
      "loss: 0.102168  [76800/141921]\n",
      "loss: 0.090294  [80000/141921]\n",
      "loss: 0.074521  [83200/141921]\n",
      "loss: 0.050173  [86400/141921]\n",
      "loss: 0.082234  [89600/141921]\n",
      "loss: 0.045847  [92800/141921]\n",
      "loss: 0.042046  [96000/141921]\n",
      "loss: 0.094859  [99200/141921]\n",
      "loss: 0.085120  [102400/141921]\n",
      "loss: 0.049485  [105600/141921]\n",
      "loss: 0.141562  [108800/141921]\n",
      "loss: 0.064561  [112000/141921]\n",
      "loss: 0.091027  [115200/141921]\n",
      "loss: 0.096112  [118400/141921]\n",
      "loss: 0.056042  [121600/141921]\n",
      "loss: 0.061271  [124800/141921]\n",
      "loss: 0.059561  [128000/141921]\n",
      "loss: 0.074323  [131200/141921]\n",
      "loss: 0.075267  [134400/141921]\n",
      "loss: 0.082608  [137600/141921]\n",
      "loss: 0.111298  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.075040 \n",
      "\n",
      "Epoch 17\n",
      "---------------------------\n",
      "loss: 0.076839  [ 3200/141921]\n",
      "loss: 0.063108  [ 6400/141921]\n",
      "loss: 0.075274  [ 9600/141921]\n",
      "loss: 0.068941  [12800/141921]\n",
      "loss: 0.055731  [16000/141921]\n",
      "loss: 0.077125  [19200/141921]\n",
      "loss: 0.096171  [22400/141921]\n",
      "loss: 0.083528  [25600/141921]\n",
      "loss: 0.124098  [28800/141921]\n",
      "loss: 0.121893  [32000/141921]\n",
      "loss: 0.041150  [35200/141921]\n",
      "loss: 0.050499  [38400/141921]\n",
      "loss: 0.060692  [41600/141921]\n",
      "loss: 0.059622  [44800/141921]\n",
      "loss: 0.054172  [48000/141921]\n",
      "loss: 0.108998  [51200/141921]\n",
      "loss: 0.097039  [54400/141921]\n",
      "loss: 0.047873  [57600/141921]\n",
      "loss: 0.053841  [60800/141921]\n",
      "loss: 0.078498  [64000/141921]\n",
      "loss: 0.081270  [67200/141921]\n",
      "loss: 0.055081  [70400/141921]\n",
      "loss: 0.129909  [73600/141921]\n",
      "loss: 0.138075  [76800/141921]\n",
      "loss: 0.094232  [80000/141921]\n",
      "loss: 0.036670  [83200/141921]\n",
      "loss: 0.048860  [86400/141921]\n",
      "loss: 0.043524  [89600/141921]\n",
      "loss: 0.032031  [92800/141921]\n",
      "loss: 0.070118  [96000/141921]\n",
      "loss: 0.102189  [99200/141921]\n",
      "loss: 0.037037  [102400/141921]\n",
      "loss: 0.057711  [105600/141921]\n",
      "loss: 0.092247  [108800/141921]\n",
      "loss: 0.103842  [112000/141921]\n",
      "loss: 0.092439  [115200/141921]\n",
      "loss: 0.035210  [118400/141921]\n",
      "loss: 0.092552  [121600/141921]\n",
      "loss: 0.076424  [124800/141921]\n",
      "loss: 0.055780  [128000/141921]\n",
      "loss: 0.077434  [131200/141921]\n",
      "loss: 0.097682  [134400/141921]\n",
      "loss: 0.068201  [137600/141921]\n",
      "loss: 0.095364  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.066872 \n",
      "\n",
      "Epoch 18\n",
      "---------------------------\n",
      "loss: 0.032876  [ 3200/141921]\n",
      "loss: 0.040160  [ 6400/141921]\n",
      "loss: 0.059961  [ 9600/141921]\n",
      "loss: 0.073696  [12800/141921]\n",
      "loss: 0.050325  [16000/141921]\n",
      "loss: 0.119618  [19200/141921]\n",
      "loss: 0.058839  [22400/141921]\n",
      "loss: 0.033110  [25600/141921]\n",
      "loss: 0.087105  [28800/141921]\n",
      "loss: 0.088216  [32000/141921]\n",
      "loss: 0.034470  [35200/141921]\n",
      "loss: 0.051506  [38400/141921]\n",
      "loss: 0.049504  [41600/141921]\n",
      "loss: 0.057614  [44800/141921]\n",
      "loss: 0.042097  [48000/141921]\n",
      "loss: 0.086749  [51200/141921]\n",
      "loss: 0.046904  [54400/141921]\n",
      "loss: 0.066065  [57600/141921]\n",
      "loss: 0.090681  [60800/141921]\n",
      "loss: 0.072636  [64000/141921]\n",
      "loss: 0.083378  [67200/141921]\n",
      "loss: 0.068928  [70400/141921]\n",
      "loss: 0.031657  [73600/141921]\n",
      "loss: 0.119431  [76800/141921]\n",
      "loss: 0.046952  [80000/141921]\n",
      "loss: 0.019574  [83200/141921]\n",
      "loss: 0.057891  [86400/141921]\n",
      "loss: 0.045445  [89600/141921]\n",
      "loss: 0.034348  [92800/141921]\n",
      "loss: 0.046155  [96000/141921]\n",
      "loss: 0.058628  [99200/141921]\n",
      "loss: 0.079162  [102400/141921]\n",
      "loss: 0.056380  [105600/141921]\n",
      "loss: 0.058608  [108800/141921]\n",
      "loss: 0.037731  [112000/141921]\n",
      "loss: 0.043014  [115200/141921]\n",
      "loss: 0.109029  [118400/141921]\n",
      "loss: 0.097576  [121600/141921]\n",
      "loss: 0.091620  [124800/141921]\n",
      "loss: 0.050469  [128000/141921]\n",
      "loss: 0.077842  [131200/141921]\n",
      "loss: 0.035968  [134400/141921]\n",
      "loss: 0.074836  [137600/141921]\n",
      "loss: 0.026835  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.060292 \n",
      "\n",
      "Epoch 19\n",
      "---------------------------\n",
      "loss: 0.034339  [ 3200/141921]\n",
      "loss: 0.065444  [ 6400/141921]\n",
      "loss: 0.078012  [ 9600/141921]\n",
      "loss: 0.034644  [12800/141921]\n",
      "loss: 0.040205  [16000/141921]\n",
      "loss: 0.022005  [19200/141921]\n",
      "loss: 0.091002  [22400/141921]\n",
      "loss: 0.108753  [25600/141921]\n",
      "loss: 0.049899  [28800/141921]\n",
      "loss: 0.057809  [32000/141921]\n",
      "loss: 0.046828  [35200/141921]\n",
      "loss: 0.037804  [38400/141921]\n",
      "loss: 0.043063  [41600/141921]\n",
      "loss: 0.071388  [44800/141921]\n",
      "loss: 0.055955  [48000/141921]\n",
      "loss: 0.034134  [51200/141921]\n",
      "loss: 0.027421  [54400/141921]\n",
      "loss: 0.069492  [57600/141921]\n",
      "loss: 0.059184  [60800/141921]\n",
      "loss: 0.064602  [64000/141921]\n",
      "loss: 0.054127  [67200/141921]\n",
      "loss: 0.046468  [70400/141921]\n",
      "loss: 0.033149  [73600/141921]\n",
      "loss: 0.077356  [76800/141921]\n",
      "loss: 0.078194  [80000/141921]\n",
      "loss: 0.044747  [83200/141921]\n",
      "loss: 0.083765  [86400/141921]\n",
      "loss: 0.054605  [89600/141921]\n",
      "loss: 0.061847  [92800/141921]\n",
      "loss: 0.049596  [96000/141921]\n",
      "loss: 0.039249  [99200/141921]\n",
      "loss: 0.084342  [102400/141921]\n",
      "loss: 0.061290  [105600/141921]\n",
      "loss: 0.083278  [108800/141921]\n",
      "loss: 0.042447  [112000/141921]\n",
      "loss: 0.051729  [115200/141921]\n",
      "loss: 0.082263  [118400/141921]\n",
      "loss: 0.046857  [121600/141921]\n",
      "loss: 0.047947  [124800/141921]\n",
      "loss: 0.046643  [128000/141921]\n",
      "loss: 0.045949  [131200/141921]\n",
      "loss: 0.106554  [134400/141921]\n",
      "loss: 0.070574  [137600/141921]\n",
      "loss: 0.076035  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.054746 \n",
      "\n",
      "Epoch 20\n",
      "---------------------------\n",
      "loss: 0.056807  [ 3200/141921]\n",
      "loss: 0.089330  [ 6400/141921]\n",
      "loss: 0.043445  [ 9600/141921]\n",
      "loss: 0.062176  [12800/141921]\n",
      "loss: 0.034960  [16000/141921]\n",
      "loss: 0.027738  [19200/141921]\n",
      "loss: 0.047951  [22400/141921]\n",
      "loss: 0.049344  [25600/141921]\n",
      "loss: 0.076247  [28800/141921]\n",
      "loss: 0.060487  [32000/141921]\n",
      "loss: 0.053451  [35200/141921]\n",
      "loss: 0.042410  [38400/141921]\n",
      "loss: 0.087489  [41600/141921]\n",
      "loss: 0.022658  [44800/141921]\n",
      "loss: 0.053688  [48000/141921]\n",
      "loss: 0.072926  [51200/141921]\n",
      "loss: 0.057594  [54400/141921]\n",
      "loss: 0.052429  [57600/141921]\n",
      "loss: 0.055511  [60800/141921]\n",
      "loss: 0.035834  [64000/141921]\n",
      "loss: 0.057177  [67200/141921]\n",
      "loss: 0.076519  [70400/141921]\n",
      "loss: 0.041422  [73600/141921]\n",
      "loss: 0.030712  [76800/141921]\n",
      "loss: 0.084308  [80000/141921]\n",
      "loss: 0.130816  [83200/141921]\n",
      "loss: 0.060834  [86400/141921]\n",
      "loss: 0.044957  [89600/141921]\n",
      "loss: 0.060898  [92800/141921]\n",
      "loss: 0.051873  [96000/141921]\n",
      "loss: 0.058289  [99200/141921]\n",
      "loss: 0.044261  [102400/141921]\n",
      "loss: 0.112298  [105600/141921]\n",
      "loss: 0.035268  [108800/141921]\n",
      "loss: 0.041901  [112000/141921]\n",
      "loss: 0.055438  [115200/141921]\n",
      "loss: 0.107203  [118400/141921]\n",
      "loss: 0.040928  [121600/141921]\n",
      "loss: 0.042714  [124800/141921]\n",
      "loss: 0.039577  [128000/141921]\n",
      "loss: 0.060706  [131200/141921]\n",
      "loss: 0.134443  [134400/141921]\n",
      "loss: 0.062604  [137600/141921]\n",
      "loss: 0.069430  [140800/141921]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.050063 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(sn_train_dataloader, sn_model, loss_fn, sn_optimizer)\n",
    "    test_loop(sn_test_dataloader, sn_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
